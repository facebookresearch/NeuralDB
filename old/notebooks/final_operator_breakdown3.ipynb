{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from neuraldb.scoring.r_precision import f1\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n"
     ]
    }
   ],
   "source": [
    "search_root = \"/checkpoint/jth/job_staging/neuraldb_expts/experiment=operator\"\n",
    "checkpoint_name = \"metrics_test.jsonl\"\n",
    "files = glob(\"{}*/**/{}\".format(search_root,checkpoint_name), recursive=True)\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/checkpoint/jth/job_staging/neuraldb_expts/experiment=operator_sweep/dataset=operator,model=t5-base,version=v2.2_clean_noisy/lr=8e-5/filters=null,train_percentage=1.0/seed-1/metrics_test.jsonl\n",
      "/checkpoint/jth/job_staging/neuraldb_expts/experiment=operator_sweep/dataset=operator,model=t5-base,version=v2.2_clean_noisy/lr=8e-5/filters=null,train_percentage=1.0/seed-2/metrics_test.jsonl\n",
      "/checkpoint/jth/job_staging/neuraldb_expts/experiment=operator_sweep/dataset=operator,model=t5-base,version=v2.2_clean_noisy/lr=8e-5/filters=null,train_percentage=1.0/seed-3/metrics_test.jsonl\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def expand(idx,chunk):\n",
    "  #elif idx == 1:\n",
    "  #  return [\"experiment={}\".format(chunk)]\n",
    "  if chunk.startswith(\"seed-\"):\n",
    "    return [\"seed={}\".format(chunk.replace(\"seed-\",\"\"))]\n",
    "  elif \",\" in chunk:\n",
    "    return chunk.split(\",\")\n",
    "  elif \"=\" in chunk:\n",
    "    return [chunk]\n",
    "\n",
    "  return []\n",
    "\n",
    "experiments = []\n",
    "for file in files:\n",
    "    chunks = file.split(\"/\")\n",
    "    chunks = itertools.chain(*[expand(idx, chunk) for idx, chunk in enumerate(chunks)])\n",
    "\n",
    "    data = {k:v for k,v in (chunk.split(\"=\") for chunk in chunks)}\n",
    "    data[\"file\"] = file\n",
    "    data['dir'] = os.path.dirname(file)\n",
    "    data[\"train_percentage\"] = float(data[\"train_percentage\"])*100 if data[\"train_percentage\"] != \"null\" else 100.0\n",
    "    if \"clean\" in file and \"noisy\" in file:\n",
    "        print(file)\n",
    "    if data[\"version\"].startswith(\"v1.3\"):\n",
    "        experiments.append(data)\n",
    "\n",
    "print(len(experiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=372.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0e947ff1fc54a83acd347800ad5e0e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "17204 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "20578 169\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "19971 170\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "11834 158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "for experiment in tqdm(experiments):\n",
    "    all_raw = []\n",
    "    all_breakdown = defaultdict(dict)\n",
    "    em = 0.0\n",
    "    with open(experiment['file']) as f:\n",
    "        for line in f:\n",
    "            partial_results = json.loads(line)\n",
    "            all_raw.extend(partial_results['test']['raw'])\n",
    "            all_breakdown[\"breakdown_prop\"].update(partial_results['test']['breakdown'][\"breakdown_prop\"].items())\n",
    "            all_breakdown[\"breakdown_type\"].update(partial_results['test']['breakdown'][\"breakdown_type\"].items())\n",
    "\n",
    "\n",
    "    experiment[\"EM\"] = np.mean([rec[2] for rec in all_raw])\n",
    "\n",
    "    for k,v in all_breakdown[\"breakdown_prop\"].items():\n",
    "        experiment[\"prop_{}\".format(k)] = np.mean(v)\n",
    "\n",
    "    for k,v in all_breakdown[\"breakdown_type\"].items():\n",
    "        experiment[\"type_{}\".format(k)] = np.mean(v)\n",
    "        experiment[\"count_type_{}\".format(k)] = len(v)\n",
    "\n",
    "\n",
    "    experiment[\"raw\"] = all_raw\n",
    "\n",
    "    qt = set()\n",
    "    at = set()\n",
    "    \n",
    "\n",
    "    avg = []\n",
    "    for k,v in experiment.items():\n",
    "        if k.startswith(\"type_negative\"):\n",
    "            avg.append((experiment[\"count_{}\".format(k)], v))\n",
    "\n",
    "    support, ems = zip(*avg)\n",
    "    experiment[\"x_avg_negative\"] = np.average(a=ems,weights=support)\n",
    "\n",
    "\n",
    "    gold = defaultdict(lambda: defaultdict(list))\n",
    "    for instance in experiment[\"raw\"]:\n",
    "        qt.add(instance[3][\"query\"])\n",
    "        at.update(instance[3][\"fact\"])\n",
    "\n",
    "        if instance[0] != \"[NULL_ANSWER]\" or instance[1] != \"[NULL_ANSWER]\":\n",
    "\n",
    "            gold[instance[3][\"type\"]][instance[3][\"query\"]].append((instance[0], instance[1]))\n",
    "\n",
    "    print(len(qt),len(at))\n",
    "    aem = 0\n",
    "    aem_count = 0\n",
    "\n",
    "    scores = defaultdict(int)\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    maxen = set()\n",
    "    mc100 = 0\n",
    "    cc100 =0\n",
    "    for t, questions in gold.items():\n",
    "        \n",
    "        if t in {\"atomic_boolean\",\"join_boolean\", \"atomic_extractive\",\"join_extractive\"}:\n",
    "            for question, answers in questions.items():\n",
    "                for answer in answers:\n",
    "                    aem_count +=1\n",
    "                    counts[t] += 1\n",
    "\n",
    "                    if answer[0] == answer[1]:\n",
    "                        aem += 1\n",
    "                        scores[t]+=1\n",
    "        elif t == \"argmin\":\n",
    "\n",
    "            for question, answers in questions.items():\n",
    "                maxen.add(len(answers))\n",
    "                argmin_aggr_gold = defaultdict(list)\n",
    "                argmin_aggr_pred = defaultdict(list)\n",
    "                for answer in answers:\n",
    "                    if answer[0] != \"[NULL_ANSWER]\" and \"[SEP]\" in answer[0]:\n",
    "                        key,value = answer[0].split(\"[SEP]\",maxsplit=1)\n",
    "                        argmin_aggr_pred[key.strip()] = value.strip()\n",
    "\n",
    "                    if answer[1] != \"[NULL_ANSWER]\":\n",
    "                        key,value = answer[1].split(\"[SEP]\",maxsplit=1)\n",
    "                        argmin_aggr_gold[key.strip()] = value.strip()\n",
    "\n",
    "                min_item_gold = sorted(argmin_aggr_gold.items(),key=lambda item: len(item[1]))\n",
    "                min_item_pred = sorted(argmin_aggr_pred.items(),key=lambda item: len(item[1]))\n",
    "\n",
    "                aem_count +=1\n",
    "                counts[t] +=1\n",
    "                if len(min_item_pred):\n",
    "                    if min_item_gold[0][0] == min_item_pred[0][0]:\n",
    "                        scores[t]+=1\n",
    "                        aem+=1\n",
    "\n",
    "                    if len(answers) > 100:\n",
    "                        mc100+= 1 if min_item_gold[0][0] == min_item_pred[0][0] else 0\n",
    "                        cc100+=1\n",
    "\n",
    "        elif t == \"argmax\":\n",
    "\n",
    "            for question, answers in questions.items():\n",
    "                maxen.add(len(answers))\n",
    "                argmin_aggr_gold = defaultdict(list)\n",
    "                argmin_aggr_pred = defaultdict(list)\n",
    "                for answer in answers:\n",
    "                    if answer[0] != \"[NULL_ANSWER]\" and \"[SEP]\" in answer[0]:\n",
    "                        key,value = answer[0].split(\"[SEP]\",maxsplit=1)\n",
    "                        argmin_aggr_pred[key.strip()] = value.strip()\n",
    "\n",
    "                    if answer[1] != \"[NULL_ANSWER]\":\n",
    "                        key,value = answer[1].split(\"[SEP]\",maxsplit=1)\n",
    "                        argmin_aggr_gold[key.strip()] = value.strip()\n",
    "\n",
    "                min_item_gold = sorted(argmin_aggr_gold.items(),key=lambda item: len(item[1]),reverse=True)\n",
    "                min_item_pred = sorted(argmin_aggr_pred.items(),key=lambda item: len(item[1]),reverse=True)\n",
    "\n",
    "                aem_count +=1\n",
    "                counts[t] +=1\n",
    "                if len(min_item_pred):\n",
    "                    if min_item_gold[0][0] == min_item_pred[0][0]:\n",
    "                        aem+=1\n",
    "                        scores[t]+=1\n",
    "\n",
    "                    if len(answers) > 100:\n",
    "                        mc100+= 1 if min_item_gold[0][0] == min_item_pred[0][0] else 0\n",
    "                        cc100+=1\n",
    "\n",
    "        elif t == \"set\":\n",
    "\n",
    "            for question, answers in questions.items():\n",
    "                maxen.add(len(answers))\n",
    "                set_gold = set()\n",
    "                set_pred = set()\n",
    "                for answer in answers:\n",
    "                    if answer[0] != \"[NULL_ANSWER]\":\n",
    "                        set_pred.add(answer[0].strip())\n",
    "\n",
    "                    if answer[1] != \"[NULL_ANSWER]\":\n",
    "                        set_gold.add(answer[1].strip())\n",
    "\n",
    "                aem_count +=1\n",
    "                counts[t] +=1\n",
    "                aem += f1(set_gold, set_pred)\n",
    "                scores[t] += f1(set_gold, set_pred)\n",
    "\n",
    "                if len(answers) > 100:\n",
    "                    mc100+= f1(set_gold, set_pred)\n",
    "                    cc100+=1\n",
    "\n",
    "        elif t == \"count\":\n",
    "            for question, answers in questions.items():\n",
    "                maxen.add(len(answers))\n",
    "                if len(answers) > 100:\n",
    "                    mc100+=1\n",
    "                    cc100+=1\n",
    "                set_gold = set()\n",
    "                set_pred = set()\n",
    "                for answer in answers:\n",
    "                    if answer[0] != \"[NULL_ANSWER]\":\n",
    "                        set_pred.add(answer[0].strip())\n",
    "\n",
    "                    if answer[1] != \"[NULL_ANSWER]\":\n",
    "                        set_gold.add(answer[1].strip())\n",
    "\n",
    "                aem_count +=1\n",
    "                aem += 1 if len(set_gold) == len(set_pred) else 0\n",
    "                scores[t] += 1 if len(set_gold) == len(set_pred) else 0\n",
    "                counts[t] += 1\n",
    "\n",
    "                if len(answers) > 100:\n",
    "                    mc100+= 1 if len(set_gold) == len(set_pred) else 0\n",
    "                    cc100+=1\n",
    "\n",
    "\n",
    "    #print(experiment[\"file\"],mc100/cc100)\n",
    "    #print(sorted(list(maxen),reverse=True)[:25])\n",
    "    for k,v in counts.items():\n",
    "        experiment[\"A_type_{}\".format(k)] = scores[k]/v\n",
    "        experiment[\"A_type_strict_{}\".format(k)] = scores[k]/v\n",
    "\n",
    "    experiment[\"A_EM\"] =aem/aem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type_bool', 'type_set', 'type_argmax', 'type_argmin', 'type_count', 'x_avg_negative']\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                                   A_EM  \\\n                                                                   mean   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.754970   \n                                     P108    100.0             0.953100   \n                                     P1082   100.0             0.942811   \n                                     P1092   100.0             0.952921   \n                                     P1110   100.0             0.954959   \n                                     P1174   100.0             0.952633   \n                                     P118    100.0             0.954618   \n                                     P1198   100.0             0.953627   \n                                     P1867   100.0             0.955196   \n                                     P19     100.0             0.945102   \n                                     P19.P20 100.0             0.933198   \n                                     P20     100.0             0.951906   \n                                     P21     100.0             0.948298   \n                                     P22     100.0             0.955194   \n                                     P22.P23 100.0             0.951885   \n                                     P23     100.0             0.955052   \n                                     P26     100.0             0.952943   \n                                     P27     100.0             0.928584   \n                                     P35     100.0             0.954482   \n                                     P38     100.0             0.955286   \n                                     P47     100.0             0.927121   \n                                     P50     100.0             0.954126   \n                                     P54     100.0             0.946459   \n                                     P57     100.0             0.952945   \n                                     P58     100.0             0.954301   \n                                     P6      100.0             0.954104   \n                                     P61     100.0             0.950638   \n                                     P69     100.0             0.949984   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.380243   \n                                             2.5               0.380874   \n                                             5.0               0.382641   \n                                             7.5               0.384913   \n                                             10.0              0.384661   \n                                             25.0              0.380916   \n                                             50.0              0.383272   \n                                             100.0             0.396104   \n                                4e-5 null    1.0               0.384619   \n                                             2.5               0.388826   \n                                             5.0               0.390382   \n                                             7.5               0.422396   \n                                             10.0              0.981201   \n                                             25.0              0.995947   \n                                             50.0              0.998023   \n                                             100.0             0.999285   \n                                6e-5 null    1.0               0.384703   \n                                             2.5               0.390340   \n                                             5.0               0.390340   \n                                             7.5               0.990365   \n                                             10.0              0.994288   \n                                             25.0              0.996676   \n                                             50.0              0.998948   \n                                             100.0             0.999243   \n                                8e-5 null    1.0               0.392513   \n                                             2.5               0.390298   \n                                             5.0               0.939287   \n                                             7.5               0.994248   \n                                             10.0              0.995414   \n                                             25.0              0.997055   \n                                             50.0              0.998591   \n                                             100.0             0.998759   \n                v1.3.2  t5-base 1e-6 null    1.0               0.462948   \n                                             2.5               0.464575   \n                                             5.0               0.466638   \n                                             7.5               0.468119   \n                                             10.0              0.466783   \n                                             25.0              0.470007   \n                                             50.0              0.472157   \n                                             100.0             0.489383   \n                                4e-5 null    1.0               0.472041   \n                                             2.5               0.489005   \n                                             5.0               0.491358   \n                                             7.5               0.805655   \n                                             10.0              0.996009   \n                                             25.0              0.997400   \n                                             50.0              0.998656   \n                                             100.0             0.999158   \n                                6e-5 null    1.0               0.474132   \n                                             2.5               0.491009   \n                                             5.0               0.648202   \n                                             7.5               0.996407   \n                                             10.0              0.997193   \n                                             25.0              0.998025   \n                                             50.0              0.999593   \n                                             100.0             0.999622   \n                                8e-5 null    1.0               0.478598   \n                                             2.5               0.491300   \n                                             5.0               0.995805   \n                                             7.5               0.996265   \n                                             10.0              0.997178   \n                                             25.0              0.998790   \n                                             50.0              0.999138   \n                                             100.0             0.999651   \n                v1.3.3  t5-base 1e-6 null    1.0               0.456139   \n                                             2.5               0.457888   \n                                             5.0               0.462059   \n                                             7.5               0.465018   \n                                             10.0              0.466061   \n                                             25.0              0.461251   \n                                             50.0              0.463404   \n                                             100.0             0.482812   \n                                4e-5 null    1.0               0.463606   \n                                             2.5               0.482682   \n                                             5.0               0.485368   \n                                             7.5               0.486411   \n                                             10.0              0.939501   \n                                             25.0              0.998304   \n                                             50.0              0.999367   \n                                             100.0             0.999624   \n                                6e-5 null    1.0               0.463438   \n                                             2.5               0.484875   \n                                             5.0               0.486276   \n                                             7.5               0.994286   \n                                             10.0              0.997342   \n                                             25.0              0.998369   \n                                             50.0              0.999731   \n                                             100.0             0.999832   \n                                8e-5 null    1.0               0.468961   \n                                             2.5               0.485267   \n                                             5.0               0.847867   \n                                             7.5               0.996994   \n                                             10.0              0.997477   \n                                             25.0              0.999058   \n                                             50.0              0.999508   \n                                             100.0             0.999765   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.014478   \n                                     P108    100.0             0.004446   \n                                     P1082   100.0             0.001670   \n                                     P1092   100.0             0.002345   \n                                     P1110   100.0             0.002883   \n                                     P1174   100.0             0.000212   \n                                     P118    100.0             0.001670   \n                                     P1198   100.0             0.001800   \n                                     P1867   100.0             0.000340   \n                                     P19     100.0             0.002089   \n                                     P19.P20 100.0             0.004638   \n                                     P20     100.0             0.001080   \n                                     P21     100.0             0.001349   \n                                     P22     100.0             0.000602   \n                                     P22.P23 100.0             0.000769   \n                                     P23     100.0             0.000866   \n                                     P26     100.0             0.001795   \n                                     P27     100.0             0.001094   \n                                     P35     100.0             0.002664   \n                                     P38     100.0             0.000771   \n                                     P47     100.0             0.002096   \n                                     P50     100.0             0.001604   \n                                     P54     100.0             0.001970   \n                                     P57     100.0             0.000551   \n                                     P58     100.0             0.003746   \n                                     P6      100.0             0.002279   \n                                     P61     100.0             0.002476   \n                                     P69     100.0             0.000832   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000146   \n                                             2.5               0.000291   \n                                             5.0               0.001350   \n                                             7.5               0.001676   \n                                             10.0              0.002376   \n                                             25.0              0.000334   \n                                             50.0              0.001495   \n                                             100.0             0.000073   \n                                4e-5 null    1.0               0.000073   \n                                             2.5               0.000386   \n                                             5.0               0.000126   \n                                             7.5               0.055121   \n                                             10.0              0.010968   \n                                             25.0              0.000485   \n                                             50.0              0.000318   \n                                             100.0             0.000131   \n                                6e-5 null    1.0               0.000379   \n                                             2.5               0.000193   \n                                             5.0               0.000146   \n                                             7.5               0.002365   \n                                             10.0              0.000492   \n                                             25.0              0.000131   \n                                             50.0              0.000193   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.001823   \n                                             2.5               0.000073   \n                                             5.0               0.068724   \n                                             7.5               0.000327   \n                                             10.0              0.000159   \n                                             25.0              0.000833   \n                                             50.0              0.000675   \n                                             100.0             0.000794   \n                v1.3.2  t5-base 1e-6 null    1.0               0.000050   \n                                             2.5               0.001133   \n                                             5.0               0.003062   \n                                             7.5               0.002029   \n                                             10.0              0.000133   \n                                             25.0              0.000252   \n                                             50.0              0.000261   \n                                             100.0             0.000580   \n                                4e-5 null    1.0               0.000363   \n                                             2.5               0.000828   \n                                             5.0               0.000266   \n                                             7.5               0.067554   \n                                             10.0              0.000798   \n                                             25.0              0.000233   \n                                             50.0              0.000640   \n                                             100.0             0.000940   \n                                6e-5 null    1.0               0.000860   \n                                             2.5               0.000306   \n                                             5.0               0.033428   \n                                             7.5               0.000305   \n                                             10.0              0.000382   \n                                             25.0              0.000050   \n                                             50.0              0.000050   \n                                             100.0             0.000050   \n                                8e-5 null    1.0               0.003655   \n                                             2.5               0.000101   \n                                             5.0               0.000550   \n                                             7.5               0.000593   \n                                             10.0              0.000315   \n                                             25.0              0.000574   \n                                             50.0              0.000864   \n                                             100.0             0.000087   \n                v1.3.3  t5-base 1e-6 null    1.0               0.000466   \n                                             2.5               0.000233   \n                                             5.0               0.000202   \n                                             7.5               0.000117   \n                                             10.0              0.000117   \n                                             25.0              0.000440   \n                                             50.0              0.000117   \n                                             100.0             0.000058   \n                                4e-5 null    1.0               0.001262   \n                                             2.5               0.000055   \n                                             5.0               0.000303   \n                                             7.5               0.000382   \n                                             10.0              0.019360   \n                                             25.0              0.000167   \n                                             50.0              0.000223   \n                                             100.0             0.000049   \n                                6e-5 null    1.0               0.001216   \n                                             2.5               0.000498   \n                                             5.0               0.000202   \n                                             7.5               0.000870   \n                                             10.0              0.000207   \n                                             25.0              0.000350   \n                                             50.0              0.000058   \n                                             100.0             0.000058   \n                                8e-5 null    1.0               0.005880   \n                                             2.5               0.000101   \n                                             5.0               0.034740   \n                                             7.5               0.000337   \n                                             10.0              0.000809   \n                                             25.0              0.000117   \n                                             50.0              0.000264   \n                                             100.0             0.000058   \n\n                                                                     EM  \\\n                                                                   mean   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.839766   \n                                     P108    100.0             0.976228   \n                                     P1082   100.0             0.847095   \n                                     P1092   100.0             0.974962   \n                                     P1110   100.0             0.976806   \n                                     P1174   100.0             0.976313   \n                                     P118    100.0             0.975860   \n                                     P1198   100.0             0.975592   \n                                     P1867   100.0             0.976727   \n                                     P19     100.0             0.952859   \n                                     P19.P20 100.0             0.940664   \n                                     P20     100.0             0.967891   \n                                     P21     100.0             0.900915   \n                                     P22     100.0             0.974537   \n                                     P22.P23 100.0             0.974084   \n                                     P23     100.0             0.976334   \n                                     P26     100.0             0.975180   \n                                     P27     100.0             0.960329   \n                                     P35     100.0             0.975971   \n                                     P38     100.0             0.976064   \n                                     P47     100.0             0.953634   \n                                     P50     100.0             0.975980   \n                                     P54     100.0             0.947976   \n                                     P57     100.0             0.976645   \n                                     P58     100.0             0.976422   \n                                     P6      100.0             0.976367   \n                                     P61     100.0             0.973881   \n                                     P69     100.0             0.972919   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.041213   \n                                             2.5               0.042826   \n                                             5.0               0.045374   \n                                             7.5               0.051845   \n                                             10.0              0.055653   \n                                             25.0              0.170751   \n                                             50.0              0.208623   \n                                             100.0             0.526257   \n                                4e-5 null    1.0               0.228990   \n                                             2.5               0.746471   \n                                             5.0               0.806858   \n                                             7.5               0.823265   \n                                             10.0              0.953880   \n                                             25.0              0.965382   \n                                             50.0              0.966125   \n                                             100.0             0.966267   \n                                6e-5 null    1.0               0.232471   \n                                             2.5               0.795143   \n                                             5.0               0.812025   \n                                             7.5               0.956236   \n                                             10.0              0.961648   \n                                             25.0              0.965721   \n                                             50.0              0.966130   \n                                             100.0             0.966339   \n                                8e-5 null    1.0               0.348405   \n                                             2.5               0.808818   \n                                             5.0               0.952946   \n                                             7.5               0.960975   \n                                             10.0              0.964497   \n                                             25.0              0.965724   \n                                             50.0              0.966215   \n                                             100.0             0.966109   \n                v1.3.2  t5-base 1e-6 null    1.0               0.077077   \n                                             2.5               0.080102   \n                                             5.0               0.083645   \n                                             7.5               0.085739   \n                                             10.0              0.083929   \n                                             25.0              0.341837   \n                                             50.0              0.420214   \n                                             100.0             0.709962   \n                                4e-5 null    1.0               0.418474   \n                                             2.5               0.711520   \n                                             5.0               0.728150   \n                                             7.5               0.807844   \n                                             10.0              0.821720   \n                                             25.0              0.980566   \n                                             50.0              0.981463   \n                                             100.0             0.981708   \n                                6e-5 null    1.0               0.453148   \n                                             2.5               0.725786   \n                                             5.0               0.797589   \n                                             7.5               0.854106   \n                                             10.0              0.978750   \n                                             25.0              0.981230   \n                                             50.0              0.981940   \n                                             100.0             0.981925   \n                                8e-5 null    1.0               0.618229   \n                                             2.5               0.728234   \n                                             5.0               0.820326   \n                                             7.5               0.977285   \n                                             10.0              0.980110   \n                                             25.0              0.981726   \n                                             50.0              0.981624   \n                                             100.0             0.982206   \n                v1.3.3  t5-base 1e-6 null    1.0               0.065735   \n                                             2.5               0.068803   \n                                             5.0               0.075679   \n                                             7.5               0.095033   \n                                             10.0              0.132682   \n                                             25.0              0.289464   \n                                             50.0              0.340942   \n                                             100.0             0.600711   \n                                4e-5 null    1.0               0.334177   \n                                             2.5               0.601996   \n                                             5.0               0.649606   \n                                             7.5               0.800404   \n                                             10.0              0.958810   \n                                             25.0              0.977023   \n                                             50.0              0.977865   \n                                             100.0             0.978082   \n                                6e-5 null    1.0               0.369300   \n                                             2.5               0.621068   \n                                             5.0               0.793911   \n                                             7.5               0.970323   \n                                             10.0              0.975397   \n                                             25.0              0.977311   \n                                             50.0              0.978071   \n                                             100.0             0.978063   \n                                8e-5 null    1.0               0.474987   \n                                             2.5               0.630407   \n                                             5.0               0.936162   \n                                             7.5               0.974998   \n                                             10.0              0.976446   \n                                             25.0              0.977737   \n                                             50.0              0.978061   \n                                             100.0             0.978176   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.007522   \n                                     P108    100.0             0.000914   \n                                     P1082   100.0             0.004081   \n                                     P1092   100.0             0.000425   \n                                     P1110   100.0             0.000441   \n                                     P1174   100.0             0.000308   \n                                     P118    100.0             0.000652   \n                                     P1198   100.0             0.000731   \n                                     P1867   100.0             0.000414   \n                                     P19     100.0             0.000612   \n                                     P19.P20 100.0             0.001877   \n                                     P20     100.0             0.000802   \n                                     P21     100.0             0.001132   \n                                     P22     100.0             0.000669   \n                                     P22.P23 100.0             0.000331   \n                                     P23     100.0             0.000960   \n                                     P26     100.0             0.000964   \n                                     P27     100.0             0.000318   \n                                     P35     100.0             0.001272   \n                                     P38     100.0             0.000998   \n                                     P47     100.0             0.000980   \n                                     P50     100.0             0.000353   \n                                     P54     100.0             0.000344   \n                                     P57     100.0             0.000843   \n                                     P58     100.0             0.000545   \n                                     P6      100.0             0.000673   \n                                     P61     100.0             0.000866   \n                                     P69     100.0             0.000205   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000052   \n                                             2.5               0.000624   \n                                             5.0               0.002111   \n                                             7.5               0.007734   \n                                             10.0              0.011561   \n                                             25.0              0.006059   \n                                             50.0              0.010296   \n                                             100.0             0.020271   \n                                4e-5 null    1.0               0.004295   \n                                             2.5               0.010281   \n                                             5.0               0.003599   \n                                             7.5               0.014962   \n                                             10.0              0.002602   \n                                             25.0              0.000099   \n                                             50.0              0.000054   \n                                             100.0             0.000074   \n                                6e-5 null    1.0               0.002669   \n                                             2.5               0.004621   \n                                             5.0               0.004494   \n                                             7.5               0.001150   \n                                             10.0              0.001317   \n                                             25.0              0.000079   \n                                             50.0              0.000313   \n                                             100.0             0.000084   \n                                8e-5 null    1.0               0.020867   \n                                             2.5               0.003129   \n                                             5.0               0.005580   \n                                             7.5               0.002140   \n                                             10.0              0.000279   \n                                             25.0              0.000384   \n                                             50.0              0.000125   \n                                             100.0             0.000413   \n                v1.3.2  t5-base 1e-6 null    1.0               0.000078   \n                                             2.5               0.001253   \n                                             5.0               0.004766   \n                                             7.5               0.003582   \n                                             10.0              0.000053   \n                                             25.0              0.025981   \n                                             50.0              0.000821   \n                                             100.0             0.003691   \n                                4e-5 null    1.0               0.007530   \n                                             2.5               0.003204   \n                                             5.0               0.000281   \n                                             7.5               0.004672   \n                                             10.0              0.004331   \n                                             25.0              0.000304   \n                                             50.0              0.000412   \n                                             100.0             0.000435   \n                                6e-5 null    1.0               0.006920   \n                                             2.5               0.000712   \n                                             5.0               0.002245   \n                                             7.5               0.038408   \n                                             10.0              0.000797   \n                                             25.0              0.000311   \n                                             50.0              0.000127   \n                                             100.0             0.000106   \n                                8e-5 null    1.0               0.121104   \n                                             2.5               0.000580   \n                                             5.0               0.001369   \n                                             7.5               0.001604   \n                                             10.0              0.000121   \n                                             25.0              0.000064   \n                                             50.0              0.000526   \n                                             100.0             0.000170   \n                v1.3.3  t5-base 1e-6 null    1.0               0.000176   \n                                             2.5               0.000049   \n                                             5.0               0.000145   \n                                             7.5               0.000176   \n                                             10.0              0.001448   \n                                             25.0              0.000579   \n                                             50.0              0.000931   \n                                             100.0             0.000447   \n                                4e-5 null    1.0               0.005124   \n                                             2.5               0.006303   \n                                             5.0               0.039749   \n                                             7.5               0.005816   \n                                             10.0              0.000352   \n                                             25.0              0.000054   \n                                             50.0              0.000142   \n                                             100.0             0.000064   \n                                6e-5 null    1.0               0.016467   \n                                             2.5               0.004909   \n                                             5.0               0.010508   \n                                             7.5               0.000710   \n                                             10.0              0.000301   \n                                             25.0              0.000225   \n                                             50.0              0.000058   \n                                             100.0             0.000095   \n                                8e-5 null    1.0               0.089539   \n                                             2.5               0.017028   \n                                             5.0               0.025037   \n                                             7.5               0.000214   \n                                             10.0              0.000340   \n                                             25.0              0.000078   \n                                             50.0              0.000129   \n                                             100.0             0.000153   \n\n                                                              count_type_negative  \\\n                                                                             amax   \nexperiment      version model   lr   filters train_percentage                       \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0                           1100   \n                                     P108    100.0                           1134   \n                                     P1082   100.0                           1100   \n                                     P1092   100.0                           1230   \n                                     P1110   100.0                           1155   \n                                     P1174   100.0                           1230   \n                                     P118    100.0                           1230   \n                                     P1198   100.0                           1230   \n                                     P1867   100.0                           1100   \n                                     P19     100.0                           1230   \n                                     P19.P20 100.0                           1230   \n                                     P20     100.0                           1100   \n                                     P21     100.0                           1230   \n                                     P22     100.0                           1230   \n                                     P22.P23 100.0                           1134   \n                                     P23     100.0                           1230   \n                                     P26     100.0                           1230   \n                                     P27     100.0                           1230   \n                                     P35     100.0                           1155   \n                                     P38     100.0                           1155   \n                                     P47     100.0                           1230   \n                                     P50     100.0                           1230   \n                                     P54     100.0                           1230   \n                                     P57     100.0                           1230   \n                                     P58     100.0                           1230   \n                                     P6      100.0                           1230   \n                                     P61     100.0                           1230   \n                                     P69     100.0                           1230   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0                             6257   \n                                             2.5                             6257   \n                                             5.0                             6263   \n                                             7.5                             6208   \n                                             10.0                            6263   \n                                             25.0                            6222   \n                                             50.0                            6263   \n                                             100.0                           6257   \n                                4e-5 null    1.0                             6257   \n                                             2.5                             6222   \n                                             5.0                             6222   \n                                             7.5                             6257   \n                                             10.0                            6263   \n                                             25.0                            6263   \n                                             50.0                            6263   \n                                             100.0                           6257   \n                                6e-5 null    1.0                             6263   \n                                             2.5                             6263   \n                                             5.0                             6222   \n                                             7.5                             6263   \n                                             10.0                            6257   \n                                             25.0                            6263   \n                                             50.0                            6257   \n                                             100.0                           6257   \n                                8e-5 null    1.0                             6263   \n                                             2.5                             6208   \n                                             5.0                             6263   \n                                             7.5                             6222   \n                                             10.0                            6257   \n                                             25.0                            6257   \n                                             50.0                            6222   \n                                             100.0                           6263   \n                v1.3.2  t5-base 1e-6 null    1.0                             2092   \n                                             2.5                             2079   \n                                             5.0                             2234   \n                                             7.5                             2092   \n                                             10.0                            2234   \n                                             25.0                            2234   \n                                             50.0                            2234   \n                                             100.0                           2136   \n                                4e-5 null    1.0                             2234   \n                                             2.5                             2234   \n                                             5.0                             2234   \n                                             7.5                             2092   \n                                             10.0                            2136   \n                                             25.0                            2234   \n                                             50.0                            2092   \n                                             100.0                           2136   \n                                6e-5 null    1.0                             2234   \n                                             2.5                             2136   \n                                             5.0                             2079   \n                                             7.5                             2092   \n                                             10.0                            2092   \n                                             25.0                            2092   \n                                             50.0                            2136   \n                                             100.0                           2136   \n                                8e-5 null    1.0                             2234   \n                                             2.5                             2136   \n                                             5.0                             2234   \n                                             7.5                             2136   \n                                             10.0                            2092   \n                                             25.0                            2136   \n                                             50.0                            2136   \n                                             100.0                           2136   \n                v1.3.3  t5-base 1e-6 null    1.0                             3677   \n                                             2.5                             3677   \n                                             5.0                             3634   \n                                             7.5                             3677   \n                                             10.0                            3759   \n                                             25.0                            3677   \n                                             50.0                            3677   \n                                             100.0                           3634   \n                                4e-5 null    1.0                             3677   \n                                             2.5                             3677   \n                                             5.0                             3677   \n                                             7.5                             3634   \n                                             10.0                            3677   \n                                             25.0                            3759   \n                                             50.0                            3677   \n                                             100.0                           3634   \n                                6e-5 null    1.0                             3677   \n                                             2.5                             3636   \n                                             5.0                             3634   \n                                             7.5                             3677   \n                                             10.0                            3677   \n                                             25.0                            3677   \n                                             50.0                            3677   \n                                             100.0                           3677   \n                                8e-5 null    1.0                             3759   \n                                             2.5                             3759   \n                                             5.0                             3636   \n                                             7.5                             3759   \n                                             10.0                            3677   \n                                             25.0                            3677   \n                                             50.0                            3636   \n                                             100.0                           3677   \n\n                                                              prop_P106  \\\n                                                                   mean   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.491389   \n                                     P108    100.0             0.977262   \n                                     P1082   100.0             0.977533   \n                                     P1092   100.0             0.977490   \n                                     P1110   100.0             0.978578   \n                                     P1174   100.0             0.978300   \n                                     P118    100.0             0.977852   \n                                     P1198   100.0             0.976782   \n                                     P1867   100.0             0.978413   \n                                     P19     100.0             0.977021   \n                                     P19.P20 100.0             0.975889   \n                                     P20     100.0             0.978459   \n                                     P21     100.0             0.977101   \n                                     P22     100.0             0.976181   \n                                     P22.P23 100.0             0.975900   \n                                     P23     100.0             0.976142   \n                                     P26     100.0             0.977749   \n                                     P27     100.0             0.978294   \n                                     P35     100.0             0.976099   \n                                     P38     100.0             0.979054   \n                                     P47     100.0             0.976123   \n                                     P50     100.0             0.977726   \n                                     P54     100.0             0.979096   \n                                     P57     100.0             0.978870   \n                                     P58     100.0             0.979016   \n                                     P6      100.0             0.977753   \n                                     P61     100.0             0.978329   \n                                     P69     100.0             0.977421   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.039213   \n                                             2.5               0.040050   \n                                             5.0               0.043461   \n                                             7.5               0.050306   \n                                             10.0              0.055553   \n                                             25.0              0.206866   \n                                             50.0              0.235983   \n                                             100.0             0.546379   \n                                4e-5 null    1.0               0.241744   \n                                             2.5               0.759413   \n                                             5.0               0.799254   \n                                             7.5               0.800128   \n                                             10.0              0.953012   \n                                             25.0              0.954668   \n                                             50.0              0.956020   \n                                             100.0             0.955644   \n                                6e-5 null    1.0               0.243625   \n                                             2.5               0.792601   \n                                             5.0               0.800264   \n                                             7.5               0.949401   \n                                             10.0              0.954003   \n                                             25.0              0.955939   \n                                             50.0              0.957265   \n                                             100.0             0.957057   \n                                8e-5 null    1.0               0.371492   \n                                             2.5               0.799982   \n                                             5.0               0.951326   \n                                             7.5               0.955488   \n                                             10.0              0.956381   \n                                             25.0              0.956970   \n                                             50.0              0.958531   \n                                             100.0             0.954815   \n                v1.3.2  t5-base 1e-6 null    1.0               0.073738   \n                                             2.5               0.076735   \n                                             5.0               0.080212   \n                                             7.5               0.082883   \n                                             10.0              0.080235   \n                                             25.0              0.383023   \n                                             50.0              0.426132   \n                                             100.0             0.748429   \n                                4e-5 null    1.0               0.422248   \n                                             2.5               0.745350   \n                                             5.0               0.745291   \n                                             7.5               0.823703   \n                                             10.0              0.842933   \n                                             25.0              0.985115   \n                                             50.0              0.985948   \n                                             100.0             0.986455   \n                                6e-5 null    1.0               0.441796   \n                                             2.5               0.751183   \n                                             5.0               0.812927   \n                                             7.5               0.867483   \n                                             10.0              0.983237   \n                                             25.0              0.987003   \n                                             50.0              0.987885   \n                                             100.0             0.985851   \n                                8e-5 null    1.0               0.636064   \n                                             2.5               0.748128   \n                                             5.0               0.830537   \n                                             7.5               0.985316   \n                                             10.0              0.986817   \n                                             25.0              0.987860   \n                                             50.0              0.985851   \n                                             100.0             0.987916   \n                v1.3.3  t5-base 1e-6 null    1.0               0.062378   \n                                             2.5               0.062441   \n                                             5.0               0.072087   \n                                             7.5               0.106603   \n                                             10.0              0.150112   \n                                             25.0              0.328818   \n                                             50.0              0.345572   \n                                             100.0             0.644095   \n                                4e-5 null    1.0               0.344465   \n                                             2.5               0.629176   \n                                             5.0               0.676110   \n                                             7.5               0.786416   \n                                             10.0              0.965668   \n                                             25.0              0.975766   \n                                             50.0              0.974742   \n                                             100.0             0.976576   \n                                6e-5 null    1.0               0.361387   \n                                             2.5               0.653836   \n                                             5.0               0.784362   \n                                             7.5               0.969545   \n                                             10.0              0.973045   \n                                             25.0              0.972794   \n                                             50.0              0.974771   \n                                             100.0             0.974800   \n                                8e-5 null    1.0               0.497245   \n                                             2.5               0.652628   \n                                             5.0               0.958832   \n                                             7.5               0.973888   \n                                             10.0              0.974555   \n                                             25.0              0.972967   \n                                             50.0              0.976817   \n                                             100.0             0.972938   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.026112   \n                                     P108    100.0             0.002146   \n                                     P1082   100.0             0.000192   \n                                     P1092   100.0             0.001234   \n                                     P1110   100.0             0.001633   \n                                     P1174   100.0             0.000646   \n                                     P118    100.0             0.001384   \n                                     P1198   100.0             0.001206   \n                                     P1867   100.0             0.000335   \n                                     P19     100.0             0.000263   \n                                     P19.P20 100.0             0.000904   \n                                     P20     100.0             0.001250   \n                                     P21     100.0             0.001760   \n                                     P22     100.0             0.001418   \n                                     P22.P23 100.0             0.002300   \n                                     P23     100.0             0.001578   \n                                     P26     100.0             0.001541   \n                                     P27     100.0             0.000982   \n                                     P35     100.0             0.002891   \n                                     P38     100.0             0.000499   \n                                     P47     100.0             0.003724   \n                                     P50     100.0             0.001316   \n                                     P54     100.0             0.000656   \n                                     P57     100.0             0.001167   \n                                     P58     100.0             0.000488   \n                                     P6      100.0             0.002099   \n                                     P61     100.0             0.000943   \n                                     P69     100.0             0.000587   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000470   \n                                             2.5               0.000155   \n                                             5.0               0.002787   \n                                             7.5               0.011671   \n                                             10.0              0.016771   \n                                             25.0              0.007462   \n                                             50.0              0.015230   \n                                             100.0             0.034126   \n                                4e-5 null    1.0               0.010761   \n                                             2.5               0.009867   \n                                             5.0               0.001700   \n                                             7.5               0.001809   \n                                             10.0              0.004947   \n                                             25.0              0.003499   \n                                             50.0              0.003883   \n                                             100.0             0.002808   \n                                6e-5 null    1.0               0.007558   \n                                             2.5               0.001448   \n                                             5.0               0.001624   \n                                             7.5               0.003261   \n                                             10.0              0.003921   \n                                             25.0              0.003825   \n                                             50.0              0.002808   \n                                             100.0             0.002646   \n                                8e-5 null    1.0               0.016044   \n                                             2.5               0.004591   \n                                             5.0               0.003431   \n                                             7.5               0.001018   \n                                             10.0              0.002042   \n                                             25.0              0.002552   \n                                             50.0              0.000321   \n                                             100.0             0.003738   \n                v1.3.2  t5-base 1e-6 null    1.0               0.001212   \n                                             2.5               0.001472   \n                                             5.0               0.006571   \n                                             7.5               0.004245   \n                                             10.0              0.001673   \n                                             25.0              0.027873   \n                                             50.0              0.014083   \n                                             100.0             0.004330   \n                                4e-5 null    1.0               0.006603   \n                                             2.5               0.010480   \n                                             5.0               0.010715   \n                                             7.5               0.005740   \n                                             10.0              0.008241   \n                                             25.0              0.003317   \n                                             50.0              0.002229   \n                                             100.0             0.002025   \n                                6e-5 null    1.0               0.012760   \n                                             2.5               0.006922   \n                                             5.0               0.002808   \n                                             7.5               0.040597   \n                                             10.0              0.000243   \n                                             25.0              0.002028   \n                                             50.0              0.001247   \n                                             100.0             0.001030   \n                                8e-5 null    1.0               0.152308   \n                                             2.5               0.006410   \n                                             5.0               0.010935   \n                                             7.5               0.000512   \n                                             10.0              0.002236   \n                                             25.0              0.001226   \n                                             50.0              0.001030   \n                                             100.0             0.001274   \n                v1.3.3  t5-base 1e-6 null    1.0               0.002582   \n                                             2.5               0.001083   \n                                             5.0               0.000044   \n                                             7.5               0.002874   \n                                             10.0              0.000382   \n                                             25.0              0.001989   \n                                             50.0              0.006371   \n                                             100.0             0.000265   \n                                4e-5 null    1.0               0.006917   \n                                             2.5               0.004130   \n                                             5.0               0.058471   \n                                             7.5               0.005745   \n                                             10.0              0.000651   \n                                             25.0              0.000934   \n                                             50.0              0.003126   \n                                             100.0             0.000050   \n                                6e-5 null    1.0               0.015760   \n                                             2.5               0.004669   \n                                             5.0               0.004782   \n                                             7.5               0.003857   \n                                             10.0              0.004222   \n                                             25.0              0.003257   \n                                             50.0              0.003151   \n                                             100.0             0.003176   \n                                8e-5 null    1.0               0.073746   \n                                             2.5               0.019072   \n                                             5.0               0.011434   \n                                             7.5               0.001323   \n                                             10.0              0.004146   \n                                             25.0              0.003176   \n                                             50.0              0.000443   \n                                             100.0             0.003126   \n\n                                                              prop_P108  \\\n                                                                   mean   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.894531   \n                                     P108    100.0             0.927847   \n                                     P1082   100.0             0.964045   \n                                     P1092   100.0             0.999482   \n                                     P1110   100.0             0.938811   \n                                     P1174   100.0             0.975465   \n                                     P118    100.0             0.976190   \n                                     P1198   100.0             0.965845   \n                                     P1867   100.0             0.955093   \n                                     P19     100.0             0.953404   \n                                     P19.P20 100.0             0.970048   \n                                     P20     100.0             0.957031   \n                                     P21     100.0             0.977157   \n                                     P22     100.0             0.982770   \n                                     P22.P23 100.0             0.969551   \n                                     P23     100.0             0.983736   \n                                     P26     100.0             0.979167   \n                                     P27     100.0             0.974432   \n                                     P35     100.0             0.978960   \n                                     P38     100.0             0.946970   \n                                     P47     100.0             0.980322   \n                                     P50     100.0             0.971331   \n                                     P54     100.0             0.996564   \n                                     P57     100.0             0.966294   \n                                     P58     100.0             0.967456   \n                                     P6      100.0             0.976744   \n                                     P61     100.0             0.953981   \n                                     P69     100.0             0.986961   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.023005   \n                                             2.5               0.024557   \n                                             5.0               0.021103   \n                                             7.5               0.025490   \n                                             10.0              0.025552   \n                                             25.0              0.148850   \n                                             50.0              0.143019   \n                                             100.0             0.421990   \n                                4e-5 null    1.0               0.160332   \n                                             2.5               0.756808   \n                                             5.0               0.866730   \n                                             7.5               0.884167   \n                                             10.0              0.923633   \n                                             25.0              0.994043   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                                6e-5 null    1.0               0.161099   \n                                             2.5               0.835459   \n                                             5.0               0.876449   \n                                             7.5               0.936016   \n                                             10.0              0.966642   \n                                             25.0              1.000000   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                                8e-5 null    1.0               0.214062   \n                                             2.5               0.870746   \n                                             5.0               0.945577   \n                                             7.5               0.968340   \n                                             10.0              0.981634   \n                                             25.0              0.998168   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                v1.3.2  t5-base 1e-6 null    1.0               0.077746   \n                                             2.5               0.073633   \n                                             5.0               0.077846   \n                                             7.5               0.082146   \n                                             10.0              0.078689   \n                                             25.0              0.391147   \n                                             50.0              0.456882   \n                                             100.0             0.582720   \n                                4e-5 null    1.0               0.438936   \n                                             2.5               0.601248   \n                                             5.0               0.599241   \n                                             7.5               0.702010   \n                                             10.0              0.681029   \n                                             25.0              0.977678   \n                                             50.0              0.997151   \n                                             100.0             0.994949   \n                                6e-5 null    1.0               0.469000   \n                                             2.5               0.608168   \n                                             5.0               0.648197   \n                                             7.5               0.792023   \n                                             10.0              0.948718   \n                                             25.0              0.992188   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                                8e-5 null    1.0               0.573239   \n                                             2.5               0.606174   \n                                             5.0               0.709734   \n                                             7.5               0.938605   \n                                             10.0              0.973469   \n                                             25.0              0.997475   \n                                             50.0              0.997151   \n                                             100.0             1.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.058158   \n                                             2.5               0.060432   \n                                             5.0               0.052900   \n                                             7.5               0.063216   \n                                             10.0              0.088612   \n                                             25.0              0.308833   \n                                             50.0              0.333504   \n                                             100.0             0.392413   \n                                4e-5 null    1.0               0.306423   \n                                             2.5               0.498057   \n                                             5.0               0.454595   \n                                             7.5               0.661850   \n                                             10.0              0.882046   \n                                             25.0              0.995186   \n                                             50.0              0.997849   \n                                             100.0             0.997849   \n                                6e-5 null    1.0               0.317800   \n                                             2.5               0.443154   \n                                             5.0               0.640273   \n                                             7.5               0.895018   \n                                             10.0              0.922439   \n                                             25.0              0.993762   \n                                             50.0              0.997849   \n                                             100.0             0.997849   \n                                8e-5 null    1.0               0.395016   \n                                             2.5               0.437481   \n                                             5.0               0.848556   \n                                             7.5               0.938756   \n                                             10.0              0.976838   \n                                             25.0              1.000000   \n                                             50.0              0.999570   \n                                             100.0             1.000000   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.046671   \n                                     P108    100.0             0.064082   \n                                     P1082   100.0             0.000704   \n                                     P1092   100.0             0.000897   \n                                     P1110   100.0             0.008394   \n                                     P1174   100.0             0.021276   \n                                     P118    100.0             0.020620   \n                                     P1198   100.0             0.032399   \n                                     P1867   100.0             0.018666   \n                                     P19     100.0             0.018848   \n                                     P19.P20 100.0             0.051878   \n                                     P20     100.0             0.018632   \n                                     P21     100.0             0.019811   \n                                     P22     100.0             0.025381   \n                                     P22.P23 100.0             0.041886   \n                                     P23     100.0             0.026106   \n                                     P26     100.0             0.036084   \n                                     P27     100.0             0.023254   \n                                     P35     100.0             0.024137   \n                                     P38     100.0             0.007256   \n                                     P47     100.0             0.029600   \n                                     P50     100.0             0.024376   \n                                     P54     100.0             0.001139   \n                                     P57     100.0             0.032525   \n                                     P58     100.0             0.029597   \n                                     P6      100.0             0.035777   \n                                     P61     100.0             0.016001   \n                                     P69     100.0             0.019711   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.002479   \n                                             2.5               0.001648   \n                                             5.0               0.000321   \n                                             7.5               0.001766   \n                                             10.0              0.003715   \n                                             25.0              0.004259   \n                                             50.0              0.004857   \n                                             100.0             0.033327   \n                                4e-5 null    1.0               0.015633   \n                                             2.5               0.023432   \n                                             5.0               0.027818   \n                                             7.5               0.026481   \n                                             10.0              0.010963   \n                                             25.0              0.006184   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                                6e-5 null    1.0               0.027606   \n                                             2.5               0.018879   \n                                             5.0               0.030592   \n                                             7.5               0.010863   \n                                             10.0              0.002667   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.028763   \n                                             2.5               0.003048   \n                                             5.0               0.022519   \n                                             7.5               0.012084   \n                                             10.0              0.008476   \n                                             25.0              0.003172   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                v1.3.2  t5-base 1e-6 null    1.0               0.010702   \n                                             2.5               0.000703   \n                                             5.0               0.005636   \n                                             7.5               0.012501   \n                                             10.0              0.005318   \n                                             25.0              0.032436   \n                                             50.0              0.017341   \n                                             100.0             0.001927   \n                                4e-5 null    1.0               0.014309   \n                                             2.5               0.020891   \n                                             5.0               0.020474   \n                                             7.5               0.035752   \n                                             10.0              0.008786   \n                                             25.0              0.020248   \n                                             50.0              0.004935   \n                                             100.0             0.008748   \n                                6e-5 null    1.0               0.017939   \n                                             2.5               0.029013   \n                                             5.0               0.003556   \n                                             7.5               0.060032   \n                                             10.0              0.017094   \n                                             25.0              0.013532   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.090804   \n                                             2.5               0.032351   \n                                             5.0               0.004494   \n                                             7.5               0.014488   \n                                             10.0              0.008173   \n                                             25.0              0.004374   \n                                             50.0              0.004935   \n                                             100.0             0.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.006960   \n                                             2.5               0.007419   \n                                             5.0               0.000167   \n                                             7.5               0.009376   \n                                             10.0              0.004964   \n                                             25.0              0.030858   \n                                             50.0              0.042293   \n                                             100.0             0.000000   \n                                4e-5 null    1.0               0.025832   \n                                             2.5               0.001596   \n                                             5.0               0.057359   \n                                             7.5               0.000428   \n                                             10.0              0.022996   \n                                             25.0              0.004169   \n                                             50.0              0.003725   \n                                             100.0             0.003725   \n                                6e-5 null    1.0               0.056888   \n                                             2.5               0.054752   \n                                             5.0               0.036695   \n                                             7.5               0.021063   \n                                             10.0              0.012906   \n                                             25.0              0.000234   \n                                             50.0              0.003725   \n                                             100.0             0.003725   \n                                8e-5 null    1.0               0.078711   \n                                             2.5               0.036037   \n                                             5.0               0.045011   \n                                             7.5               0.030770   \n                                             10.0              0.021727   \n                                             25.0              0.000000   \n                                             50.0              0.000745   \n                                             100.0             0.000000   \n\n                                                              prop_P1082  ...  \\\n                                                                    mean  ...   \nexperiment      version model   lr   filters train_percentage             ...   \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0              0.983530  ...   \n                                     P108    100.0              0.984558  ...   \n                                     P1082   100.0              0.455868  ...   \n                                     P1092   100.0              0.987894  ...   \n                                     P1110   100.0              0.985670  ...   \n                                     P1174   100.0              0.987078  ...   \n                                     P118    100.0              0.987316  ...   \n                                     P1198   100.0              0.986391  ...   \n                                     P1867   100.0              0.985346  ...   \n                                     P19     100.0              0.986309  ...   \n                                     P19.P20 100.0              0.985924  ...   \n                                     P20     100.0              0.985604  ...   \n                                     P21     100.0              0.986187  ...   \n                                     P22     100.0              0.985103  ...   \n                                     P22.P23 100.0              0.984436  ...   \n                                     P23     100.0              0.984985  ...   \n                                     P26     100.0              0.986753  ...   \n                                     P27     100.0              0.986267  ...   \n                                     P35     100.0              0.984434  ...   \n                                     P38     100.0              0.986068  ...   \n                                     P47     100.0              0.985711  ...   \n                                     P50     100.0              0.986248  ...   \n                                     P54     100.0              0.986973  ...   \n                                     P57     100.0              0.986372  ...   \n                                     P58     100.0              0.986257  ...   \n                                     P6      100.0              0.985903  ...   \n                                     P61     100.0              0.986158  ...   \n                                     P69     100.0              0.987633  ...   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0                0.047451  ...   \n                                             2.5                0.049664  ...   \n                                             5.0                0.054002  ...   \n                                             7.5                0.063396  ...   \n                                             10.0               0.065923  ...   \n                                             25.0               0.180863  ...   \n                                             50.0               0.259124  ...   \n                                             100.0              0.595265  ...   \n                                4e-5 null    1.0                0.305568  ...   \n                                             2.5                0.654618  ...   \n                                             5.0                0.728546  ...   \n                                             7.5                0.787859  ...   \n                                             10.0               0.937748  ...   \n                                             25.0               0.955069  ...   \n                                             50.0               0.949566  ...   \n                                             100.0              0.955630  ...   \n                                6e-5 null    1.0                0.292736  ...   \n                                             2.5                0.703469  ...   \n                                             5.0                0.733651  ...   \n                                             7.5                0.929257  ...   \n                                             10.0               0.953119  ...   \n                                             25.0               0.953132  ...   \n                                             50.0               0.957217  ...   \n                                             100.0              0.953608  ...   \n                                8e-5 null    1.0                0.514929  ...   \n                                             2.5                0.732833  ...   \n                                             5.0                0.932475  ...   \n                                             7.5                0.948089  ...   \n                                             10.0               0.957167  ...   \n                                             25.0               0.957217  ...   \n                                             50.0               0.955237  ...   \n                                             100.0              0.955069  ...   \n                v1.3.2  t5-base 1e-6 null    1.0                0.076326  ...   \n                                             2.5                0.080606  ...   \n                                             5.0                0.084599  ...   \n                                             7.5                0.086540  ...   \n                                             10.0               0.085397  ...   \n                                             25.0               0.345434  ...   \n                                             50.0               0.416306  ...   \n                                             100.0              0.794581  ...   \n                                4e-5 null    1.0                0.476682  ...   \n                                             2.5                0.801295  ...   \n                                             5.0                0.796113  ...   \n                                             7.5                0.904665  ...   \n                                             10.0               0.908077  ...   \n                                             25.0               0.990176  ...   \n                                             50.0               0.989040  ...   \n                                             100.0              0.989028  ...   \n                                6e-5 null    1.0                0.494962  ...   \n                                             2.5                0.795820  ...   \n                                             5.0                0.903756  ...   \n                                             7.5                0.926855  ...   \n                                             10.0               0.987427  ...   \n                                             25.0               0.989927  ...   \n                                             50.0               0.989947  ...   \n                                             100.0              0.988094  ...   \n                                8e-5 null    1.0                0.743828  ...   \n                                             2.5                0.794976  ...   \n                                             5.0                0.905913  ...   \n                                             7.5                0.986513  ...   \n                                             10.0               0.989863  ...   \n                                             25.0               0.989947  ...   \n                                             50.0               0.988097  ...   \n                                             100.0              0.989947  ...   \n                v1.3.3  t5-base 1e-6 null    1.0                0.071228  ...   \n                                             2.5                0.074051  ...   \n                                             5.0                0.079687  ...   \n                                             7.5                0.093334  ...   \n                                             10.0               0.135907  ...   \n                                             25.0               0.306160  ...   \n                                             50.0               0.386407  ...   \n                                             100.0              0.717404  ...   \n                                4e-5 null    1.0                0.392371  ...   \n                                             2.5                0.733232  ...   \n                                             5.0                0.725620  ...   \n                                             7.5                0.903275  ...   \n                                             10.0               0.963374  ...   \n                                             25.0               0.980744  ...   \n                                             50.0               0.979234  ...   \n                                             100.0              0.976974  ...   \n                                6e-5 null    1.0                0.439826  ...   \n                                             2.5                0.778802  ...   \n                                             5.0                0.883627  ...   \n                                             7.5                0.975510  ...   \n                                             10.0               0.979228  ...   \n                                             25.0               0.981495  ...   \n                                             50.0               0.979270  ...   \n                                             100.0              0.979270  ...   \n                                8e-5 null    1.0                0.642586  ...   \n                                             2.5                0.727581  ...   \n                                             5.0                0.946988  ...   \n                                             7.5                0.974277  ...   \n                                             10.0               0.984338  ...   \n                                             25.0               0.981531  ...   \n                                             50.0               0.979528  ...   \n                                             100.0              0.981531  ...   \n\n                                                              type_bool  \\\n                                                                   mean   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.993333   \n                                     P108    100.0             0.999834   \n                                     P1082   100.0             0.885527   \n                                     P1092   100.0             1.000000   \n                                     P1110   100.0             0.999779   \n                                     P1174   100.0             0.999923   \n                                     P118    100.0             0.999419   \n                                     P1198   100.0             0.999772   \n                                     P1867   100.0             0.999812   \n                                     P19     100.0             0.998041   \n                                     P19.P20 100.0             0.992480   \n                                     P20     100.0             0.999848   \n                                     P21     100.0             0.998840   \n                                     P22     100.0             0.999349   \n                                     P22.P23 100.0             0.999588   \n                                     P23     100.0             1.000000   \n                                     P26     100.0             0.999250   \n                                     P27     100.0             0.999933   \n                                     P35     100.0             0.999908   \n                                     P38     100.0             0.999856   \n                                     P47     100.0             0.989428   \n                                     P50     100.0             0.999946   \n                                     P54     100.0             0.998759   \n                                     P57     100.0             0.999819   \n                                     P58     100.0             0.999669   \n                                     P6      100.0             0.999840   \n                                     P61     100.0             0.999771   \n                                     P69     100.0             0.999880   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.191557   \n                                             2.5               0.194997   \n                                             5.0               0.191697   \n                                             7.5               0.218801   \n                                             10.0              0.232274   \n                                             25.0              0.531926   \n                                             50.0              0.530409   \n                                             100.0             0.756355   \n                                4e-5 null    1.0               0.495495   \n                                             2.5               0.768369   \n                                             5.0               0.807301   \n                                             7.5               0.815598   \n                                             10.0              0.913390   \n                                             25.0              0.999884   \n                                             50.0              0.999884   \n                                             100.0             1.000000   \n                                6e-5 null    1.0               0.474761   \n                                             2.5               0.795048   \n                                             5.0               0.808461   \n                                             7.5               0.913242   \n                                             10.0              0.937056   \n                                             25.0              1.000000   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                                8e-5 null    1.0               0.553214   \n                                             2.5               0.810549   \n                                             5.0               0.913331   \n                                             7.5               0.939725   \n                                             10.0              1.000000   \n                                             25.0              1.000000   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                v1.3.2  t5-base 1e-6 null    1.0               0.190641   \n                                             2.5               0.195520   \n                                             5.0               0.198294   \n                                             7.5               0.202690   \n                                             10.0              0.198087   \n                                             25.0              0.630797   \n                                             50.0              0.630308   \n                                             100.0             0.904271   \n                                4e-5 null    1.0               0.642116   \n                                             2.5               0.908114   \n                                             5.0               0.912679   \n                                             7.5               0.999773   \n                                             10.0              0.999980   \n                                             25.0              0.999980   \n                                             50.0              0.999980   \n                                             100.0             1.000000   \n                                6e-5 null    1.0               0.669066   \n                                             2.5               0.911797   \n                                             5.0               0.999913   \n                                             7.5               0.999673   \n                                             10.0              0.999824   \n                                             25.0              1.000000   \n                                             50.0              0.999960   \n                                             100.0             0.999976   \n                                8e-5 null    1.0               0.801500   \n                                             2.5               0.912890   \n                                             5.0               1.000000   \n                                             7.5               0.999953   \n                                             10.0              0.999980   \n                                             25.0              1.000000   \n                                             50.0              1.000000   \n                                             100.0             1.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.189776   \n                                             2.5               0.195191   \n                                             5.0               0.203794   \n                                             7.5               0.248926   \n                                             10.0              0.338021   \n                                             25.0              0.639248   \n                                             50.0              0.655651   \n                                             100.0             0.904216   \n                                4e-5 null    1.0               0.628341   \n                                             2.5               0.901123   \n                                             5.0               0.899607   \n                                             7.5               0.999460   \n                                             10.0              0.999836   \n                                             25.0              1.000000   \n                                             50.0              0.999907   \n                                             100.0             0.999882   \n                                6e-5 null    1.0               0.678354   \n                                             2.5               0.899201   \n                                             5.0               0.999697   \n                                             7.5               0.999895   \n                                             10.0              0.999907   \n                                             25.0              0.999941   \n                                             50.0              0.999966   \n                                             100.0             0.999941   \n                                8e-5 null    1.0               0.724627   \n                                             2.5               0.911504   \n                                             5.0               0.999882   \n                                             7.5               0.999941   \n                                             10.0              0.999989   \n                                             25.0              1.000000   \n                                             50.0              0.999882   \n                                             100.0             1.000000   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.000451   \n                                     P108    100.0             0.000148   \n                                     P1082   100.0             0.025773   \n                                     P1092   100.0             0.000000   \n                                     P1110   100.0             0.000133   \n                                     P1174   100.0             0.000133   \n                                     P118    100.0             0.000176   \n                                     P1198   100.0             0.000006   \n                                     P1867   100.0             0.000076   \n                                     P19     100.0             0.000106   \n                                     P19.P20 100.0             0.003936   \n                                     P20     100.0             0.000084   \n                                     P21     100.0             0.000906   \n                                     P22     100.0             0.000141   \n                                     P22.P23 100.0             0.000147   \n                                     P23     100.0             0.000000   \n                                     P26     100.0             0.000677   \n                                     P27     100.0             0.000099   \n                                     P35     100.0             0.000159   \n                                     P38     100.0             0.000031   \n                                     P47     100.0             0.000881   \n                                     P50     100.0             0.000093   \n                                     P54     100.0             0.000103   \n                                     P57     100.0             0.000227   \n                                     P58     100.0             0.000168   \n                                     P6      100.0             0.000182   \n                                     P61     100.0             0.000236   \n                                     P69     100.0             0.000105   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000916   \n                                             2.5               0.002685   \n                                             5.0               0.004135   \n                                             7.5               0.025612   \n                                             10.0              0.044068   \n                                             25.0              0.005527   \n                                             50.0              0.004835   \n                                             100.0             0.008822   \n                                4e-5 null    1.0               0.023697   \n                                             2.5               0.005162   \n                                             5.0               0.004798   \n                                             7.5               0.005837   \n                                             10.0              0.000447   \n                                             25.0              0.000200   \n                                             50.0              0.000200   \n                                             100.0             0.000000   \n                                6e-5 null    1.0               0.004422   \n                                             2.5               0.006294   \n                                             5.0               0.003394   \n                                             7.5               0.000792   \n                                             10.0              0.038813   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.044221   \n                                             2.5               0.003014   \n                                             5.0               0.001491   \n                                             7.5               0.037276   \n                                             10.0              0.000000   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                v1.3.2  t5-base 1e-6 null    1.0               0.000987   \n                                             2.5               0.001999   \n                                             5.0               0.007490   \n                                             7.5               0.004252   \n                                             10.0              0.002663   \n                                             25.0              0.022017   \n                                             50.0              0.011126   \n                                             100.0             0.005273   \n                                4e-5 null    1.0               0.021514   \n                                             2.5               0.005122   \n                                             5.0               0.000699   \n                                             7.5               0.000168   \n                                             10.0              0.000034   \n                                             25.0              0.000035   \n                                             50.0              0.000034   \n                                             100.0             0.000000   \n                                6e-5 null    1.0               0.014182   \n                                             2.5               0.000900   \n                                             5.0               0.000012   \n                                             7.5               0.000145   \n                                             10.0              0.000157   \n                                             25.0              0.000000   \n                                             50.0              0.000034   \n                                             100.0             0.000041   \n                                8e-5 null    1.0               0.110294   \n                                             2.5               0.000745   \n                                             5.0               0.000000   \n                                             7.5               0.000042   \n                                             10.0              0.000034   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.000544   \n                                             2.5               0.000247   \n                                             5.0               0.000046   \n                                             7.5               0.000531   \n                                             10.0              0.004144   \n                                             25.0              0.001409   \n                                             50.0              0.001011   \n                                             100.0             0.000238   \n                                4e-5 null    1.0               0.009008   \n                                             2.5               0.001411   \n                                             5.0               0.009273   \n                                             7.5               0.000272   \n                                             10.0              0.000158   \n                                             25.0              0.000000   \n                                             50.0              0.000089   \n                                             100.0             0.000102   \n                                6e-5 null    1.0               0.044612   \n                                             2.5               0.010621   \n                                             5.0               0.000058   \n                                             7.5               0.000093   \n                                             10.0              0.000089   \n                                             25.0              0.000102   \n                                             50.0              0.000060   \n                                             100.0             0.000102   \n                                8e-5 null    1.0               0.151810   \n                                             2.5               0.001169   \n                                             5.0               0.000102   \n                                             7.5               0.000102   \n                                             10.0              0.000020   \n                                             25.0              0.000000   \n                                             50.0              0.000102   \n                                             100.0             0.000000   \n\n                                                              type_count  \\\n                                                                    mean   \nexperiment      version model   lr   filters train_percentage              \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0              0.933151   \n                                     P108    100.0              0.992195   \n                                     P1082   100.0              0.931426   \n                                     P1092   100.0              0.993459   \n                                     P1110   100.0              0.993321   \n                                     P1174   100.0              0.993664   \n                                     P118    100.0              0.994444   \n                                     P1198   100.0              0.992984   \n                                     P1867   100.0              0.992776   \n                                     P19     100.0              0.992524   \n                                     P19.P20 100.0              0.974775   \n                                     P20     100.0              0.992488   \n                                     P21     100.0              0.917972   \n                                     P22     100.0              0.992944   \n                                     P22.P23 100.0              0.991912   \n                                     P23     100.0              0.993156   \n                                     P26     100.0              0.994355   \n                                     P27     100.0              0.990530   \n                                     P35     100.0              0.992689   \n                                     P38     100.0              0.993075   \n                                     P47     100.0              0.972459   \n                                     P50     100.0              0.992834   \n                                     P54     100.0              0.992627   \n                                     P57     100.0              0.992565   \n                                     P58     100.0              0.993552   \n                                     P6      100.0              0.991614   \n                                     P61     100.0              0.993036   \n                                     P69     100.0              0.994078   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0                0.046812   \n                                             2.5                0.049046   \n                                             5.0                0.052486   \n                                             7.5                0.060131   \n                                             10.0               0.066910   \n                                             25.0               0.316094   \n                                             50.0               0.348668   \n                                             100.0              0.615164   \n                                4e-5 null    1.0                0.403484   \n                                             2.5                0.574301   \n                                             5.0                0.581171   \n                                             7.5                0.598663   \n                                             10.0               0.969913   \n                                             25.0               0.999292   \n                                             50.0               0.999786   \n                                             100.0              0.999840   \n                                6e-5 null    1.0                0.415279   \n                                             2.5                0.579990   \n                                             5.0                0.581706   \n                                             7.5                0.967272   \n                                             10.0               0.999136   \n                                             25.0               0.999601   \n                                             50.0               1.000000   \n                                             100.0              0.999840   \n                                8e-5 null    1.0                0.782095   \n                                             2.5                0.580590   \n                                             5.0                0.964156   \n                                             7.5                0.992962   \n                                             10.0               0.999334   \n                                             25.0               0.999840   \n                                             50.0               1.000000   \n                                             100.0              0.999571   \n                v1.3.2  t5-base 1e-6 null    1.0                0.046980   \n                                             2.5                0.049765   \n                                             5.0                0.052316   \n                                             7.5                0.053550   \n                                             10.0               0.052982   \n                                             25.0               0.326287   \n                                             50.0               0.441135   \n                                             100.0              0.712516   \n                                4e-5 null    1.0                0.414282   \n                                             2.5                0.726891   \n                                             5.0                0.718029   \n                                             7.5                0.998770   \n                                             10.0               0.998828   \n                                             25.0               0.999230   \n                                             50.0               0.999900   \n                                             100.0              0.999917   \n                                6e-5 null    1.0                0.485312   \n                                             2.5                0.716517   \n                                             5.0                0.996427   \n                                             7.5                0.999594   \n                                             10.0               0.999944   \n                                             25.0               0.999357   \n                                             50.0               0.999936   \n                                             100.0              1.000000   \n                                8e-5 null    1.0                0.778786   \n                                             2.5                0.718053   \n                                             5.0                0.998800   \n                                             7.5                0.998895   \n                                             10.0               0.999309   \n                                             25.0               0.999422   \n                                             50.0               1.000000   \n                                             100.0              1.000000   \n                v1.3.3  t5-base 1e-6 null    1.0                0.047558   \n                                             2.5                0.051006   \n                                             5.0                0.054812   \n                                             7.5                0.073186   \n                                             10.0               0.112518   \n                                             25.0               0.343418   \n                                             50.0               0.407584   \n                                             100.0              0.705839   \n                                4e-5 null    1.0                0.397724   \n                                             2.5                0.733730   \n                                             5.0                0.719050   \n                                             7.5                0.978500   \n                                             10.0               0.996421   \n                                             25.0               0.999265   \n                                             50.0               0.999502   \n                                             100.0              0.999909   \n                                6e-5 null    1.0                0.444926   \n                                             2.5                0.877620   \n                                             5.0                0.966700   \n                                             7.5                0.997982   \n                                             10.0               0.998636   \n                                             25.0               0.998879   \n                                             50.0               0.999867   \n                                             100.0              1.000000   \n                                8e-5 null    1.0                0.698874   \n                                             2.5                0.718210   \n                                             5.0                0.995600   \n                                             7.5                0.999338   \n                                             10.0               0.999031   \n                                             25.0               0.999195   \n                                             50.0               1.000000   \n                                             100.0              0.999959   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.012544   \n                                     P108    100.0             0.000452   \n                                     P1082   100.0             0.002710   \n                                     P1092   100.0             0.000323   \n                                     P1110   100.0             0.000396   \n                                     P1174   100.0             0.001216   \n                                     P118    100.0             0.000405   \n                                     P1198   100.0             0.001085   \n                                     P1867   100.0             0.000883   \n                                     P19     100.0             0.001179   \n                                     P19.P20 100.0             0.006580   \n                                     P20     100.0             0.000298   \n                                     P21     100.0             0.001203   \n                                     P22     100.0             0.001349   \n                                     P22.P23 100.0             0.000316   \n                                     P23     100.0             0.001088   \n                                     P26     100.0             0.000538   \n                                     P27     100.0             0.002044   \n                                     P35     100.0             0.000612   \n                                     P38     100.0             0.000689   \n                                     P47     100.0             0.004417   \n                                     P50     100.0             0.001250   \n                                     P54     100.0             0.000857   \n                                     P57     100.0             0.001023   \n                                     P58     100.0             0.000948   \n                                     P6      100.0             0.001026   \n                                     P61     100.0             0.000876   \n                                     P69     100.0             0.000121   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000529   \n                                             2.5               0.000599   \n                                             5.0               0.002201   \n                                             7.5               0.010469   \n                                             10.0              0.015950   \n                                             25.0              0.009004   \n                                             50.0              0.020523   \n                                             100.0             0.008699   \n                                4e-5 null    1.0               0.005559   \n                                             2.5               0.002512   \n                                             5.0               0.001270   \n                                             7.5               0.027640   \n                                             10.0              0.013042   \n                                             25.0              0.000622   \n                                             50.0              0.000371   \n                                             100.0             0.000277   \n                                6e-5 null    1.0               0.012745   \n                                             2.5               0.001559   \n                                             5.0               0.002632   \n                                             7.5               0.010831   \n                                             10.0              0.001439   \n                                             25.0              0.000349   \n                                             50.0              0.000000   \n                                             100.0             0.000277   \n                                8e-5 null    1.0               0.052298   \n                                             2.5               0.001689   \n                                             5.0               0.023260   \n                                             7.5               0.008747   \n                                             10.0              0.001154   \n                                             25.0              0.000277   \n                                             50.0              0.000000   \n                                             100.0             0.000407   \n                v1.3.2  t5-base 1e-6 null    1.0               0.000111   \n                                             2.5               0.001158   \n                                             5.0               0.003143   \n                                             7.5               0.002117   \n                                             10.0              0.000487   \n                                             25.0              0.035984   \n                                             50.0              0.002088   \n                                             100.0             0.002010   \n                                4e-5 null    1.0               0.011914   \n                                             2.5               0.021974   \n                                             5.0               0.000530   \n                                             7.5               0.000601   \n                                             10.0              0.000201   \n                                             25.0              0.000209   \n                                             50.0              0.000173   \n                                             100.0             0.000144   \n                                6e-5 null    1.0               0.008882   \n                                             2.5               0.000737   \n                                             5.0               0.002232   \n                                             7.5               0.000308   \n                                             10.0              0.000049   \n                                             25.0              0.000486   \n                                             50.0              0.000111   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.232642   \n                                             2.5               0.000677   \n                                             5.0               0.000223   \n                                             7.5               0.000581   \n                                             10.0              0.000603   \n                                             25.0              0.000510   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.001250   \n                                             2.5               0.001537   \n                                             5.0               0.000306   \n                                             7.5               0.003586   \n                                             10.0              0.005190   \n                                             25.0              0.007020   \n                                             50.0              0.004360   \n                                             100.0             0.000428   \n                                4e-5 null    1.0               0.003236   \n                                             2.5               0.034276   \n                                             5.0               0.003645   \n                                             7.5               0.006186   \n                                             10.0              0.001016   \n                                             25.0              0.000328   \n                                             50.0              0.000389   \n                                             100.0             0.000158   \n                                6e-5 null    1.0               0.018337   \n                                             2.5               0.012689   \n                                             5.0               0.011453   \n                                             7.5               0.000218   \n                                             10.0              0.000337   \n                                             25.0              0.000466   \n                                             50.0              0.000137   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.189575   \n                                             2.5               0.002258   \n                                             5.0               0.002225   \n                                             7.5               0.000497   \n                                             10.0              0.000724   \n                                             25.0              0.000460   \n                                             50.0              0.000000   \n                                             100.0             0.000072   \n\n                                                              type_negative  \\\n                                                                       mean   \nexperiment      version model   lr   filters train_percentage                 \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0                 0.913333   \n                                     P108    100.0                 0.916896   \n                                     P1082   100.0                 0.927273   \n                                     P1092   100.0                 0.931165   \n                                     P1110   100.0                 0.920952   \n                                     P1174   100.0                 0.929192   \n                                     P118    100.0                 0.927913   \n                                     P1198   100.0                 0.919167   \n                                     P1867   100.0                 0.918788   \n                                     P19     100.0                 0.918973   \n                                     P19.P20 100.0                 0.926593   \n                                     P20     100.0                 0.916970   \n                                     P21     100.0                 0.914494   \n                                     P22     100.0                 0.921115   \n                                     P22.P23 100.0                 0.915620   \n                                     P23     100.0                 0.922493   \n                                     P26     100.0                 0.922018   \n                                     P27     100.0                 0.923907   \n                                     P35     100.0                 0.919042   \n                                     P38     100.0                 0.922078   \n                                     P47     100.0                 0.906284   \n                                     P50     100.0                 0.922453   \n                                     P54     100.0                 0.930148   \n                                     P57     100.0                 0.926612   \n                                     P58     100.0                 0.926178   \n                                     P6      100.0                 0.925052   \n                                     P61     100.0                 0.920936   \n                                     P69     100.0                 0.931707   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0                   0.000000   \n                                             2.5                   0.000000   \n                                             5.0                   0.000000   \n                                             7.5                   0.000000   \n                                             10.0                  0.000000   \n                                             25.0                  0.000000   \n                                             50.0                  0.000000   \n                                             100.0                 0.325503   \n                                4e-5 null    1.0                   0.000000   \n                                             2.5                   0.839334   \n                                             5.0                   0.931264   \n                                             7.5                   0.945018   \n                                             10.0                  0.941486   \n                                             25.0                  0.944845   \n                                             50.0                  0.944779   \n                                             100.0                 0.945309   \n                                6e-5 null    1.0                   0.000000   \n                                             2.5                   0.908193   \n                                             5.0                   0.935933   \n                                             7.5                   0.940846   \n                                             10.0                  0.942862   \n                                             25.0                  0.945113   \n                                             50.0                  0.945808   \n                                             100.0                 0.945419   \n                                8e-5 null    1.0                   0.008716   \n                                             2.5                   0.937607   \n                                             5.0                   0.941742   \n                                             7.5                   0.942805   \n                                             10.0                  0.944039   \n                                             25.0                  0.945378   \n                                             50.0                  0.945918   \n                                             100.0                 0.945433   \n                v1.3.2  t5-base 1e-6 null    1.0                   0.000000   \n                                             2.5                   0.000000   \n                                             5.0                   0.000000   \n                                             7.5                   0.000000   \n                                             10.0                  0.000000   \n                                             25.0                  0.000000   \n                                             50.0                  0.000000   \n                                             100.0                 0.000000   \n                                4e-5 null    1.0                   0.000000   \n                                             2.5                   0.000000   \n                                             5.0                   0.000000   \n                                             7.5                   0.000000   \n                                             10.0                  0.018102   \n                                             25.0                  0.945446   \n                                             50.0                  0.938236   \n                                             100.0                 0.943558   \n                                6e-5 null    1.0                   0.000000   \n                                             2.5                   0.000000   \n                                             5.0                   0.000000   \n                                             7.5                   0.201721   \n                                             10.0                  0.920650   \n                                             25.0                  0.943704   \n                                             50.0                  0.949983   \n                                             100.0                 0.941953   \n                                8e-5 null    1.0                   0.000000   \n                                             2.5                   0.000000   \n                                             5.0                   0.009063   \n                                             7.5                   0.932870   \n                                             10.0                  0.940503   \n                                             25.0                  0.949506   \n                                             50.0                  0.940997   \n                                             100.0                 0.950299   \n                v1.3.3  t5-base 1e-6 null    1.0                   0.000000   \n                                             2.5                   0.000000   \n                                             5.0                   0.000000   \n                                             7.5                   0.000000   \n                                             10.0                  0.000000   \n                                             25.0                  0.000000   \n                                             50.0                  0.000000   \n                                             100.0                 0.000000   \n                                4e-5 null    1.0                   0.000000   \n                                             2.5                   0.000725   \n                                             5.0                   0.107610   \n                                             7.5                   0.526234   \n                                             10.0                  0.904965   \n                                             25.0                  0.948717   \n                                             50.0                  0.948826   \n                                             100.0                 0.948083   \n                                6e-5 null    1.0                   0.000000   \n                                             2.5                   0.000734   \n                                             5.0                   0.504403   \n                                             7.5                   0.930722   \n                                             10.0                  0.941700   \n                                             25.0                  0.949392   \n                                             50.0                  0.949009   \n                                             100.0                 0.949192   \n                                8e-5 null    1.0                   0.000092   \n                                             2.5                   0.038766   \n                                             5.0                   0.848026   \n                                             7.5                   0.940815   \n                                             10.0                  0.948401   \n                                             25.0                  0.950028   \n                                             50.0                  0.949376   \n                                             100.0                 0.950301   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.006577   \n                                     P108    100.0             0.002844   \n                                     P1082   100.0             0.003963   \n                                     P1092   100.0             0.003078   \n                                     P1110   100.0             0.004223   \n                                     P1174   100.0             0.007219   \n                                     P118    100.0             0.005413   \n                                     P1198   100.0             0.004855   \n                                     P1867   100.0             0.003193   \n                                     P19     100.0             0.004169   \n                                     P19.P20 100.0             0.008905   \n                                     P20     100.0             0.003674   \n                                     P21     100.0             0.008867   \n                                     P22     100.0             0.009174   \n                                     P22.P23 100.0             0.005044   \n                                     P23     100.0             0.010844   \n                                     P26     100.0             0.004189   \n                                     P27     100.0             0.009193   \n                                     P35     100.0             0.005550   \n                                     P38     100.0             0.005266   \n                                     P47     100.0             0.008043   \n                                     P50     100.0             0.009740   \n                                     P54     100.0             0.011180   \n                                     P57     100.0             0.012686   \n                                     P58     100.0             0.009744   \n                                     P6      100.0             0.012054   \n                                     P61     100.0             0.008376   \n                                     P69     100.0             0.003544   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000000   \n                                             2.5               0.000000   \n                                             5.0               0.000000   \n                                             7.5               0.000000   \n                                             10.0              0.000000   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.054280   \n                                4e-5 null    1.0               0.000000   \n                                             2.5               0.013386   \n                                             5.0               0.012068   \n                                             7.5               0.011933   \n                                             10.0              0.000455   \n                                             25.0              0.000990   \n                                             50.0              0.000394   \n                                             100.0             0.001213   \n                                6e-5 null    1.0               0.000000   \n                                             2.5               0.009517   \n                                             5.0               0.008561   \n                                             7.5               0.000362   \n                                             10.0              0.001085   \n                                             25.0              0.000830   \n                                             50.0              0.001394   \n                                             100.0             0.001374   \n                                8e-5 null    1.0               0.004533   \n                                             2.5               0.008209   \n                                             5.0               0.001031   \n                                             7.5               0.000338   \n                                             10.0              0.000691   \n                                             25.0              0.000877   \n                                             50.0              0.001186   \n                                             100.0             0.001481   \n                v1.3.2  t5-base 1e-6 null    1.0               0.000000   \n                                             2.5               0.000000   \n                                             5.0               0.000000   \n                                             7.5               0.000000   \n                                             10.0              0.000000   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                                4e-5 null    1.0               0.000000   \n                                             2.5               0.000000   \n                                             5.0               0.000000   \n                                             7.5               0.000000   \n                                             10.0              0.031354   \n                                             25.0              0.003059   \n                                             50.0              0.011427   \n                                             100.0             0.010062   \n                                6e-5 null    1.0               0.000000   \n                                             2.5               0.000000   \n                                             5.0               0.000000   \n                                             7.5               0.221373   \n                                             10.0              0.004560   \n                                             25.0              0.010076   \n                                             50.0              0.002914   \n                                             100.0             0.008100   \n                                8e-5 null    1.0               0.000000   \n                                             2.5               0.000000   \n                                             5.0               0.008672   \n                                             7.5               0.005202   \n                                             10.0              0.009754   \n                                             25.0              0.002907   \n                                             50.0              0.009755   \n                                             100.0             0.002773   \n                v1.3.3  t5-base 1e-6 null    1.0               0.000000   \n                                             2.5               0.000000   \n                                             5.0               0.000000   \n                                             7.5               0.000000   \n                                             10.0              0.000000   \n                                             25.0              0.000000   \n                                             50.0              0.000000   \n                                             100.0             0.000000   \n                                4e-5 null    1.0               0.000000   \n                                             2.5               0.001030   \n                                             5.0               0.146849   \n                                             7.5               0.015033   \n                                             10.0              0.005379   \n                                             25.0              0.002144   \n                                             50.0              0.001943   \n                                             100.0             0.000159   \n                                6e-5 null    1.0               0.000000   \n                                             2.5               0.000573   \n                                             5.0               0.040412   \n                                             7.5               0.004658   \n                                             10.0              0.002047   \n                                             25.0              0.001738   \n                                             50.0              0.002005   \n                                             100.0             0.001847   \n                                8e-5 null    1.0               0.000159   \n                                             2.5               0.060331   \n                                             5.0               0.071151   \n                                             7.5               0.001348   \n                                             10.0              0.001392   \n                                             25.0              0.001764   \n                                             50.0              0.002398   \n                                             100.0             0.001762   \n\n                                                               type_set  \\\n                                                                   mean   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.765056   \n                                     P108    100.0             0.990330   \n                                     P1082   100.0             0.987711   \n                                     P1092   100.0             0.988861   \n                                     P1110   100.0             0.990933   \n                                     P1174   100.0             0.990156   \n                                     P118    100.0             0.991036   \n                                     P1198   100.0             0.990083   \n                                     P1867   100.0             0.990584   \n                                     P19     100.0             0.986448   \n                                     P19.P20 100.0             0.980094   \n                                     P20     100.0             0.989653   \n                                     P21     100.0             0.843108   \n                                     P22     100.0             0.991674   \n                                     P22.P23 100.0             0.990394   \n                                     P23     100.0             0.991003   \n                                     P26     100.0             0.990064   \n                                     P27     100.0             0.954982   \n                                     P35     100.0             0.991103   \n                                     P38     100.0             0.991137   \n                                     P47     100.0             0.975888   \n                                     P50     100.0             0.990698   \n                                     P54     100.0             0.989630   \n                                     P57     100.0             0.990663   \n                                     P58     100.0             0.991201   \n                                     P6      100.0             0.991632   \n                                     P61     100.0             0.983419   \n                                     P69     100.0             0.990527   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.062254   \n                                             2.5               0.063627   \n                                             5.0               0.066124   \n                                             7.5               0.075616   \n                                             10.0              0.082768   \n                                             25.0              0.398260   \n                                             50.0              0.440616   \n                                             100.0             0.623933   \n                                4e-5 null    1.0               0.476101   \n                                             2.5               0.605557   \n                                             5.0               0.655588   \n                                             7.5               0.673806   \n                                             10.0              0.983928   \n                                             25.0              0.999435   \n                                             50.0              0.999885   \n                                             100.0             0.999899   \n                                6e-5 null    1.0               0.490919   \n                                             2.5               0.646480   \n                                             5.0               0.658870   \n                                             7.5               0.994222   \n                                             10.0              0.999220   \n                                             25.0              0.999788   \n                                             50.0              0.999899   \n                                             100.0             0.999858   \n                                8e-5 null    1.0               0.603892   \n                                             2.5               0.658844   \n                                             5.0               0.975043   \n                                             7.5               0.998769   \n                                             10.0              0.999754   \n                                             25.0              0.999721   \n                                             50.0              0.999960   \n                                             100.0             0.999718   \n                v1.3.2  t5-base 1e-6 null    1.0               0.061871   \n                                             2.5               0.063946   \n                                             5.0               0.066863   \n                                             7.5               0.067979   \n                                             10.0              0.066711   \n                                             25.0              0.386294   \n                                             50.0              0.472227   \n                                             100.0             0.758248   \n                                4e-5 null    1.0               0.482378   \n                                             2.5               0.755259   \n                                             5.0               0.829883   \n                                             7.5               0.933072   \n                                             10.0              0.998661   \n                                             25.0              0.999549   \n                                             50.0              0.999788   \n                                             100.0             0.999916   \n                                6e-5 null    1.0               0.482702   \n                                             2.5               0.822679   \n                                             5.0               0.874759   \n                                             7.5               0.998747   \n                                             10.0              0.999091   \n                                             25.0              0.999759   \n                                             50.0              0.999889   \n                                             100.0             0.999874   \n                                8e-5 null    1.0               0.590277   \n                                             2.5               0.830894   \n                                             5.0               0.998075   \n                                             7.5               0.997814   \n                                             10.0              0.998646   \n                                             25.0              0.999686   \n                                             50.0              0.999748   \n                                             100.0             1.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.062052   \n                                             2.5               0.063661   \n                                             5.0               0.068893   \n                                             7.5               0.087834   \n                                             10.0              0.129150   \n                                             25.0              0.403461   \n                                             50.0              0.450711   \n                                             100.0             0.769528   \n                                4e-5 null    1.0               0.454981   \n                                             2.5               0.751015   \n                                             5.0               0.826463   \n                                             7.5               0.674198   \n                                             10.0              0.964105   \n                                             25.0              0.999995   \n                                             50.0              0.999815   \n                                             100.0             0.999927   \n                                6e-5 null    1.0               0.463374   \n                                             2.5               0.763383   \n                                             5.0               0.687419   \n                                             7.5               0.991736   \n                                             10.0              0.998133   \n                                             25.0              0.999591   \n                                             50.0              0.999964   \n                                             100.0             1.000000   \n                                8e-5 null    1.0               0.522564   \n                                             2.5               0.825256   \n                                             5.0               0.926716   \n                                             7.5               0.996934   \n                                             10.0              0.999556   \n                                             25.0              0.999965   \n                                             50.0              0.999751   \n                                             100.0             0.999964   \n\n                                                                         \\\n                                                                    std   \nexperiment      version model   lr   filters train_percentage             \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.024635   \n                                     P108    100.0             0.000899   \n                                     P1082   100.0             0.000634   \n                                     P1092   100.0             0.000934   \n                                     P1110   100.0             0.000776   \n                                     P1174   100.0             0.000438   \n                                     P118    100.0             0.000667   \n                                     P1198   100.0             0.000821   \n                                     P1867   100.0             0.000634   \n                                     P19     100.0             0.001148   \n                                     P19.P20 100.0             0.002361   \n                                     P20     100.0             0.000270   \n                                     P21     100.0             0.002044   \n                                     P22     100.0             0.000297   \n                                     P22.P23 100.0             0.000430   \n                                     P23     100.0             0.000275   \n                                     P26     100.0             0.000843   \n                                     P27     100.0             0.002526   \n                                     P35     100.0             0.000961   \n                                     P38     100.0             0.000857   \n                                     P47     100.0             0.002388   \n                                     P50     100.0             0.000703   \n                                     P54     100.0             0.001775   \n                                     P57     100.0             0.000475   \n                                     P58     100.0             0.000544   \n                                     P6      100.0             0.000524   \n                                     P61     100.0             0.000863   \n                                     P69     100.0             0.000523   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.001139   \n                                             2.5               0.001354   \n                                             5.0               0.002538   \n                                             7.5               0.012597   \n                                             10.0              0.017823   \n                                             25.0              0.016694   \n                                             50.0              0.019064   \n                                             100.0             0.010344   \n                                4e-5 null    1.0               0.011279   \n                                             2.5               0.011443   \n                                             5.0               0.005547   \n                                             7.5               0.019697   \n                                             10.0              0.009025   \n                                             25.0              0.000421   \n                                             50.0              0.000112   \n                                             100.0             0.000175   \n                                6e-5 null    1.0               0.011099   \n                                             2.5               0.005910   \n                                             5.0               0.004420   \n                                             7.5               0.001016   \n                                             10.0              0.000144   \n                                             25.0              0.000221   \n                                             50.0              0.000175   \n                                             100.0             0.000152   \n                                8e-5 null    1.0               0.042609   \n                                             2.5               0.001021   \n                                             5.0               0.019100   \n                                             7.5               0.000555   \n                                             10.0              0.000147   \n                                             25.0              0.000193   \n                                             50.0              0.000048   \n                                             100.0             0.000272   \n                v1.3.2  t5-base 1e-6 null    1.0               0.000907   \n                                             2.5               0.001080   \n                                             5.0               0.003832   \n                                             7.5               0.002489   \n                                             10.0              0.001028   \n                                             25.0              0.044967   \n                                             50.0              0.003505   \n                                             100.0             0.012535   \n                                4e-5 null    1.0               0.014521   \n                                             2.5               0.022898   \n                                             5.0               0.001111   \n                                             7.5               0.026861   \n                                             10.0              0.000701   \n                                             25.0              0.000472   \n                                             50.0              0.000231   \n                                             100.0             0.000146   \n                                6e-5 null    1.0               0.020771   \n                                             2.5               0.001538   \n                                             5.0               0.009875   \n                                             7.5               0.000456   \n                                             10.0              0.000454   \n                                             25.0              0.000187   \n                                             50.0              0.000099   \n                                             100.0             0.000109   \n                                8e-5 null    1.0               0.106721   \n                                             2.5               0.001087   \n                                             5.0               0.000785   \n                                             7.5               0.001918   \n                                             10.0              0.000878   \n                                             25.0              0.000122   \n                                             50.0              0.000109   \n                                             100.0             0.000000   \n                v1.3.3  t5-base 1e-6 null    1.0               0.000650   \n                                             2.5               0.000744   \n                                             5.0               0.000271   \n                                             7.5               0.000485   \n                                             10.0              0.006987   \n                                             25.0              0.001553   \n                                             50.0              0.001895   \n                                             100.0             0.001939   \n                                4e-5 null    1.0               0.013862   \n                                             2.5               0.011724   \n                                             5.0               0.001490   \n                                             7.5               0.012064   \n                                             10.0              0.007066   \n                                             25.0              0.000009   \n                                             50.0              0.000208   \n                                             100.0             0.000063   \n                                6e-5 null    1.0               0.006089   \n                                             2.5               0.015199   \n                                             5.0               0.029367   \n                                             7.5               0.001986   \n                                             10.0              0.000798   \n                                             25.0              0.000308   \n                                             50.0              0.000063   \n                                             100.0             0.000000   \n                                8e-5 null    1.0               0.087131   \n                                             2.5               0.002948   \n                                             5.0               0.031799   \n                                             7.5               0.000909   \n                                             10.0              0.000747   \n                                             25.0              0.000022   \n                                             50.0              0.000432   \n                                             100.0             0.000063   \n\n                                                              x_avg_negative  \\\n                                                                        mean   \nexperiment      version model   lr   filters train_percentage                  \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0                  0.913333   \n                                     P108    100.0                  0.916896   \n                                     P1082   100.0                  0.927273   \n                                     P1092   100.0                  0.931165   \n                                     P1110   100.0                  0.920952   \n                                     P1174   100.0                  0.929192   \n                                     P118    100.0                  0.927913   \n                                     P1198   100.0                  0.919167   \n                                     P1867   100.0                  0.918788   \n                                     P19     100.0                  0.918973   \n                                     P19.P20 100.0                  0.926593   \n                                     P20     100.0                  0.916970   \n                                     P21     100.0                  0.914494   \n                                     P22     100.0                  0.921115   \n                                     P22.P23 100.0                  0.915620   \n                                     P23     100.0                  0.922493   \n                                     P26     100.0                  0.922018   \n                                     P27     100.0                  0.923907   \n                                     P35     100.0                  0.919042   \n                                     P38     100.0                  0.922078   \n                                     P47     100.0                  0.906284   \n                                     P50     100.0                  0.922453   \n                                     P54     100.0                  0.930148   \n                                     P57     100.0                  0.926612   \n                                     P58     100.0                  0.926178   \n                                     P6      100.0                  0.925052   \n                                     P61     100.0                  0.920936   \n                                     P69     100.0                  0.931707   \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0                    0.000000   \n                                             2.5                    0.000000   \n                                             5.0                    0.000000   \n                                             7.5                    0.000000   \n                                             10.0                   0.000000   \n                                             25.0                   0.000000   \n                                             50.0                   0.000000   \n                                             100.0                  0.325503   \n                                4e-5 null    1.0                    0.000000   \n                                             2.5                    0.839334   \n                                             5.0                    0.931264   \n                                             7.5                    0.945018   \n                                             10.0                   0.941486   \n                                             25.0                   0.944845   \n                                             50.0                   0.944779   \n                                             100.0                  0.945309   \n                                6e-5 null    1.0                    0.000000   \n                                             2.5                    0.908193   \n                                             5.0                    0.935933   \n                                             7.5                    0.940846   \n                                             10.0                   0.942862   \n                                             25.0                   0.945113   \n                                             50.0                   0.945808   \n                                             100.0                  0.945419   \n                                8e-5 null    1.0                    0.008716   \n                                             2.5                    0.937607   \n                                             5.0                    0.941742   \n                                             7.5                    0.942805   \n                                             10.0                   0.944039   \n                                             25.0                   0.945378   \n                                             50.0                   0.945918   \n                                             100.0                  0.945433   \n                v1.3.2  t5-base 1e-6 null    1.0                    0.000000   \n                                             2.5                    0.000000   \n                                             5.0                    0.000000   \n                                             7.5                    0.000000   \n                                             10.0                   0.000000   \n                                             25.0                   0.000000   \n                                             50.0                   0.000000   \n                                             100.0                  0.000000   \n                                4e-5 null    1.0                    0.000000   \n                                             2.5                    0.000000   \n                                             5.0                    0.000000   \n                                             7.5                    0.000000   \n                                             10.0                   0.018102   \n                                             25.0                   0.945446   \n                                             50.0                   0.938236   \n                                             100.0                  0.943558   \n                                6e-5 null    1.0                    0.000000   \n                                             2.5                    0.000000   \n                                             5.0                    0.000000   \n                                             7.5                    0.201721   \n                                             10.0                   0.920650   \n                                             25.0                   0.943704   \n                                             50.0                   0.949983   \n                                             100.0                  0.941953   \n                                8e-5 null    1.0                    0.000000   \n                                             2.5                    0.000000   \n                                             5.0                    0.009063   \n                                             7.5                    0.932870   \n                                             10.0                   0.940503   \n                                             25.0                   0.949506   \n                                             50.0                   0.940997   \n                                             100.0                  0.950299   \n                v1.3.3  t5-base 1e-6 null    1.0                    0.000000   \n                                             2.5                    0.000000   \n                                             5.0                    0.000000   \n                                             7.5                    0.000000   \n                                             10.0                   0.000000   \n                                             25.0                   0.000000   \n                                             50.0                   0.000000   \n                                             100.0                  0.000000   \n                                4e-5 null    1.0                    0.000000   \n                                             2.5                    0.000725   \n                                             5.0                    0.107610   \n                                             7.5                    0.526234   \n                                             10.0                   0.904965   \n                                             25.0                   0.948717   \n                                             50.0                   0.948826   \n                                             100.0                  0.948083   \n                                6e-5 null    1.0                    0.000000   \n                                             2.5                    0.000734   \n                                             5.0                    0.504403   \n                                             7.5                    0.930722   \n                                             10.0                   0.941700   \n                                             25.0                   0.949392   \n                                             50.0                   0.949009   \n                                             100.0                  0.949192   \n                                8e-5 null    1.0                    0.000092   \n                                             2.5                    0.038766   \n                                             5.0                    0.848026   \n                                             7.5                    0.940815   \n                                             10.0                   0.948401   \n                                             25.0                   0.950028   \n                                             50.0                   0.949376   \n                                             100.0                  0.950301   \n\n                                                                         \n                                                                    std  \nexperiment      version model   lr   filters train_percentage            \noperator_filter v1.3.2  t5-base 8e-5 P106    100.0             0.006577  \n                                     P108    100.0             0.002844  \n                                     P1082   100.0             0.003963  \n                                     P1092   100.0             0.003078  \n                                     P1110   100.0             0.004223  \n                                     P1174   100.0             0.007219  \n                                     P118    100.0             0.005413  \n                                     P1198   100.0             0.004855  \n                                     P1867   100.0             0.003193  \n                                     P19     100.0             0.004169  \n                                     P19.P20 100.0             0.008905  \n                                     P20     100.0             0.003674  \n                                     P21     100.0             0.008867  \n                                     P22     100.0             0.009174  \n                                     P22.P23 100.0             0.005044  \n                                     P23     100.0             0.010844  \n                                     P26     100.0             0.004189  \n                                     P27     100.0             0.009193  \n                                     P35     100.0             0.005550  \n                                     P38     100.0             0.005266  \n                                     P47     100.0             0.008043  \n                                     P50     100.0             0.009740  \n                                     P54     100.0             0.011180  \n                                     P57     100.0             0.012686  \n                                     P58     100.0             0.009744  \n                                     P6      100.0             0.012054  \n                                     P61     100.0             0.008376  \n                                     P69     100.0             0.003544  \noperator_sweep  v1.3.1  t5-base 1e-6 null    1.0               0.000000  \n                                             2.5               0.000000  \n                                             5.0               0.000000  \n                                             7.5               0.000000  \n                                             10.0              0.000000  \n                                             25.0              0.000000  \n                                             50.0              0.000000  \n                                             100.0             0.054280  \n                                4e-5 null    1.0               0.000000  \n                                             2.5               0.013386  \n                                             5.0               0.012068  \n                                             7.5               0.011933  \n                                             10.0              0.000455  \n                                             25.0              0.000990  \n                                             50.0              0.000394  \n                                             100.0             0.001213  \n                                6e-5 null    1.0               0.000000  \n                                             2.5               0.009517  \n                                             5.0               0.008561  \n                                             7.5               0.000362  \n                                             10.0              0.001085  \n                                             25.0              0.000830  \n                                             50.0              0.001394  \n                                             100.0             0.001374  \n                                8e-5 null    1.0               0.004533  \n                                             2.5               0.008209  \n                                             5.0               0.001031  \n                                             7.5               0.000338  \n                                             10.0              0.000691  \n                                             25.0              0.000877  \n                                             50.0              0.001186  \n                                             100.0             0.001481  \n                v1.3.2  t5-base 1e-6 null    1.0               0.000000  \n                                             2.5               0.000000  \n                                             5.0               0.000000  \n                                             7.5               0.000000  \n                                             10.0              0.000000  \n                                             25.0              0.000000  \n                                             50.0              0.000000  \n                                             100.0             0.000000  \n                                4e-5 null    1.0               0.000000  \n                                             2.5               0.000000  \n                                             5.0               0.000000  \n                                             7.5               0.000000  \n                                             10.0              0.031354  \n                                             25.0              0.003059  \n                                             50.0              0.011427  \n                                             100.0             0.010062  \n                                6e-5 null    1.0               0.000000  \n                                             2.5               0.000000  \n                                             5.0               0.000000  \n                                             7.5               0.221373  \n                                             10.0              0.004560  \n                                             25.0              0.010076  \n                                             50.0              0.002914  \n                                             100.0             0.008100  \n                                8e-5 null    1.0               0.000000  \n                                             2.5               0.000000  \n                                             5.0               0.008672  \n                                             7.5               0.005202  \n                                             10.0              0.009754  \n                                             25.0              0.002907  \n                                             50.0              0.009755  \n                                             100.0             0.002773  \n                v1.3.3  t5-base 1e-6 null    1.0               0.000000  \n                                             2.5               0.000000  \n                                             5.0               0.000000  \n                                             7.5               0.000000  \n                                             10.0              0.000000  \n                                             25.0              0.000000  \n                                             50.0              0.000000  \n                                             100.0             0.000000  \n                                4e-5 null    1.0               0.000000  \n                                             2.5               0.001030  \n                                             5.0               0.146849  \n                                             7.5               0.015033  \n                                             10.0              0.005379  \n                                             25.0              0.002144  \n                                             50.0              0.001943  \n                                             100.0             0.000159  \n                                6e-5 null    1.0               0.000000  \n                                             2.5               0.000573  \n                                             5.0               0.040412  \n                                             7.5               0.004658  \n                                             10.0              0.002047  \n                                             25.0              0.001738  \n                                             50.0              0.002005  \n                                             100.0             0.001847  \n                                8e-5 null    1.0               0.000159  \n                                             2.5               0.060331  \n                                             5.0               0.071151  \n                                             7.5               0.001348  \n                                             10.0              0.001392  \n                                             25.0              0.001764  \n                                             50.0              0.002398  \n                                             100.0             0.001762  \n\n[124 rows x 69 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">A_EM</th>\n      <th colspan=\"2\" halign=\"left\">EM</th>\n      <th>count_type_negative</th>\n      <th colspan=\"2\" halign=\"left\">prop_P106</th>\n      <th colspan=\"2\" halign=\"left\">prop_P108</th>\n      <th>prop_P1082</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">type_bool</th>\n      <th colspan=\"2\" halign=\"left\">type_count</th>\n      <th colspan=\"2\" halign=\"left\">type_negative</th>\n      <th colspan=\"2\" halign=\"left\">type_set</th>\n      <th colspan=\"2\" halign=\"left\">x_avg_negative</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>amax</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>...</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>experiment</th>\n      <th>version</th>\n      <th>model</th>\n      <th>lr</th>\n      <th>filters</th>\n      <th>train_percentage</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"28\" valign=\"top\">operator_filter</th>\n      <th rowspan=\"28\" valign=\"top\">v1.3.2</th>\n      <th rowspan=\"28\" valign=\"top\">t5-base</th>\n      <th rowspan=\"28\" valign=\"top\">8e-5</th>\n      <th>P106</th>\n      <th>100.0</th>\n      <td>0.754970</td>\n      <td>0.014478</td>\n      <td>0.839766</td>\n      <td>0.007522</td>\n      <td>1100</td>\n      <td>0.491389</td>\n      <td>0.026112</td>\n      <td>0.894531</td>\n      <td>0.046671</td>\n      <td>0.983530</td>\n      <td>...</td>\n      <td>0.993333</td>\n      <td>0.000451</td>\n      <td>0.933151</td>\n      <td>0.012544</td>\n      <td>0.913333</td>\n      <td>0.006577</td>\n      <td>0.765056</td>\n      <td>0.024635</td>\n      <td>0.913333</td>\n      <td>0.006577</td>\n    </tr>\n    <tr>\n      <th>P108</th>\n      <th>100.0</th>\n      <td>0.953100</td>\n      <td>0.004446</td>\n      <td>0.976228</td>\n      <td>0.000914</td>\n      <td>1134</td>\n      <td>0.977262</td>\n      <td>0.002146</td>\n      <td>0.927847</td>\n      <td>0.064082</td>\n      <td>0.984558</td>\n      <td>...</td>\n      <td>0.999834</td>\n      <td>0.000148</td>\n      <td>0.992195</td>\n      <td>0.000452</td>\n      <td>0.916896</td>\n      <td>0.002844</td>\n      <td>0.990330</td>\n      <td>0.000899</td>\n      <td>0.916896</td>\n      <td>0.002844</td>\n    </tr>\n    <tr>\n      <th>P1082</th>\n      <th>100.0</th>\n      <td>0.942811</td>\n      <td>0.001670</td>\n      <td>0.847095</td>\n      <td>0.004081</td>\n      <td>1100</td>\n      <td>0.977533</td>\n      <td>0.000192</td>\n      <td>0.964045</td>\n      <td>0.000704</td>\n      <td>0.455868</td>\n      <td>...</td>\n      <td>0.885527</td>\n      <td>0.025773</td>\n      <td>0.931426</td>\n      <td>0.002710</td>\n      <td>0.927273</td>\n      <td>0.003963</td>\n      <td>0.987711</td>\n      <td>0.000634</td>\n      <td>0.927273</td>\n      <td>0.003963</td>\n    </tr>\n    <tr>\n      <th>P1092</th>\n      <th>100.0</th>\n      <td>0.952921</td>\n      <td>0.002345</td>\n      <td>0.974962</td>\n      <td>0.000425</td>\n      <td>1230</td>\n      <td>0.977490</td>\n      <td>0.001234</td>\n      <td>0.999482</td>\n      <td>0.000897</td>\n      <td>0.987894</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.993459</td>\n      <td>0.000323</td>\n      <td>0.931165</td>\n      <td>0.003078</td>\n      <td>0.988861</td>\n      <td>0.000934</td>\n      <td>0.931165</td>\n      <td>0.003078</td>\n    </tr>\n    <tr>\n      <th>P1110</th>\n      <th>100.0</th>\n      <td>0.954959</td>\n      <td>0.002883</td>\n      <td>0.976806</td>\n      <td>0.000441</td>\n      <td>1155</td>\n      <td>0.978578</td>\n      <td>0.001633</td>\n      <td>0.938811</td>\n      <td>0.008394</td>\n      <td>0.985670</td>\n      <td>...</td>\n      <td>0.999779</td>\n      <td>0.000133</td>\n      <td>0.993321</td>\n      <td>0.000396</td>\n      <td>0.920952</td>\n      <td>0.004223</td>\n      <td>0.990933</td>\n      <td>0.000776</td>\n      <td>0.920952</td>\n      <td>0.004223</td>\n    </tr>\n    <tr>\n      <th>P1174</th>\n      <th>100.0</th>\n      <td>0.952633</td>\n      <td>0.000212</td>\n      <td>0.976313</td>\n      <td>0.000308</td>\n      <td>1230</td>\n      <td>0.978300</td>\n      <td>0.000646</td>\n      <td>0.975465</td>\n      <td>0.021276</td>\n      <td>0.987078</td>\n      <td>...</td>\n      <td>0.999923</td>\n      <td>0.000133</td>\n      <td>0.993664</td>\n      <td>0.001216</td>\n      <td>0.929192</td>\n      <td>0.007219</td>\n      <td>0.990156</td>\n      <td>0.000438</td>\n      <td>0.929192</td>\n      <td>0.007219</td>\n    </tr>\n    <tr>\n      <th>P118</th>\n      <th>100.0</th>\n      <td>0.954618</td>\n      <td>0.001670</td>\n      <td>0.975860</td>\n      <td>0.000652</td>\n      <td>1230</td>\n      <td>0.977852</td>\n      <td>0.001384</td>\n      <td>0.976190</td>\n      <td>0.020620</td>\n      <td>0.987316</td>\n      <td>...</td>\n      <td>0.999419</td>\n      <td>0.000176</td>\n      <td>0.994444</td>\n      <td>0.000405</td>\n      <td>0.927913</td>\n      <td>0.005413</td>\n      <td>0.991036</td>\n      <td>0.000667</td>\n      <td>0.927913</td>\n      <td>0.005413</td>\n    </tr>\n    <tr>\n      <th>P1198</th>\n      <th>100.0</th>\n      <td>0.953627</td>\n      <td>0.001800</td>\n      <td>0.975592</td>\n      <td>0.000731</td>\n      <td>1230</td>\n      <td>0.976782</td>\n      <td>0.001206</td>\n      <td>0.965845</td>\n      <td>0.032399</td>\n      <td>0.986391</td>\n      <td>...</td>\n      <td>0.999772</td>\n      <td>0.000006</td>\n      <td>0.992984</td>\n      <td>0.001085</td>\n      <td>0.919167</td>\n      <td>0.004855</td>\n      <td>0.990083</td>\n      <td>0.000821</td>\n      <td>0.919167</td>\n      <td>0.004855</td>\n    </tr>\n    <tr>\n      <th>P1867</th>\n      <th>100.0</th>\n      <td>0.955196</td>\n      <td>0.000340</td>\n      <td>0.976727</td>\n      <td>0.000414</td>\n      <td>1100</td>\n      <td>0.978413</td>\n      <td>0.000335</td>\n      <td>0.955093</td>\n      <td>0.018666</td>\n      <td>0.985346</td>\n      <td>...</td>\n      <td>0.999812</td>\n      <td>0.000076</td>\n      <td>0.992776</td>\n      <td>0.000883</td>\n      <td>0.918788</td>\n      <td>0.003193</td>\n      <td>0.990584</td>\n      <td>0.000634</td>\n      <td>0.918788</td>\n      <td>0.003193</td>\n    </tr>\n    <tr>\n      <th>P19</th>\n      <th>100.0</th>\n      <td>0.945102</td>\n      <td>0.002089</td>\n      <td>0.952859</td>\n      <td>0.000612</td>\n      <td>1230</td>\n      <td>0.977021</td>\n      <td>0.000263</td>\n      <td>0.953404</td>\n      <td>0.018848</td>\n      <td>0.986309</td>\n      <td>...</td>\n      <td>0.998041</td>\n      <td>0.000106</td>\n      <td>0.992524</td>\n      <td>0.001179</td>\n      <td>0.918973</td>\n      <td>0.004169</td>\n      <td>0.986448</td>\n      <td>0.001148</td>\n      <td>0.918973</td>\n      <td>0.004169</td>\n    </tr>\n    <tr>\n      <th>P19.P20</th>\n      <th>100.0</th>\n      <td>0.933198</td>\n      <td>0.004638</td>\n      <td>0.940664</td>\n      <td>0.001877</td>\n      <td>1230</td>\n      <td>0.975889</td>\n      <td>0.000904</td>\n      <td>0.970048</td>\n      <td>0.051878</td>\n      <td>0.985924</td>\n      <td>...</td>\n      <td>0.992480</td>\n      <td>0.003936</td>\n      <td>0.974775</td>\n      <td>0.006580</td>\n      <td>0.926593</td>\n      <td>0.008905</td>\n      <td>0.980094</td>\n      <td>0.002361</td>\n      <td>0.926593</td>\n      <td>0.008905</td>\n    </tr>\n    <tr>\n      <th>P20</th>\n      <th>100.0</th>\n      <td>0.951906</td>\n      <td>0.001080</td>\n      <td>0.967891</td>\n      <td>0.000802</td>\n      <td>1100</td>\n      <td>0.978459</td>\n      <td>0.001250</td>\n      <td>0.957031</td>\n      <td>0.018632</td>\n      <td>0.985604</td>\n      <td>...</td>\n      <td>0.999848</td>\n      <td>0.000084</td>\n      <td>0.992488</td>\n      <td>0.000298</td>\n      <td>0.916970</td>\n      <td>0.003674</td>\n      <td>0.989653</td>\n      <td>0.000270</td>\n      <td>0.916970</td>\n      <td>0.003674</td>\n    </tr>\n    <tr>\n      <th>P21</th>\n      <th>100.0</th>\n      <td>0.948298</td>\n      <td>0.001349</td>\n      <td>0.900915</td>\n      <td>0.001132</td>\n      <td>1230</td>\n      <td>0.977101</td>\n      <td>0.001760</td>\n      <td>0.977157</td>\n      <td>0.019811</td>\n      <td>0.986187</td>\n      <td>...</td>\n      <td>0.998840</td>\n      <td>0.000906</td>\n      <td>0.917972</td>\n      <td>0.001203</td>\n      <td>0.914494</td>\n      <td>0.008867</td>\n      <td>0.843108</td>\n      <td>0.002044</td>\n      <td>0.914494</td>\n      <td>0.008867</td>\n    </tr>\n    <tr>\n      <th>P22</th>\n      <th>100.0</th>\n      <td>0.955194</td>\n      <td>0.000602</td>\n      <td>0.974537</td>\n      <td>0.000669</td>\n      <td>1230</td>\n      <td>0.976181</td>\n      <td>0.001418</td>\n      <td>0.982770</td>\n      <td>0.025381</td>\n      <td>0.985103</td>\n      <td>...</td>\n      <td>0.999349</td>\n      <td>0.000141</td>\n      <td>0.992944</td>\n      <td>0.001349</td>\n      <td>0.921115</td>\n      <td>0.009174</td>\n      <td>0.991674</td>\n      <td>0.000297</td>\n      <td>0.921115</td>\n      <td>0.009174</td>\n    </tr>\n    <tr>\n      <th>P22.P23</th>\n      <th>100.0</th>\n      <td>0.951885</td>\n      <td>0.000769</td>\n      <td>0.974084</td>\n      <td>0.000331</td>\n      <td>1134</td>\n      <td>0.975900</td>\n      <td>0.002300</td>\n      <td>0.969551</td>\n      <td>0.041886</td>\n      <td>0.984436</td>\n      <td>...</td>\n      <td>0.999588</td>\n      <td>0.000147</td>\n      <td>0.991912</td>\n      <td>0.000316</td>\n      <td>0.915620</td>\n      <td>0.005044</td>\n      <td>0.990394</td>\n      <td>0.000430</td>\n      <td>0.915620</td>\n      <td>0.005044</td>\n    </tr>\n    <tr>\n      <th>P23</th>\n      <th>100.0</th>\n      <td>0.955052</td>\n      <td>0.000866</td>\n      <td>0.976334</td>\n      <td>0.000960</td>\n      <td>1230</td>\n      <td>0.976142</td>\n      <td>0.001578</td>\n      <td>0.983736</td>\n      <td>0.026106</td>\n      <td>0.984985</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.993156</td>\n      <td>0.001088</td>\n      <td>0.922493</td>\n      <td>0.010844</td>\n      <td>0.991003</td>\n      <td>0.000275</td>\n      <td>0.922493</td>\n      <td>0.010844</td>\n    </tr>\n    <tr>\n      <th>P26</th>\n      <th>100.0</th>\n      <td>0.952943</td>\n      <td>0.001795</td>\n      <td>0.975180</td>\n      <td>0.000964</td>\n      <td>1230</td>\n      <td>0.977749</td>\n      <td>0.001541</td>\n      <td>0.979167</td>\n      <td>0.036084</td>\n      <td>0.986753</td>\n      <td>...</td>\n      <td>0.999250</td>\n      <td>0.000677</td>\n      <td>0.994355</td>\n      <td>0.000538</td>\n      <td>0.922018</td>\n      <td>0.004189</td>\n      <td>0.990064</td>\n      <td>0.000843</td>\n      <td>0.922018</td>\n      <td>0.004189</td>\n    </tr>\n    <tr>\n      <th>P27</th>\n      <th>100.0</th>\n      <td>0.928584</td>\n      <td>0.001094</td>\n      <td>0.960329</td>\n      <td>0.000318</td>\n      <td>1230</td>\n      <td>0.978294</td>\n      <td>0.000982</td>\n      <td>0.974432</td>\n      <td>0.023254</td>\n      <td>0.986267</td>\n      <td>...</td>\n      <td>0.999933</td>\n      <td>0.000099</td>\n      <td>0.990530</td>\n      <td>0.002044</td>\n      <td>0.923907</td>\n      <td>0.009193</td>\n      <td>0.954982</td>\n      <td>0.002526</td>\n      <td>0.923907</td>\n      <td>0.009193</td>\n    </tr>\n    <tr>\n      <th>P35</th>\n      <th>100.0</th>\n      <td>0.954482</td>\n      <td>0.002664</td>\n      <td>0.975971</td>\n      <td>0.001272</td>\n      <td>1155</td>\n      <td>0.976099</td>\n      <td>0.002891</td>\n      <td>0.978960</td>\n      <td>0.024137</td>\n      <td>0.984434</td>\n      <td>...</td>\n      <td>0.999908</td>\n      <td>0.000159</td>\n      <td>0.992689</td>\n      <td>0.000612</td>\n      <td>0.919042</td>\n      <td>0.005550</td>\n      <td>0.991103</td>\n      <td>0.000961</td>\n      <td>0.919042</td>\n      <td>0.005550</td>\n    </tr>\n    <tr>\n      <th>P38</th>\n      <th>100.0</th>\n      <td>0.955286</td>\n      <td>0.000771</td>\n      <td>0.976064</td>\n      <td>0.000998</td>\n      <td>1155</td>\n      <td>0.979054</td>\n      <td>0.000499</td>\n      <td>0.946970</td>\n      <td>0.007256</td>\n      <td>0.986068</td>\n      <td>...</td>\n      <td>0.999856</td>\n      <td>0.000031</td>\n      <td>0.993075</td>\n      <td>0.000689</td>\n      <td>0.922078</td>\n      <td>0.005266</td>\n      <td>0.991137</td>\n      <td>0.000857</td>\n      <td>0.922078</td>\n      <td>0.005266</td>\n    </tr>\n    <tr>\n      <th>P47</th>\n      <th>100.0</th>\n      <td>0.927121</td>\n      <td>0.002096</td>\n      <td>0.953634</td>\n      <td>0.000980</td>\n      <td>1230</td>\n      <td>0.976123</td>\n      <td>0.003724</td>\n      <td>0.980322</td>\n      <td>0.029600</td>\n      <td>0.985711</td>\n      <td>...</td>\n      <td>0.989428</td>\n      <td>0.000881</td>\n      <td>0.972459</td>\n      <td>0.004417</td>\n      <td>0.906284</td>\n      <td>0.008043</td>\n      <td>0.975888</td>\n      <td>0.002388</td>\n      <td>0.906284</td>\n      <td>0.008043</td>\n    </tr>\n    <tr>\n      <th>P50</th>\n      <th>100.0</th>\n      <td>0.954126</td>\n      <td>0.001604</td>\n      <td>0.975980</td>\n      <td>0.000353</td>\n      <td>1230</td>\n      <td>0.977726</td>\n      <td>0.001316</td>\n      <td>0.971331</td>\n      <td>0.024376</td>\n      <td>0.986248</td>\n      <td>...</td>\n      <td>0.999946</td>\n      <td>0.000093</td>\n      <td>0.992834</td>\n      <td>0.001250</td>\n      <td>0.922453</td>\n      <td>0.009740</td>\n      <td>0.990698</td>\n      <td>0.000703</td>\n      <td>0.922453</td>\n      <td>0.009740</td>\n    </tr>\n    <tr>\n      <th>P54</th>\n      <th>100.0</th>\n      <td>0.946459</td>\n      <td>0.001970</td>\n      <td>0.947976</td>\n      <td>0.000344</td>\n      <td>1230</td>\n      <td>0.979096</td>\n      <td>0.000656</td>\n      <td>0.996564</td>\n      <td>0.001139</td>\n      <td>0.986973</td>\n      <td>...</td>\n      <td>0.998759</td>\n      <td>0.000103</td>\n      <td>0.992627</td>\n      <td>0.000857</td>\n      <td>0.930148</td>\n      <td>0.011180</td>\n      <td>0.989630</td>\n      <td>0.001775</td>\n      <td>0.930148</td>\n      <td>0.011180</td>\n    </tr>\n    <tr>\n      <th>P57</th>\n      <th>100.0</th>\n      <td>0.952945</td>\n      <td>0.000551</td>\n      <td>0.976645</td>\n      <td>0.000843</td>\n      <td>1230</td>\n      <td>0.978870</td>\n      <td>0.001167</td>\n      <td>0.966294</td>\n      <td>0.032525</td>\n      <td>0.986372</td>\n      <td>...</td>\n      <td>0.999819</td>\n      <td>0.000227</td>\n      <td>0.992565</td>\n      <td>0.001023</td>\n      <td>0.926612</td>\n      <td>0.012686</td>\n      <td>0.990663</td>\n      <td>0.000475</td>\n      <td>0.926612</td>\n      <td>0.012686</td>\n    </tr>\n    <tr>\n      <th>P58</th>\n      <th>100.0</th>\n      <td>0.954301</td>\n      <td>0.003746</td>\n      <td>0.976422</td>\n      <td>0.000545</td>\n      <td>1230</td>\n      <td>0.979016</td>\n      <td>0.000488</td>\n      <td>0.967456</td>\n      <td>0.029597</td>\n      <td>0.986257</td>\n      <td>...</td>\n      <td>0.999669</td>\n      <td>0.000168</td>\n      <td>0.993552</td>\n      <td>0.000948</td>\n      <td>0.926178</td>\n      <td>0.009744</td>\n      <td>0.991201</td>\n      <td>0.000544</td>\n      <td>0.926178</td>\n      <td>0.009744</td>\n    </tr>\n    <tr>\n      <th>P6</th>\n      <th>100.0</th>\n      <td>0.954104</td>\n      <td>0.002279</td>\n      <td>0.976367</td>\n      <td>0.000673</td>\n      <td>1230</td>\n      <td>0.977753</td>\n      <td>0.002099</td>\n      <td>0.976744</td>\n      <td>0.035777</td>\n      <td>0.985903</td>\n      <td>...</td>\n      <td>0.999840</td>\n      <td>0.000182</td>\n      <td>0.991614</td>\n      <td>0.001026</td>\n      <td>0.925052</td>\n      <td>0.012054</td>\n      <td>0.991632</td>\n      <td>0.000524</td>\n      <td>0.925052</td>\n      <td>0.012054</td>\n    </tr>\n    <tr>\n      <th>P61</th>\n      <th>100.0</th>\n      <td>0.950638</td>\n      <td>0.002476</td>\n      <td>0.973881</td>\n      <td>0.000866</td>\n      <td>1230</td>\n      <td>0.978329</td>\n      <td>0.000943</td>\n      <td>0.953981</td>\n      <td>0.016001</td>\n      <td>0.986158</td>\n      <td>...</td>\n      <td>0.999771</td>\n      <td>0.000236</td>\n      <td>0.993036</td>\n      <td>0.000876</td>\n      <td>0.920936</td>\n      <td>0.008376</td>\n      <td>0.983419</td>\n      <td>0.000863</td>\n      <td>0.920936</td>\n      <td>0.008376</td>\n    </tr>\n    <tr>\n      <th>P69</th>\n      <th>100.0</th>\n      <td>0.949984</td>\n      <td>0.000832</td>\n      <td>0.972919</td>\n      <td>0.000205</td>\n      <td>1230</td>\n      <td>0.977421</td>\n      <td>0.000587</td>\n      <td>0.986961</td>\n      <td>0.019711</td>\n      <td>0.987633</td>\n      <td>...</td>\n      <td>0.999880</td>\n      <td>0.000105</td>\n      <td>0.994078</td>\n      <td>0.000121</td>\n      <td>0.931707</td>\n      <td>0.003544</td>\n      <td>0.990527</td>\n      <td>0.000523</td>\n      <td>0.931707</td>\n      <td>0.003544</td>\n    </tr>\n    <tr>\n      <th rowspan=\"96\" valign=\"top\">operator_sweep</th>\n      <th rowspan=\"32\" valign=\"top\">v1.3.1</th>\n      <th rowspan=\"32\" valign=\"top\">t5-base</th>\n      <th rowspan=\"8\" valign=\"top\">1e-6</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.380243</td>\n      <td>0.000146</td>\n      <td>0.041213</td>\n      <td>0.000052</td>\n      <td>6257</td>\n      <td>0.039213</td>\n      <td>0.000470</td>\n      <td>0.023005</td>\n      <td>0.002479</td>\n      <td>0.047451</td>\n      <td>...</td>\n      <td>0.191557</td>\n      <td>0.000916</td>\n      <td>0.046812</td>\n      <td>0.000529</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.062254</td>\n      <td>0.001139</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.380874</td>\n      <td>0.000291</td>\n      <td>0.042826</td>\n      <td>0.000624</td>\n      <td>6257</td>\n      <td>0.040050</td>\n      <td>0.000155</td>\n      <td>0.024557</td>\n      <td>0.001648</td>\n      <td>0.049664</td>\n      <td>...</td>\n      <td>0.194997</td>\n      <td>0.002685</td>\n      <td>0.049046</td>\n      <td>0.000599</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.063627</td>\n      <td>0.001354</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.382641</td>\n      <td>0.001350</td>\n      <td>0.045374</td>\n      <td>0.002111</td>\n      <td>6263</td>\n      <td>0.043461</td>\n      <td>0.002787</td>\n      <td>0.021103</td>\n      <td>0.000321</td>\n      <td>0.054002</td>\n      <td>...</td>\n      <td>0.191697</td>\n      <td>0.004135</td>\n      <td>0.052486</td>\n      <td>0.002201</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.066124</td>\n      <td>0.002538</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.384913</td>\n      <td>0.001676</td>\n      <td>0.051845</td>\n      <td>0.007734</td>\n      <td>6208</td>\n      <td>0.050306</td>\n      <td>0.011671</td>\n      <td>0.025490</td>\n      <td>0.001766</td>\n      <td>0.063396</td>\n      <td>...</td>\n      <td>0.218801</td>\n      <td>0.025612</td>\n      <td>0.060131</td>\n      <td>0.010469</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.075616</td>\n      <td>0.012597</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.384661</td>\n      <td>0.002376</td>\n      <td>0.055653</td>\n      <td>0.011561</td>\n      <td>6263</td>\n      <td>0.055553</td>\n      <td>0.016771</td>\n      <td>0.025552</td>\n      <td>0.003715</td>\n      <td>0.065923</td>\n      <td>...</td>\n      <td>0.232274</td>\n      <td>0.044068</td>\n      <td>0.066910</td>\n      <td>0.015950</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.082768</td>\n      <td>0.017823</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.380916</td>\n      <td>0.000334</td>\n      <td>0.170751</td>\n      <td>0.006059</td>\n      <td>6222</td>\n      <td>0.206866</td>\n      <td>0.007462</td>\n      <td>0.148850</td>\n      <td>0.004259</td>\n      <td>0.180863</td>\n      <td>...</td>\n      <td>0.531926</td>\n      <td>0.005527</td>\n      <td>0.316094</td>\n      <td>0.009004</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.398260</td>\n      <td>0.016694</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.383272</td>\n      <td>0.001495</td>\n      <td>0.208623</td>\n      <td>0.010296</td>\n      <td>6263</td>\n      <td>0.235983</td>\n      <td>0.015230</td>\n      <td>0.143019</td>\n      <td>0.004857</td>\n      <td>0.259124</td>\n      <td>...</td>\n      <td>0.530409</td>\n      <td>0.004835</td>\n      <td>0.348668</td>\n      <td>0.020523</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.440616</td>\n      <td>0.019064</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.396104</td>\n      <td>0.000073</td>\n      <td>0.526257</td>\n      <td>0.020271</td>\n      <td>6257</td>\n      <td>0.546379</td>\n      <td>0.034126</td>\n      <td>0.421990</td>\n      <td>0.033327</td>\n      <td>0.595265</td>\n      <td>...</td>\n      <td>0.756355</td>\n      <td>0.008822</td>\n      <td>0.615164</td>\n      <td>0.008699</td>\n      <td>0.325503</td>\n      <td>0.054280</td>\n      <td>0.623933</td>\n      <td>0.010344</td>\n      <td>0.325503</td>\n      <td>0.054280</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">4e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.384619</td>\n      <td>0.000073</td>\n      <td>0.228990</td>\n      <td>0.004295</td>\n      <td>6257</td>\n      <td>0.241744</td>\n      <td>0.010761</td>\n      <td>0.160332</td>\n      <td>0.015633</td>\n      <td>0.305568</td>\n      <td>...</td>\n      <td>0.495495</td>\n      <td>0.023697</td>\n      <td>0.403484</td>\n      <td>0.005559</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.476101</td>\n      <td>0.011279</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.388826</td>\n      <td>0.000386</td>\n      <td>0.746471</td>\n      <td>0.010281</td>\n      <td>6222</td>\n      <td>0.759413</td>\n      <td>0.009867</td>\n      <td>0.756808</td>\n      <td>0.023432</td>\n      <td>0.654618</td>\n      <td>...</td>\n      <td>0.768369</td>\n      <td>0.005162</td>\n      <td>0.574301</td>\n      <td>0.002512</td>\n      <td>0.839334</td>\n      <td>0.013386</td>\n      <td>0.605557</td>\n      <td>0.011443</td>\n      <td>0.839334</td>\n      <td>0.013386</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.390382</td>\n      <td>0.000126</td>\n      <td>0.806858</td>\n      <td>0.003599</td>\n      <td>6222</td>\n      <td>0.799254</td>\n      <td>0.001700</td>\n      <td>0.866730</td>\n      <td>0.027818</td>\n      <td>0.728546</td>\n      <td>...</td>\n      <td>0.807301</td>\n      <td>0.004798</td>\n      <td>0.581171</td>\n      <td>0.001270</td>\n      <td>0.931264</td>\n      <td>0.012068</td>\n      <td>0.655588</td>\n      <td>0.005547</td>\n      <td>0.931264</td>\n      <td>0.012068</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.422396</td>\n      <td>0.055121</td>\n      <td>0.823265</td>\n      <td>0.014962</td>\n      <td>6257</td>\n      <td>0.800128</td>\n      <td>0.001809</td>\n      <td>0.884167</td>\n      <td>0.026481</td>\n      <td>0.787859</td>\n      <td>...</td>\n      <td>0.815598</td>\n      <td>0.005837</td>\n      <td>0.598663</td>\n      <td>0.027640</td>\n      <td>0.945018</td>\n      <td>0.011933</td>\n      <td>0.673806</td>\n      <td>0.019697</td>\n      <td>0.945018</td>\n      <td>0.011933</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.981201</td>\n      <td>0.010968</td>\n      <td>0.953880</td>\n      <td>0.002602</td>\n      <td>6263</td>\n      <td>0.953012</td>\n      <td>0.004947</td>\n      <td>0.923633</td>\n      <td>0.010963</td>\n      <td>0.937748</td>\n      <td>...</td>\n      <td>0.913390</td>\n      <td>0.000447</td>\n      <td>0.969913</td>\n      <td>0.013042</td>\n      <td>0.941486</td>\n      <td>0.000455</td>\n      <td>0.983928</td>\n      <td>0.009025</td>\n      <td>0.941486</td>\n      <td>0.000455</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.995947</td>\n      <td>0.000485</td>\n      <td>0.965382</td>\n      <td>0.000099</td>\n      <td>6263</td>\n      <td>0.954668</td>\n      <td>0.003499</td>\n      <td>0.994043</td>\n      <td>0.006184</td>\n      <td>0.955069</td>\n      <td>...</td>\n      <td>0.999884</td>\n      <td>0.000200</td>\n      <td>0.999292</td>\n      <td>0.000622</td>\n      <td>0.944845</td>\n      <td>0.000990</td>\n      <td>0.999435</td>\n      <td>0.000421</td>\n      <td>0.944845</td>\n      <td>0.000990</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.998023</td>\n      <td>0.000318</td>\n      <td>0.966125</td>\n      <td>0.000054</td>\n      <td>6263</td>\n      <td>0.956020</td>\n      <td>0.003883</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.949566</td>\n      <td>...</td>\n      <td>0.999884</td>\n      <td>0.000200</td>\n      <td>0.999786</td>\n      <td>0.000371</td>\n      <td>0.944779</td>\n      <td>0.000394</td>\n      <td>0.999885</td>\n      <td>0.000112</td>\n      <td>0.944779</td>\n      <td>0.000394</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999285</td>\n      <td>0.000131</td>\n      <td>0.966267</td>\n      <td>0.000074</td>\n      <td>6257</td>\n      <td>0.955644</td>\n      <td>0.002808</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.955630</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999840</td>\n      <td>0.000277</td>\n      <td>0.945309</td>\n      <td>0.001213</td>\n      <td>0.999899</td>\n      <td>0.000175</td>\n      <td>0.945309</td>\n      <td>0.001213</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">6e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.384703</td>\n      <td>0.000379</td>\n      <td>0.232471</td>\n      <td>0.002669</td>\n      <td>6263</td>\n      <td>0.243625</td>\n      <td>0.007558</td>\n      <td>0.161099</td>\n      <td>0.027606</td>\n      <td>0.292736</td>\n      <td>...</td>\n      <td>0.474761</td>\n      <td>0.004422</td>\n      <td>0.415279</td>\n      <td>0.012745</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.490919</td>\n      <td>0.011099</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.390340</td>\n      <td>0.000193</td>\n      <td>0.795143</td>\n      <td>0.004621</td>\n      <td>6263</td>\n      <td>0.792601</td>\n      <td>0.001448</td>\n      <td>0.835459</td>\n      <td>0.018879</td>\n      <td>0.703469</td>\n      <td>...</td>\n      <td>0.795048</td>\n      <td>0.006294</td>\n      <td>0.579990</td>\n      <td>0.001559</td>\n      <td>0.908193</td>\n      <td>0.009517</td>\n      <td>0.646480</td>\n      <td>0.005910</td>\n      <td>0.908193</td>\n      <td>0.009517</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.390340</td>\n      <td>0.000146</td>\n      <td>0.812025</td>\n      <td>0.004494</td>\n      <td>6222</td>\n      <td>0.800264</td>\n      <td>0.001624</td>\n      <td>0.876449</td>\n      <td>0.030592</td>\n      <td>0.733651</td>\n      <td>...</td>\n      <td>0.808461</td>\n      <td>0.003394</td>\n      <td>0.581706</td>\n      <td>0.002632</td>\n      <td>0.935933</td>\n      <td>0.008561</td>\n      <td>0.658870</td>\n      <td>0.004420</td>\n      <td>0.935933</td>\n      <td>0.008561</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.990365</td>\n      <td>0.002365</td>\n      <td>0.956236</td>\n      <td>0.001150</td>\n      <td>6263</td>\n      <td>0.949401</td>\n      <td>0.003261</td>\n      <td>0.936016</td>\n      <td>0.010863</td>\n      <td>0.929257</td>\n      <td>...</td>\n      <td>0.913242</td>\n      <td>0.000792</td>\n      <td>0.967272</td>\n      <td>0.010831</td>\n      <td>0.940846</td>\n      <td>0.000362</td>\n      <td>0.994222</td>\n      <td>0.001016</td>\n      <td>0.940846</td>\n      <td>0.000362</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.994288</td>\n      <td>0.000492</td>\n      <td>0.961648</td>\n      <td>0.001317</td>\n      <td>6257</td>\n      <td>0.954003</td>\n      <td>0.003921</td>\n      <td>0.966642</td>\n      <td>0.002667</td>\n      <td>0.953119</td>\n      <td>...</td>\n      <td>0.937056</td>\n      <td>0.038813</td>\n      <td>0.999136</td>\n      <td>0.001439</td>\n      <td>0.942862</td>\n      <td>0.001085</td>\n      <td>0.999220</td>\n      <td>0.000144</td>\n      <td>0.942862</td>\n      <td>0.001085</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.996676</td>\n      <td>0.000131</td>\n      <td>0.965721</td>\n      <td>0.000079</td>\n      <td>6263</td>\n      <td>0.955939</td>\n      <td>0.003825</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.953132</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999601</td>\n      <td>0.000349</td>\n      <td>0.945113</td>\n      <td>0.000830</td>\n      <td>0.999788</td>\n      <td>0.000221</td>\n      <td>0.945113</td>\n      <td>0.000830</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.998948</td>\n      <td>0.000193</td>\n      <td>0.966130</td>\n      <td>0.000313</td>\n      <td>6257</td>\n      <td>0.957265</td>\n      <td>0.002808</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.957217</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.945808</td>\n      <td>0.001394</td>\n      <td>0.999899</td>\n      <td>0.000175</td>\n      <td>0.945808</td>\n      <td>0.001394</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999243</td>\n      <td>0.000000</td>\n      <td>0.966339</td>\n      <td>0.000084</td>\n      <td>6257</td>\n      <td>0.957057</td>\n      <td>0.002646</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.953608</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999840</td>\n      <td>0.000277</td>\n      <td>0.945419</td>\n      <td>0.001374</td>\n      <td>0.999858</td>\n      <td>0.000152</td>\n      <td>0.945419</td>\n      <td>0.001374</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">8e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.392513</td>\n      <td>0.001823</td>\n      <td>0.348405</td>\n      <td>0.020867</td>\n      <td>6263</td>\n      <td>0.371492</td>\n      <td>0.016044</td>\n      <td>0.214062</td>\n      <td>0.028763</td>\n      <td>0.514929</td>\n      <td>...</td>\n      <td>0.553214</td>\n      <td>0.044221</td>\n      <td>0.782095</td>\n      <td>0.052298</td>\n      <td>0.008716</td>\n      <td>0.004533</td>\n      <td>0.603892</td>\n      <td>0.042609</td>\n      <td>0.008716</td>\n      <td>0.004533</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.390298</td>\n      <td>0.000073</td>\n      <td>0.808818</td>\n      <td>0.003129</td>\n      <td>6208</td>\n      <td>0.799982</td>\n      <td>0.004591</td>\n      <td>0.870746</td>\n      <td>0.003048</td>\n      <td>0.732833</td>\n      <td>...</td>\n      <td>0.810549</td>\n      <td>0.003014</td>\n      <td>0.580590</td>\n      <td>0.001689</td>\n      <td>0.937607</td>\n      <td>0.008209</td>\n      <td>0.658844</td>\n      <td>0.001021</td>\n      <td>0.937607</td>\n      <td>0.008209</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.939287</td>\n      <td>0.068724</td>\n      <td>0.952946</td>\n      <td>0.005580</td>\n      <td>6263</td>\n      <td>0.951326</td>\n      <td>0.003431</td>\n      <td>0.945577</td>\n      <td>0.022519</td>\n      <td>0.932475</td>\n      <td>...</td>\n      <td>0.913331</td>\n      <td>0.001491</td>\n      <td>0.964156</td>\n      <td>0.023260</td>\n      <td>0.941742</td>\n      <td>0.001031</td>\n      <td>0.975043</td>\n      <td>0.019100</td>\n      <td>0.941742</td>\n      <td>0.001031</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.994248</td>\n      <td>0.000327</td>\n      <td>0.960975</td>\n      <td>0.002140</td>\n      <td>6222</td>\n      <td>0.955488</td>\n      <td>0.001018</td>\n      <td>0.968340</td>\n      <td>0.012084</td>\n      <td>0.948089</td>\n      <td>...</td>\n      <td>0.939725</td>\n      <td>0.037276</td>\n      <td>0.992962</td>\n      <td>0.008747</td>\n      <td>0.942805</td>\n      <td>0.000338</td>\n      <td>0.998769</td>\n      <td>0.000555</td>\n      <td>0.942805</td>\n      <td>0.000338</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.995414</td>\n      <td>0.000159</td>\n      <td>0.964497</td>\n      <td>0.000279</td>\n      <td>6257</td>\n      <td>0.956381</td>\n      <td>0.002042</td>\n      <td>0.981634</td>\n      <td>0.008476</td>\n      <td>0.957167</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999334</td>\n      <td>0.001154</td>\n      <td>0.944039</td>\n      <td>0.000691</td>\n      <td>0.999754</td>\n      <td>0.000147</td>\n      <td>0.944039</td>\n      <td>0.000691</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.997055</td>\n      <td>0.000833</td>\n      <td>0.965724</td>\n      <td>0.000384</td>\n      <td>6257</td>\n      <td>0.956970</td>\n      <td>0.002552</td>\n      <td>0.998168</td>\n      <td>0.003172</td>\n      <td>0.957217</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999840</td>\n      <td>0.000277</td>\n      <td>0.945378</td>\n      <td>0.000877</td>\n      <td>0.999721</td>\n      <td>0.000193</td>\n      <td>0.945378</td>\n      <td>0.000877</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.998591</td>\n      <td>0.000675</td>\n      <td>0.966215</td>\n      <td>0.000125</td>\n      <td>6222</td>\n      <td>0.958531</td>\n      <td>0.000321</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.955237</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.945918</td>\n      <td>0.001186</td>\n      <td>0.999960</td>\n      <td>0.000048</td>\n      <td>0.945918</td>\n      <td>0.001186</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.998759</td>\n      <td>0.000794</td>\n      <td>0.966109</td>\n      <td>0.000413</td>\n      <td>6263</td>\n      <td>0.954815</td>\n      <td>0.003738</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.955069</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999571</td>\n      <td>0.000407</td>\n      <td>0.945433</td>\n      <td>0.001481</td>\n      <td>0.999718</td>\n      <td>0.000272</td>\n      <td>0.945433</td>\n      <td>0.001481</td>\n    </tr>\n    <tr>\n      <th rowspan=\"32\" valign=\"top\">v1.3.2</th>\n      <th rowspan=\"32\" valign=\"top\">t5-base</th>\n      <th rowspan=\"8\" valign=\"top\">1e-6</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.462948</td>\n      <td>0.000050</td>\n      <td>0.077077</td>\n      <td>0.000078</td>\n      <td>2092</td>\n      <td>0.073738</td>\n      <td>0.001212</td>\n      <td>0.077746</td>\n      <td>0.010702</td>\n      <td>0.076326</td>\n      <td>...</td>\n      <td>0.190641</td>\n      <td>0.000987</td>\n      <td>0.046980</td>\n      <td>0.000111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.061871</td>\n      <td>0.000907</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.464575</td>\n      <td>0.001133</td>\n      <td>0.080102</td>\n      <td>0.001253</td>\n      <td>2079</td>\n      <td>0.076735</td>\n      <td>0.001472</td>\n      <td>0.073633</td>\n      <td>0.000703</td>\n      <td>0.080606</td>\n      <td>...</td>\n      <td>0.195520</td>\n      <td>0.001999</td>\n      <td>0.049765</td>\n      <td>0.001158</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.063946</td>\n      <td>0.001080</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.466638</td>\n      <td>0.003062</td>\n      <td>0.083645</td>\n      <td>0.004766</td>\n      <td>2234</td>\n      <td>0.080212</td>\n      <td>0.006571</td>\n      <td>0.077846</td>\n      <td>0.005636</td>\n      <td>0.084599</td>\n      <td>...</td>\n      <td>0.198294</td>\n      <td>0.007490</td>\n      <td>0.052316</td>\n      <td>0.003143</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.066863</td>\n      <td>0.003832</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.468119</td>\n      <td>0.002029</td>\n      <td>0.085739</td>\n      <td>0.003582</td>\n      <td>2092</td>\n      <td>0.082883</td>\n      <td>0.004245</td>\n      <td>0.082146</td>\n      <td>0.012501</td>\n      <td>0.086540</td>\n      <td>...</td>\n      <td>0.202690</td>\n      <td>0.004252</td>\n      <td>0.053550</td>\n      <td>0.002117</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.067979</td>\n      <td>0.002489</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.466783</td>\n      <td>0.000133</td>\n      <td>0.083929</td>\n      <td>0.000053</td>\n      <td>2234</td>\n      <td>0.080235</td>\n      <td>0.001673</td>\n      <td>0.078689</td>\n      <td>0.005318</td>\n      <td>0.085397</td>\n      <td>...</td>\n      <td>0.198087</td>\n      <td>0.002663</td>\n      <td>0.052982</td>\n      <td>0.000487</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.066711</td>\n      <td>0.001028</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.470007</td>\n      <td>0.000252</td>\n      <td>0.341837</td>\n      <td>0.025981</td>\n      <td>2234</td>\n      <td>0.383023</td>\n      <td>0.027873</td>\n      <td>0.391147</td>\n      <td>0.032436</td>\n      <td>0.345434</td>\n      <td>...</td>\n      <td>0.630797</td>\n      <td>0.022017</td>\n      <td>0.326287</td>\n      <td>0.035984</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.386294</td>\n      <td>0.044967</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.472157</td>\n      <td>0.000261</td>\n      <td>0.420214</td>\n      <td>0.000821</td>\n      <td>2234</td>\n      <td>0.426132</td>\n      <td>0.014083</td>\n      <td>0.456882</td>\n      <td>0.017341</td>\n      <td>0.416306</td>\n      <td>...</td>\n      <td>0.630308</td>\n      <td>0.011126</td>\n      <td>0.441135</td>\n      <td>0.002088</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.472227</td>\n      <td>0.003505</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.489383</td>\n      <td>0.000580</td>\n      <td>0.709962</td>\n      <td>0.003691</td>\n      <td>2136</td>\n      <td>0.748429</td>\n      <td>0.004330</td>\n      <td>0.582720</td>\n      <td>0.001927</td>\n      <td>0.794581</td>\n      <td>...</td>\n      <td>0.904271</td>\n      <td>0.005273</td>\n      <td>0.712516</td>\n      <td>0.002010</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.758248</td>\n      <td>0.012535</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">4e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.472041</td>\n      <td>0.000363</td>\n      <td>0.418474</td>\n      <td>0.007530</td>\n      <td>2234</td>\n      <td>0.422248</td>\n      <td>0.006603</td>\n      <td>0.438936</td>\n      <td>0.014309</td>\n      <td>0.476682</td>\n      <td>...</td>\n      <td>0.642116</td>\n      <td>0.021514</td>\n      <td>0.414282</td>\n      <td>0.011914</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.482378</td>\n      <td>0.014521</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.489005</td>\n      <td>0.000828</td>\n      <td>0.711520</td>\n      <td>0.003204</td>\n      <td>2234</td>\n      <td>0.745350</td>\n      <td>0.010480</td>\n      <td>0.601248</td>\n      <td>0.020891</td>\n      <td>0.801295</td>\n      <td>...</td>\n      <td>0.908114</td>\n      <td>0.005122</td>\n      <td>0.726891</td>\n      <td>0.021974</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.755259</td>\n      <td>0.022898</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.491358</td>\n      <td>0.000266</td>\n      <td>0.728150</td>\n      <td>0.000281</td>\n      <td>2234</td>\n      <td>0.745291</td>\n      <td>0.010715</td>\n      <td>0.599241</td>\n      <td>0.020474</td>\n      <td>0.796113</td>\n      <td>...</td>\n      <td>0.912679</td>\n      <td>0.000699</td>\n      <td>0.718029</td>\n      <td>0.000530</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.829883</td>\n      <td>0.001111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.805655</td>\n      <td>0.067554</td>\n      <td>0.807844</td>\n      <td>0.004672</td>\n      <td>2092</td>\n      <td>0.823703</td>\n      <td>0.005740</td>\n      <td>0.702010</td>\n      <td>0.035752</td>\n      <td>0.904665</td>\n      <td>...</td>\n      <td>0.999773</td>\n      <td>0.000168</td>\n      <td>0.998770</td>\n      <td>0.000601</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.933072</td>\n      <td>0.026861</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.996009</td>\n      <td>0.000798</td>\n      <td>0.821720</td>\n      <td>0.004331</td>\n      <td>2136</td>\n      <td>0.842933</td>\n      <td>0.008241</td>\n      <td>0.681029</td>\n      <td>0.008786</td>\n      <td>0.908077</td>\n      <td>...</td>\n      <td>0.999980</td>\n      <td>0.000034</td>\n      <td>0.998828</td>\n      <td>0.000201</td>\n      <td>0.018102</td>\n      <td>0.031354</td>\n      <td>0.998661</td>\n      <td>0.000701</td>\n      <td>0.018102</td>\n      <td>0.031354</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.997400</td>\n      <td>0.000233</td>\n      <td>0.980566</td>\n      <td>0.000304</td>\n      <td>2234</td>\n      <td>0.985115</td>\n      <td>0.003317</td>\n      <td>0.977678</td>\n      <td>0.020248</td>\n      <td>0.990176</td>\n      <td>...</td>\n      <td>0.999980</td>\n      <td>0.000035</td>\n      <td>0.999230</td>\n      <td>0.000209</td>\n      <td>0.945446</td>\n      <td>0.003059</td>\n      <td>0.999549</td>\n      <td>0.000472</td>\n      <td>0.945446</td>\n      <td>0.003059</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.998656</td>\n      <td>0.000640</td>\n      <td>0.981463</td>\n      <td>0.000412</td>\n      <td>2092</td>\n      <td>0.985948</td>\n      <td>0.002229</td>\n      <td>0.997151</td>\n      <td>0.004935</td>\n      <td>0.989040</td>\n      <td>...</td>\n      <td>0.999980</td>\n      <td>0.000034</td>\n      <td>0.999900</td>\n      <td>0.000173</td>\n      <td>0.938236</td>\n      <td>0.011427</td>\n      <td>0.999788</td>\n      <td>0.000231</td>\n      <td>0.938236</td>\n      <td>0.011427</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999158</td>\n      <td>0.000940</td>\n      <td>0.981708</td>\n      <td>0.000435</td>\n      <td>2136</td>\n      <td>0.986455</td>\n      <td>0.002025</td>\n      <td>0.994949</td>\n      <td>0.008748</td>\n      <td>0.989028</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999917</td>\n      <td>0.000144</td>\n      <td>0.943558</td>\n      <td>0.010062</td>\n      <td>0.999916</td>\n      <td>0.000146</td>\n      <td>0.943558</td>\n      <td>0.010062</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">6e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.474132</td>\n      <td>0.000860</td>\n      <td>0.453148</td>\n      <td>0.006920</td>\n      <td>2234</td>\n      <td>0.441796</td>\n      <td>0.012760</td>\n      <td>0.469000</td>\n      <td>0.017939</td>\n      <td>0.494962</td>\n      <td>...</td>\n      <td>0.669066</td>\n      <td>0.014182</td>\n      <td>0.485312</td>\n      <td>0.008882</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.482702</td>\n      <td>0.020771</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.491009</td>\n      <td>0.000306</td>\n      <td>0.725786</td>\n      <td>0.000712</td>\n      <td>2136</td>\n      <td>0.751183</td>\n      <td>0.006922</td>\n      <td>0.608168</td>\n      <td>0.029013</td>\n      <td>0.795820</td>\n      <td>...</td>\n      <td>0.911797</td>\n      <td>0.000900</td>\n      <td>0.716517</td>\n      <td>0.000737</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.822679</td>\n      <td>0.001538</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.648202</td>\n      <td>0.033428</td>\n      <td>0.797589</td>\n      <td>0.002245</td>\n      <td>2079</td>\n      <td>0.812927</td>\n      <td>0.002808</td>\n      <td>0.648197</td>\n      <td>0.003556</td>\n      <td>0.903756</td>\n      <td>...</td>\n      <td>0.999913</td>\n      <td>0.000012</td>\n      <td>0.996427</td>\n      <td>0.002232</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.874759</td>\n      <td>0.009875</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.996407</td>\n      <td>0.000305</td>\n      <td>0.854106</td>\n      <td>0.038408</td>\n      <td>2092</td>\n      <td>0.867483</td>\n      <td>0.040597</td>\n      <td>0.792023</td>\n      <td>0.060032</td>\n      <td>0.926855</td>\n      <td>...</td>\n      <td>0.999673</td>\n      <td>0.000145</td>\n      <td>0.999594</td>\n      <td>0.000308</td>\n      <td>0.201721</td>\n      <td>0.221373</td>\n      <td>0.998747</td>\n      <td>0.000456</td>\n      <td>0.201721</td>\n      <td>0.221373</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.997193</td>\n      <td>0.000382</td>\n      <td>0.978750</td>\n      <td>0.000797</td>\n      <td>2092</td>\n      <td>0.983237</td>\n      <td>0.000243</td>\n      <td>0.948718</td>\n      <td>0.017094</td>\n      <td>0.987427</td>\n      <td>...</td>\n      <td>0.999824</td>\n      <td>0.000157</td>\n      <td>0.999944</td>\n      <td>0.000049</td>\n      <td>0.920650</td>\n      <td>0.004560</td>\n      <td>0.999091</td>\n      <td>0.000454</td>\n      <td>0.920650</td>\n      <td>0.004560</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.998025</td>\n      <td>0.000050</td>\n      <td>0.981230</td>\n      <td>0.000311</td>\n      <td>2092</td>\n      <td>0.987003</td>\n      <td>0.002028</td>\n      <td>0.992188</td>\n      <td>0.013532</td>\n      <td>0.989927</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999357</td>\n      <td>0.000486</td>\n      <td>0.943704</td>\n      <td>0.010076</td>\n      <td>0.999759</td>\n      <td>0.000187</td>\n      <td>0.943704</td>\n      <td>0.010076</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.999593</td>\n      <td>0.000050</td>\n      <td>0.981940</td>\n      <td>0.000127</td>\n      <td>2136</td>\n      <td>0.987885</td>\n      <td>0.001247</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.989947</td>\n      <td>...</td>\n      <td>0.999960</td>\n      <td>0.000034</td>\n      <td>0.999936</td>\n      <td>0.000111</td>\n      <td>0.949983</td>\n      <td>0.002914</td>\n      <td>0.999889</td>\n      <td>0.000099</td>\n      <td>0.949983</td>\n      <td>0.002914</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999622</td>\n      <td>0.000050</td>\n      <td>0.981925</td>\n      <td>0.000106</td>\n      <td>2136</td>\n      <td>0.985851</td>\n      <td>0.001030</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.988094</td>\n      <td>...</td>\n      <td>0.999976</td>\n      <td>0.000041</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.941953</td>\n      <td>0.008100</td>\n      <td>0.999874</td>\n      <td>0.000109</td>\n      <td>0.941953</td>\n      <td>0.008100</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">8e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.478598</td>\n      <td>0.003655</td>\n      <td>0.618229</td>\n      <td>0.121104</td>\n      <td>2234</td>\n      <td>0.636064</td>\n      <td>0.152308</td>\n      <td>0.573239</td>\n      <td>0.090804</td>\n      <td>0.743828</td>\n      <td>...</td>\n      <td>0.801500</td>\n      <td>0.110294</td>\n      <td>0.778786</td>\n      <td>0.232642</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.590277</td>\n      <td>0.106721</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.491300</td>\n      <td>0.000101</td>\n      <td>0.728234</td>\n      <td>0.000580</td>\n      <td>2136</td>\n      <td>0.748128</td>\n      <td>0.006410</td>\n      <td>0.606174</td>\n      <td>0.032351</td>\n      <td>0.794976</td>\n      <td>...</td>\n      <td>0.912890</td>\n      <td>0.000745</td>\n      <td>0.718053</td>\n      <td>0.000677</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.830894</td>\n      <td>0.001087</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.995805</td>\n      <td>0.000550</td>\n      <td>0.820326</td>\n      <td>0.001369</td>\n      <td>2234</td>\n      <td>0.830537</td>\n      <td>0.010935</td>\n      <td>0.709734</td>\n      <td>0.004494</td>\n      <td>0.905913</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.998800</td>\n      <td>0.000223</td>\n      <td>0.009063</td>\n      <td>0.008672</td>\n      <td>0.998075</td>\n      <td>0.000785</td>\n      <td>0.009063</td>\n      <td>0.008672</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.996265</td>\n      <td>0.000593</td>\n      <td>0.977285</td>\n      <td>0.001604</td>\n      <td>2136</td>\n      <td>0.985316</td>\n      <td>0.000512</td>\n      <td>0.938605</td>\n      <td>0.014488</td>\n      <td>0.986513</td>\n      <td>...</td>\n      <td>0.999953</td>\n      <td>0.000042</td>\n      <td>0.998895</td>\n      <td>0.000581</td>\n      <td>0.932870</td>\n      <td>0.005202</td>\n      <td>0.997814</td>\n      <td>0.001918</td>\n      <td>0.932870</td>\n      <td>0.005202</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.997178</td>\n      <td>0.000315</td>\n      <td>0.980110</td>\n      <td>0.000121</td>\n      <td>2092</td>\n      <td>0.986817</td>\n      <td>0.002236</td>\n      <td>0.973469</td>\n      <td>0.008173</td>\n      <td>0.989863</td>\n      <td>...</td>\n      <td>0.999980</td>\n      <td>0.000034</td>\n      <td>0.999309</td>\n      <td>0.000603</td>\n      <td>0.940503</td>\n      <td>0.009754</td>\n      <td>0.998646</td>\n      <td>0.000878</td>\n      <td>0.940503</td>\n      <td>0.009754</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.998790</td>\n      <td>0.000574</td>\n      <td>0.981726</td>\n      <td>0.000064</td>\n      <td>2136</td>\n      <td>0.987860</td>\n      <td>0.001226</td>\n      <td>0.997475</td>\n      <td>0.004374</td>\n      <td>0.989947</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999422</td>\n      <td>0.000510</td>\n      <td>0.949506</td>\n      <td>0.002907</td>\n      <td>0.999686</td>\n      <td>0.000122</td>\n      <td>0.949506</td>\n      <td>0.002907</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.999138</td>\n      <td>0.000864</td>\n      <td>0.981624</td>\n      <td>0.000526</td>\n      <td>2136</td>\n      <td>0.985851</td>\n      <td>0.001030</td>\n      <td>0.997151</td>\n      <td>0.004935</td>\n      <td>0.988097</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.940997</td>\n      <td>0.009755</td>\n      <td>0.999748</td>\n      <td>0.000109</td>\n      <td>0.940997</td>\n      <td>0.009755</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999651</td>\n      <td>0.000087</td>\n      <td>0.982206</td>\n      <td>0.000170</td>\n      <td>2136</td>\n      <td>0.987916</td>\n      <td>0.001274</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.989947</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.950299</td>\n      <td>0.002773</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.950299</td>\n      <td>0.002773</td>\n    </tr>\n    <tr>\n      <th rowspan=\"32\" valign=\"top\">v1.3.3</th>\n      <th rowspan=\"32\" valign=\"top\">t5-base</th>\n      <th rowspan=\"8\" valign=\"top\">1e-6</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.456139</td>\n      <td>0.000466</td>\n      <td>0.065735</td>\n      <td>0.000176</td>\n      <td>3677</td>\n      <td>0.062378</td>\n      <td>0.002582</td>\n      <td>0.058158</td>\n      <td>0.006960</td>\n      <td>0.071228</td>\n      <td>...</td>\n      <td>0.189776</td>\n      <td>0.000544</td>\n      <td>0.047558</td>\n      <td>0.001250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.062052</td>\n      <td>0.000650</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.457888</td>\n      <td>0.000233</td>\n      <td>0.068803</td>\n      <td>0.000049</td>\n      <td>3677</td>\n      <td>0.062441</td>\n      <td>0.001083</td>\n      <td>0.060432</td>\n      <td>0.007419</td>\n      <td>0.074051</td>\n      <td>...</td>\n      <td>0.195191</td>\n      <td>0.000247</td>\n      <td>0.051006</td>\n      <td>0.001537</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.063661</td>\n      <td>0.000744</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.462059</td>\n      <td>0.000202</td>\n      <td>0.075679</td>\n      <td>0.000145</td>\n      <td>3634</td>\n      <td>0.072087</td>\n      <td>0.000044</td>\n      <td>0.052900</td>\n      <td>0.000167</td>\n      <td>0.079687</td>\n      <td>...</td>\n      <td>0.203794</td>\n      <td>0.000046</td>\n      <td>0.054812</td>\n      <td>0.000306</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.068893</td>\n      <td>0.000271</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.465018</td>\n      <td>0.000117</td>\n      <td>0.095033</td>\n      <td>0.000176</td>\n      <td>3677</td>\n      <td>0.106603</td>\n      <td>0.002874</td>\n      <td>0.063216</td>\n      <td>0.009376</td>\n      <td>0.093334</td>\n      <td>...</td>\n      <td>0.248926</td>\n      <td>0.000531</td>\n      <td>0.073186</td>\n      <td>0.003586</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.087834</td>\n      <td>0.000485</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.466061</td>\n      <td>0.000117</td>\n      <td>0.132682</td>\n      <td>0.001448</td>\n      <td>3759</td>\n      <td>0.150112</td>\n      <td>0.000382</td>\n      <td>0.088612</td>\n      <td>0.004964</td>\n      <td>0.135907</td>\n      <td>...</td>\n      <td>0.338021</td>\n      <td>0.004144</td>\n      <td>0.112518</td>\n      <td>0.005190</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.129150</td>\n      <td>0.006987</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.461251</td>\n      <td>0.000440</td>\n      <td>0.289464</td>\n      <td>0.000579</td>\n      <td>3677</td>\n      <td>0.328818</td>\n      <td>0.001989</td>\n      <td>0.308833</td>\n      <td>0.030858</td>\n      <td>0.306160</td>\n      <td>...</td>\n      <td>0.639248</td>\n      <td>0.001409</td>\n      <td>0.343418</td>\n      <td>0.007020</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.403461</td>\n      <td>0.001553</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.463404</td>\n      <td>0.000117</td>\n      <td>0.340942</td>\n      <td>0.000931</td>\n      <td>3677</td>\n      <td>0.345572</td>\n      <td>0.006371</td>\n      <td>0.333504</td>\n      <td>0.042293</td>\n      <td>0.386407</td>\n      <td>...</td>\n      <td>0.655651</td>\n      <td>0.001011</td>\n      <td>0.407584</td>\n      <td>0.004360</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.450711</td>\n      <td>0.001895</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.482812</td>\n      <td>0.000058</td>\n      <td>0.600711</td>\n      <td>0.000447</td>\n      <td>3634</td>\n      <td>0.644095</td>\n      <td>0.000265</td>\n      <td>0.392413</td>\n      <td>0.000000</td>\n      <td>0.717404</td>\n      <td>...</td>\n      <td>0.904216</td>\n      <td>0.000238</td>\n      <td>0.705839</td>\n      <td>0.000428</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.769528</td>\n      <td>0.001939</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">4e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.463606</td>\n      <td>0.001262</td>\n      <td>0.334177</td>\n      <td>0.005124</td>\n      <td>3677</td>\n      <td>0.344465</td>\n      <td>0.006917</td>\n      <td>0.306423</td>\n      <td>0.025832</td>\n      <td>0.392371</td>\n      <td>...</td>\n      <td>0.628341</td>\n      <td>0.009008</td>\n      <td>0.397724</td>\n      <td>0.003236</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.454981</td>\n      <td>0.013862</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.482682</td>\n      <td>0.000055</td>\n      <td>0.601996</td>\n      <td>0.006303</td>\n      <td>3677</td>\n      <td>0.629176</td>\n      <td>0.004130</td>\n      <td>0.498057</td>\n      <td>0.001596</td>\n      <td>0.733232</td>\n      <td>...</td>\n      <td>0.901123</td>\n      <td>0.001411</td>\n      <td>0.733730</td>\n      <td>0.034276</td>\n      <td>0.000725</td>\n      <td>0.001030</td>\n      <td>0.751015</td>\n      <td>0.011724</td>\n      <td>0.000725</td>\n      <td>0.001030</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.485368</td>\n      <td>0.000303</td>\n      <td>0.649606</td>\n      <td>0.039749</td>\n      <td>3677</td>\n      <td>0.676110</td>\n      <td>0.058471</td>\n      <td>0.454595</td>\n      <td>0.057359</td>\n      <td>0.725620</td>\n      <td>...</td>\n      <td>0.899607</td>\n      <td>0.009273</td>\n      <td>0.719050</td>\n      <td>0.003645</td>\n      <td>0.107610</td>\n      <td>0.146849</td>\n      <td>0.826463</td>\n      <td>0.001490</td>\n      <td>0.107610</td>\n      <td>0.146849</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.486411</td>\n      <td>0.000382</td>\n      <td>0.800404</td>\n      <td>0.005816</td>\n      <td>3634</td>\n      <td>0.786416</td>\n      <td>0.005745</td>\n      <td>0.661850</td>\n      <td>0.000428</td>\n      <td>0.903275</td>\n      <td>...</td>\n      <td>0.999460</td>\n      <td>0.000272</td>\n      <td>0.978500</td>\n      <td>0.006186</td>\n      <td>0.526234</td>\n      <td>0.015033</td>\n      <td>0.674198</td>\n      <td>0.012064</td>\n      <td>0.526234</td>\n      <td>0.015033</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.939501</td>\n      <td>0.019360</td>\n      <td>0.958810</td>\n      <td>0.000352</td>\n      <td>3677</td>\n      <td>0.965668</td>\n      <td>0.000651</td>\n      <td>0.882046</td>\n      <td>0.022996</td>\n      <td>0.963374</td>\n      <td>...</td>\n      <td>0.999836</td>\n      <td>0.000158</td>\n      <td>0.996421</td>\n      <td>0.001016</td>\n      <td>0.904965</td>\n      <td>0.005379</td>\n      <td>0.964105</td>\n      <td>0.007066</td>\n      <td>0.904965</td>\n      <td>0.005379</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.998304</td>\n      <td>0.000167</td>\n      <td>0.977023</td>\n      <td>0.000054</td>\n      <td>3759</td>\n      <td>0.975766</td>\n      <td>0.000934</td>\n      <td>0.995186</td>\n      <td>0.004169</td>\n      <td>0.980744</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999265</td>\n      <td>0.000328</td>\n      <td>0.948717</td>\n      <td>0.002144</td>\n      <td>0.999995</td>\n      <td>0.000009</td>\n      <td>0.948717</td>\n      <td>0.002144</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.999367</td>\n      <td>0.000223</td>\n      <td>0.977865</td>\n      <td>0.000142</td>\n      <td>3677</td>\n      <td>0.974742</td>\n      <td>0.003126</td>\n      <td>0.997849</td>\n      <td>0.003725</td>\n      <td>0.979234</td>\n      <td>...</td>\n      <td>0.999907</td>\n      <td>0.000089</td>\n      <td>0.999502</td>\n      <td>0.000389</td>\n      <td>0.948826</td>\n      <td>0.001943</td>\n      <td>0.999815</td>\n      <td>0.000208</td>\n      <td>0.948826</td>\n      <td>0.001943</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999624</td>\n      <td>0.000049</td>\n      <td>0.978082</td>\n      <td>0.000064</td>\n      <td>3634</td>\n      <td>0.976576</td>\n      <td>0.000050</td>\n      <td>0.997849</td>\n      <td>0.003725</td>\n      <td>0.976974</td>\n      <td>...</td>\n      <td>0.999882</td>\n      <td>0.000102</td>\n      <td>0.999909</td>\n      <td>0.000158</td>\n      <td>0.948083</td>\n      <td>0.000159</td>\n      <td>0.999927</td>\n      <td>0.000063</td>\n      <td>0.948083</td>\n      <td>0.000159</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">6e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.463438</td>\n      <td>0.001216</td>\n      <td>0.369300</td>\n      <td>0.016467</td>\n      <td>3677</td>\n      <td>0.361387</td>\n      <td>0.015760</td>\n      <td>0.317800</td>\n      <td>0.056888</td>\n      <td>0.439826</td>\n      <td>...</td>\n      <td>0.678354</td>\n      <td>0.044612</td>\n      <td>0.444926</td>\n      <td>0.018337</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.463374</td>\n      <td>0.006089</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.484875</td>\n      <td>0.000498</td>\n      <td>0.621068</td>\n      <td>0.004909</td>\n      <td>3636</td>\n      <td>0.653836</td>\n      <td>0.004669</td>\n      <td>0.443154</td>\n      <td>0.054752</td>\n      <td>0.778802</td>\n      <td>...</td>\n      <td>0.899201</td>\n      <td>0.010621</td>\n      <td>0.877620</td>\n      <td>0.012689</td>\n      <td>0.000734</td>\n      <td>0.000573</td>\n      <td>0.763383</td>\n      <td>0.015199</td>\n      <td>0.000734</td>\n      <td>0.000573</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.486276</td>\n      <td>0.000202</td>\n      <td>0.793911</td>\n      <td>0.010508</td>\n      <td>3634</td>\n      <td>0.784362</td>\n      <td>0.004782</td>\n      <td>0.640273</td>\n      <td>0.036695</td>\n      <td>0.883627</td>\n      <td>...</td>\n      <td>0.999697</td>\n      <td>0.000058</td>\n      <td>0.966700</td>\n      <td>0.011453</td>\n      <td>0.504403</td>\n      <td>0.040412</td>\n      <td>0.687419</td>\n      <td>0.029367</td>\n      <td>0.504403</td>\n      <td>0.040412</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.994286</td>\n      <td>0.000870</td>\n      <td>0.970323</td>\n      <td>0.000710</td>\n      <td>3677</td>\n      <td>0.969545</td>\n      <td>0.003857</td>\n      <td>0.895018</td>\n      <td>0.021063</td>\n      <td>0.975510</td>\n      <td>...</td>\n      <td>0.999895</td>\n      <td>0.000093</td>\n      <td>0.997982</td>\n      <td>0.000218</td>\n      <td>0.930722</td>\n      <td>0.004658</td>\n      <td>0.991736</td>\n      <td>0.001986</td>\n      <td>0.930722</td>\n      <td>0.004658</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.997342</td>\n      <td>0.000207</td>\n      <td>0.975397</td>\n      <td>0.000301</td>\n      <td>3677</td>\n      <td>0.973045</td>\n      <td>0.004222</td>\n      <td>0.922439</td>\n      <td>0.012906</td>\n      <td>0.979228</td>\n      <td>...</td>\n      <td>0.999907</td>\n      <td>0.000089</td>\n      <td>0.998636</td>\n      <td>0.000337</td>\n      <td>0.941700</td>\n      <td>0.002047</td>\n      <td>0.998133</td>\n      <td>0.000798</td>\n      <td>0.941700</td>\n      <td>0.002047</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.998369</td>\n      <td>0.000350</td>\n      <td>0.977311</td>\n      <td>0.000225</td>\n      <td>3677</td>\n      <td>0.972794</td>\n      <td>0.003257</td>\n      <td>0.993762</td>\n      <td>0.000234</td>\n      <td>0.981495</td>\n      <td>...</td>\n      <td>0.999941</td>\n      <td>0.000102</td>\n      <td>0.998879</td>\n      <td>0.000466</td>\n      <td>0.949392</td>\n      <td>0.001738</td>\n      <td>0.999591</td>\n      <td>0.000308</td>\n      <td>0.949392</td>\n      <td>0.001738</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.999731</td>\n      <td>0.000058</td>\n      <td>0.978071</td>\n      <td>0.000058</td>\n      <td>3677</td>\n      <td>0.974771</td>\n      <td>0.003151</td>\n      <td>0.997849</td>\n      <td>0.003725</td>\n      <td>0.979270</td>\n      <td>...</td>\n      <td>0.999966</td>\n      <td>0.000060</td>\n      <td>0.999867</td>\n      <td>0.000137</td>\n      <td>0.949009</td>\n      <td>0.002005</td>\n      <td>0.999964</td>\n      <td>0.000063</td>\n      <td>0.949009</td>\n      <td>0.002005</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999832</td>\n      <td>0.000058</td>\n      <td>0.978063</td>\n      <td>0.000095</td>\n      <td>3677</td>\n      <td>0.974800</td>\n      <td>0.003176</td>\n      <td>0.997849</td>\n      <td>0.003725</td>\n      <td>0.979270</td>\n      <td>...</td>\n      <td>0.999941</td>\n      <td>0.000102</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.949192</td>\n      <td>0.001847</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.949192</td>\n      <td>0.001847</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">8e-5</th>\n      <th rowspan=\"8\" valign=\"top\">null</th>\n      <th>1.0</th>\n      <td>0.468961</td>\n      <td>0.005880</td>\n      <td>0.474987</td>\n      <td>0.089539</td>\n      <td>3759</td>\n      <td>0.497245</td>\n      <td>0.073746</td>\n      <td>0.395016</td>\n      <td>0.078711</td>\n      <td>0.642586</td>\n      <td>...</td>\n      <td>0.724627</td>\n      <td>0.151810</td>\n      <td>0.698874</td>\n      <td>0.189575</td>\n      <td>0.000092</td>\n      <td>0.000159</td>\n      <td>0.522564</td>\n      <td>0.087131</td>\n      <td>0.000092</td>\n      <td>0.000159</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <td>0.485267</td>\n      <td>0.000101</td>\n      <td>0.630407</td>\n      <td>0.017028</td>\n      <td>3759</td>\n      <td>0.652628</td>\n      <td>0.019072</td>\n      <td>0.437481</td>\n      <td>0.036037</td>\n      <td>0.727581</td>\n      <td>...</td>\n      <td>0.911504</td>\n      <td>0.001169</td>\n      <td>0.718210</td>\n      <td>0.002258</td>\n      <td>0.038766</td>\n      <td>0.060331</td>\n      <td>0.825256</td>\n      <td>0.002948</td>\n      <td>0.038766</td>\n      <td>0.060331</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.847867</td>\n      <td>0.034740</td>\n      <td>0.936162</td>\n      <td>0.025037</td>\n      <td>3636</td>\n      <td>0.958832</td>\n      <td>0.011434</td>\n      <td>0.848556</td>\n      <td>0.045011</td>\n      <td>0.946988</td>\n      <td>...</td>\n      <td>0.999882</td>\n      <td>0.000102</td>\n      <td>0.995600</td>\n      <td>0.002225</td>\n      <td>0.848026</td>\n      <td>0.071151</td>\n      <td>0.926716</td>\n      <td>0.031799</td>\n      <td>0.848026</td>\n      <td>0.071151</td>\n    </tr>\n    <tr>\n      <th>7.5</th>\n      <td>0.996994</td>\n      <td>0.000337</td>\n      <td>0.974998</td>\n      <td>0.000214</td>\n      <td>3759</td>\n      <td>0.973888</td>\n      <td>0.001323</td>\n      <td>0.938756</td>\n      <td>0.030770</td>\n      <td>0.974277</td>\n      <td>...</td>\n      <td>0.999941</td>\n      <td>0.000102</td>\n      <td>0.999338</td>\n      <td>0.000497</td>\n      <td>0.940815</td>\n      <td>0.001348</td>\n      <td>0.996934</td>\n      <td>0.000909</td>\n      <td>0.940815</td>\n      <td>0.001348</td>\n    </tr>\n    <tr>\n      <th>10.0</th>\n      <td>0.997477</td>\n      <td>0.000809</td>\n      <td>0.976446</td>\n      <td>0.000340</td>\n      <td>3677</td>\n      <td>0.974555</td>\n      <td>0.004146</td>\n      <td>0.976838</td>\n      <td>0.021727</td>\n      <td>0.984338</td>\n      <td>...</td>\n      <td>0.999989</td>\n      <td>0.000020</td>\n      <td>0.999031</td>\n      <td>0.000724</td>\n      <td>0.948401</td>\n      <td>0.001392</td>\n      <td>0.999556</td>\n      <td>0.000747</td>\n      <td>0.948401</td>\n      <td>0.001392</td>\n    </tr>\n    <tr>\n      <th>25.0</th>\n      <td>0.999058</td>\n      <td>0.000117</td>\n      <td>0.977737</td>\n      <td>0.000078</td>\n      <td>3677</td>\n      <td>0.972967</td>\n      <td>0.003176</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.981531</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999195</td>\n      <td>0.000460</td>\n      <td>0.950028</td>\n      <td>0.001764</td>\n      <td>0.999965</td>\n      <td>0.000022</td>\n      <td>0.950028</td>\n      <td>0.001764</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <td>0.999508</td>\n      <td>0.000264</td>\n      <td>0.978061</td>\n      <td>0.000129</td>\n      <td>3636</td>\n      <td>0.976817</td>\n      <td>0.000443</td>\n      <td>0.999570</td>\n      <td>0.000745</td>\n      <td>0.979528</td>\n      <td>...</td>\n      <td>0.999882</td>\n      <td>0.000102</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.949376</td>\n      <td>0.002398</td>\n      <td>0.999751</td>\n      <td>0.000432</td>\n      <td>0.949376</td>\n      <td>0.002398</td>\n    </tr>\n    <tr>\n      <th>100.0</th>\n      <td>0.999765</td>\n      <td>0.000058</td>\n      <td>0.978176</td>\n      <td>0.000153</td>\n      <td>3677</td>\n      <td>0.972938</td>\n      <td>0.003126</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.981531</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999959</td>\n      <td>0.000072</td>\n      <td>0.950301</td>\n      <td>0.001762</td>\n      <td>0.999964</td>\n      <td>0.000063</td>\n      <td>0.950301</td>\n      <td>0.001762</td>\n    </tr>\n  </tbody>\n</table>\n<p>124 rows  69 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(experiments).fillna(0)\n",
    "\n",
    "cols = {col:[np.mean, np.std] for col in filter(lambda col: col == \"A_EM\" or col == \"EM\" or col.startswith(\"x_\") or col.startswith(\"prop_\") or col.startswith(\"type_\"),results.columns)}\n",
    "cols.update({col:[np.max] for col in filter(lambda col: col.startswith(\"count_type_negative\"), results.columns)})\n",
    "breakdown_cols = list(filter(lambda col: col.startswith(\"prop_\"),results.columns))\n",
    "type_cols = list(filter(lambda col: (col.startswith(\"type_\") and \"negative\" not in col) or col.startswith(\"x\"),results.columns))\n",
    "print(type_cols)\n",
    "type_cols2 = list(filter(lambda col: col.startswith(\"type_\") and \"negative\" not in col or col == \"x_avg_negative\",results.columns))\n",
    "a_type_cols = list(filter(lambda col: col.startswith(\"A_type_\") and \"negative\" not in col or col == \"x_avg_negative\",results.columns))\n",
    "type_cols3 = list(filter(lambda col: \"count\" not in col and  \"negative\" in col,results.columns))\n",
    "type_cols4 = list(filter(lambda col: col.startswith(\"type_\") and \"negative\" not in col,results.columns))\n",
    "breakdown = pd.pivot_table(results, index=[\"experiment\",\"version\",\"model\",\"lr\",\"filters\",\"train_percentage\"],columns=[],aggfunc=cols)\n",
    "#pd.option_context(\"display.max_rows\",None)\n",
    "pd.options.display.max_rows = 150\n",
    "breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "display = \"v1.3.1\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x216 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"8e-5\"][\"null\"][100].T[breakdown_cols]\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "for score in [prop_scores[a] for a in breakdown_cols]:\n",
    "    means.append(score[\"mean\"])\n",
    "    stds.append(score[\"std\"])\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"T5 Neural SP EM by Wikidata relation name\")\n",
    "plt.ylabel(\"Exact match\")\n",
    "plt.xlabel(\"Wikidata relation name\")\n",
    "\n",
    "plt.bar(breakdown_cols,means,yerr=stds, color=\"brown\")\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(\"/scratch/jth/neural_sp_rels.pdf\", bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A_type_argmax'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36mget_value\u001B[0;34m(self, series, key)\u001B[0m\n\u001B[1;32m   1496\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1497\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mlibindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_value_at\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1498\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.get_value_at\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.get_value_at\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/util.pxd\u001B[0m in \u001B[0;36mpandas._libs.util.get_value_at\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/util.pxd\u001B[0m in \u001B[0;36mpandas._libs.util.validate_indexer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-314-48fe4545bc21>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0msort_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msorted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma_type_cols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mscore\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mprop_scores\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msort_cols\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mmeans\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"mean\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mstds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"std\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-314-48fe4545bc21>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0msort_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msorted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma_type_cols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mscore\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mprop_scores\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msort_cols\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mmeans\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"mean\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mstds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"std\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    869\u001B[0m         \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    870\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 871\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    872\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    873\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36mget_value\u001B[0;34m(self, series, key)\u001B[0m\n\u001B[1;32m   1503\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0mInvalidIndexError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1504\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1505\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0me1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1506\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pragma: no cover\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1507\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0me1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36mget_value\u001B[0;34m(self, series, key)\u001B[0m\n\u001B[1;32m   1487\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1488\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1489\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1490\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1491\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_value\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_value\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'A_type_argmax'"
     ]
    }
   ],
   "source": [
    "prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"8e-5\"][\"null\"][100.0].T[a_type_cols]\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "sort_cols = sorted(a_type_cols)\n",
    "for score in [prop_scores[a] for a in sort_cols]:\n",
    "    means.append(score[\"mean\"])\n",
    "    stds.append(score[\"std\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.title(\"T5 Neural SP EM by projection type\")\n",
    "plt.ylabel(\"Exact match\")\n",
    "plt.xlabel(\"Projection type\")\n",
    "plt.bar(sort_cols,means,yerr=stds, color=\"brown\")\n",
    "plt.ylim(0,1)\n",
    "print(means)\n",
    "print(stds)\n",
    "plt.savefig(\"/scratch/jth/neural_sp_proj.pdf\", bbox_inches = 'tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'null'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2645\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2646\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2647\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'null'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-72-f79266e38c96>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mcolors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"brown\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"red\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"orange\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"olive\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdisplay\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m     \u001B[0mprop_scores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbreakdown\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"operator_sweep\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdisplay\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"t5-base\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"null\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m100.0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype_cols2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mmeans\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2797\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_single_key\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2798\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2799\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2800\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2801\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_getitem_multilevel\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2847\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2848\u001B[0m         \u001B[0;31m# self.columns is a MultiIndex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2849\u001B[0;31m         \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2850\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mslice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2851\u001B[0m             \u001B[0mnew_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method)\u001B[0m\n\u001B[1;32m   2660\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtuple\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2661\u001B[0m             \u001B[0;31m# not including list here breaks some indexing, xref #30892\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2662\u001B[0;31m             \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_level_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2663\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0m_maybe_to_slice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2664\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36m_get_level_indexer\u001B[0;34m(self, key, level, indexer)\u001B[0m\n\u001B[1;32m   2927\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2929\u001B[0;31m             \u001B[0mcode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_loc_single_level_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlevel_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2930\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2931\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlevel\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlexsort_depth\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36m_get_loc_single_level_index\u001B[0;34m(self, level_index, key)\u001B[0m\n\u001B[1;32m   2596\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2598\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mlevel_index\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2599\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2600\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2646\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2647\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2648\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_cast_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2649\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2650\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'null'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.title(\"T5 Operator model EM by projection type\")\n",
    "plt.ylabel(\"Exact match\")\n",
    "plt.xlabel(\"Projection type\")\n",
    "plt.title(\"T5 Operator model negative instance EM by negative type\")\n",
    "\n",
    "x = np.arange(len(type_cols2))\n",
    "w = 0.2\n",
    "plt.xticks(x+w/5, type_cols2,rotation=90)\n",
    "\n",
    "datasets = [\"v1.1.1\", \"v1.1.2\", \"v1.1.3\", \"v1.1.4\"]\n",
    "colors = [\"brown\", \"red\",\"orange\", \"olive\"]\n",
    "for idx, display in enumerate(datasets):\n",
    "    prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"null\"][100.0].T[type_cols2]\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for score in [prop_scores[a] for a in type_cols2]:\n",
    "        means.append(score[\"mean\"])\n",
    "        stds.append(score[\"std\"])\n",
    "\n",
    "    plt.bar(x+idx*w,means,yerr=stds, width=w, color=colors[idx])\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.legend(datasets)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.title(\"T5 Operator model EM by relation name\")\n",
    "plt.ylabel(\"Exact match\")\n",
    "plt.xlabel(\"Relation name\")\n",
    "plt.title(\"T5 Operator model negative instance EM by relation name\")\n",
    "\n",
    "x = np.arange(len(breakdown_cols))\n",
    "w = 0.2\n",
    "plt.xticks(x+w/5, breakdown_cols,rotation=90)\n",
    "\n",
    "datasets = [\"v1.1.1\", \"v1.1.2\", \"v1.1.3\", \"v1.1.4\"]\n",
    "colors = [\"brown\", \"red\",\"orange\", \"olive\"]\n",
    "for idx, display in enumerate(datasets):\n",
    "    prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"null\"][100.0].T[breakdown_cols]\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for score in [prop_scores[a] for a in breakdown_cols]:\n",
    "        means.append(score[\"mean\"])\n",
    "        stds.append(score[\"std\"])\n",
    "\n",
    "    plt.bar(x+idx*w,means,yerr=stds, width=w, color=colors[idx])\n",
    "\n",
    "print(means)\n",
    "plt.ylim(0,1)\n",
    "plt.legend(datasets, loc='lower right')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.title(\"T5 Operator model EM by projection type\")\n",
    "plt.ylabel(\"Exact match\")\n",
    "plt.xlabel(\"Projection type\")\n",
    "\n",
    "\n",
    "prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"null\"][100.0].T[type_cols2]\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "for score in [prop_scores[a] for a in type_cols2]:\n",
    "    means.append(score[\"mean\"])\n",
    "    stds.append(score[\"std\"])\n",
    "\n",
    "plt.bar(type_cols2,means,yerr=stds)\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t5-base'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2645\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2646\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2647\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 't5-base'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-112-cdf9951ab6a0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprop_scores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbreakdown\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"operator_sweep\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"t5-base\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"null\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m100.0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype_cols3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mmeans\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mstds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmatched\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2797\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_single_key\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2798\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2799\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2800\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2801\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_getitem_multilevel\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2847\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2848\u001B[0m         \u001B[0;31m# self.columns is a MultiIndex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2849\u001B[0;31m         \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2850\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mslice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2851\u001B[0m             \u001B[0mnew_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method)\u001B[0m\n\u001B[1;32m   2660\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtuple\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2661\u001B[0m             \u001B[0;31m# not including list here breaks some indexing, xref #30892\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2662\u001B[0;31m             \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_level_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2663\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0m_maybe_to_slice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2664\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36m_get_level_indexer\u001B[0;34m(self, key, level, indexer)\u001B[0m\n\u001B[1;32m   2927\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2929\u001B[0;31m             \u001B[0mcode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_loc_single_level_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlevel_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2930\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2931\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlevel\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlexsort_depth\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36m_get_loc_single_level_index\u001B[0;34m(self, level_index, key)\u001B[0m\n\u001B[1;32m   2596\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2598\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mlevel_index\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2599\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2600\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2646\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2647\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2648\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_cast_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2649\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2650\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 't5-base'"
     ]
    }
   ],
   "source": [
    "prop_scores = breakdown.T[\"operator_sweep\"][\"t5-base\"][\"null\"][100.0].T[type_cols3]\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "matched = []\n",
    "props = []\n",
    "\n",
    "w = 0.3\n",
    "for name in type_cols3:\n",
    "\n",
    "    try:\n",
    "        score =  prop_scores[name]\n",
    "        matched.append(name)\n",
    "        means.append(score[\"mean\"])\n",
    "        stds.append(score[\"std\"])\n",
    "\n",
    "    except:\n",
    "        print(\"No instances for {}\".format(name))\n",
    "\n",
    "    if \"x\" not in name:\n",
    "        props.append(breakdown.T[\"operator_sweep\"][\"t5-base\"][\"null\"][100.0][\"count_{}\".format(name)][\"amax\"])\n",
    "    else:\n",
    "        props.append(0.0)\n",
    "\n",
    "\n",
    "fig,ax1 = plt.subplots(figsize=(16,4))\n",
    "\n",
    "x = np.arange(len(matched))\n",
    "\n",
    "plt.xticks(x+w/2, matched,rotation=90)\n",
    "plt.title(\"T5 Operator model negative instance EM by negative type\")\n",
    "ax1.set_ylabel(\"Exact match\")\n",
    "ax1.set_xlabel(\"Projection type\")\n",
    "\n",
    "ems = ax1.bar(x, means, yerr=stds, width=w)\n",
    "\n",
    "ax2 = plt.twinx()\n",
    "sizes = ax2.bar(x+w, props, color=\"orange\", width=w)\n",
    "ax1.set_ylabel(\"Number of data\")\n",
    "\n",
    "plt.legend([ems,sizes],['EM Score','Number of data'])\n",
    "ax1.set_ylim(0,1)\n",
    "ax2.set_ylim(0,600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prop_P106', 'prop_P20', 'prop_P1082', 'prop_P19', 'prop_P47', 'prop_P1110', 'prop_educated_at', 'prop_is', 'prop_born_in', 'prop_P21', 'prop_is_a_at', 'prop_P69', 'prop_lang', 'prop_P61', 'prop_P54', 'prop_P26', 'prop_lives_where_with', 'prop_P58', 'prop_P22', 'prop_P108', 'prop_P6', 'prop_plays_sport', 'prop_father', 'prop_spouse', 'prop_P1092', 'prop_has_child', 'prop_mother', 'prop_P118', 'prop_P1198', 'prop_P57', 'prop_P50', 'prop_P35', 'prop_P38', 'prop_P1174', 'prop_P1867']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'operator_filter'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2645\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2646\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2647\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'operator_filter'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-277-3e3da88f5482>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mbreakdown_cols\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m!=\u001B[0m \u001B[0;34m\"P27\"\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0;34m\"prop_P27\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbreakdown_cols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbreakdown_cols\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mcols2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"null\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbreakdown\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"operator_filter\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"v1.1.1\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"t5-base\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"1e-4\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mx_labels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msorted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcols2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2797\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_single_key\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2798\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2799\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2800\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2801\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_getitem_multilevel\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2847\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2848\u001B[0m         \u001B[0;31m# self.columns is a MultiIndex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2849\u001B[0;31m         \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2850\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mslice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2851\u001B[0m             \u001B[0mnew_columns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method)\u001B[0m\n\u001B[1;32m   2660\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtuple\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2661\u001B[0m             \u001B[0;31m# not including list here breaks some indexing, xref #30892\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2662\u001B[0;31m             \u001B[0mloc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_level_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2663\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0m_maybe_to_slice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2664\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36m_get_level_indexer\u001B[0;34m(self, key, level, indexer)\u001B[0m\n\u001B[1;32m   2927\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2929\u001B[0;31m             \u001B[0mcode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_loc_single_level_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlevel_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2930\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2931\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlevel\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlexsort_depth\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001B[0m in \u001B[0;36m_get_loc_single_level_index\u001B[0;34m(self, level_index, key)\u001B[0m\n\u001B[1;32m   2596\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2598\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mlevel_index\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2599\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2600\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/neuraldb/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   2646\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2647\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2648\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_cast_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2649\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2650\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'operator_filter'"
     ]
    }
   ],
   "source": [
    "breakdown_cols= list(filter(lambda col: col!= \"P27\" and col!=\"prop_P27\",breakdown_cols))\n",
    "print(breakdown_cols)\n",
    "cols2 = list(set(map(lambda a: a[0], filter(lambda col:col[0] != \"null\", breakdown.T[\"operator_filter\"][\"v1.1.1\"][\"t5-base\"][\"1e-4\"].columns))))\n",
    "\n",
    "x_labels = sorted(cols2)\n",
    "y_labels = sorted(breakdown_cols)\n",
    "\n",
    "heatmap = []\n",
    "\n",
    "for c in y_labels:\n",
    "    row = []\n",
    "    for x in x_labels:\n",
    "        row.append(breakdown.T[\"operator_filter\"][\"v1.3.1\"][\"t5-base\"][\"1e-4\"][x][100.0].T[c][\"mean\"])\n",
    "    heatmap.append(row)\n",
    "\n",
    "heatmap=np.array(heatmap)\n",
    "\n",
    "assert heatmap.shape[0] == len(y_labels)\n",
    "assert heatmap.shape[1] == len(x_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "im = ax.imshow(1-heatmap, cmap=\"YlOrBr\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xticks(np.arange(len(x_labels)),x_labels,rotation=90)\n",
    "plt.yticks(np.arange(len(y_labels)),y_labels)\n",
    "\n",
    "for j in range(len(x_labels)):\n",
    "    for i in range(len(y_labels)):\n",
    "        text = ax.text(j,i, round(100*(1-heatmap[i,j]),1),color='w', ha=\"center\",va=\"center\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Property removed at training\")\n",
    "plt.ylabel(\"Property error rate at test time\")\n",
    "plt.title(\"Error rates (%) for cross domain transfer between relations\")\n",
    "plt.savefig(\"/scratch/jth/neural_sp_trans.pdf\", bbox_inches = 'tight')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('operator_filter', 'v1.3.2', 't5-base', '8e-5', 'P106', 100.0)\n",
      "[1.0, 2.5, 5.0, 7.5, 10.0, 25.0, 50.0, 100.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with plt.style.context(\"ggplot\"):\n",
    "    print(breakdown.index[0])\n",
    "    display = \"v1.3.2\"\n",
    "    sizes = [a[5] for a in breakdown.index if a[1] == display and a[3] == \"8e-5\" and a[4] == \"null\" and a[5] != \"null\"]\n",
    "    print(sizes)\n",
    "\n",
    "    prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"8e-5\"][\"null\"][sizes].T[\"EM\"]\n",
    "\n",
    "    means = []\n",
    "    uppers = []\n",
    "    lowers = []\n",
    "\n",
    "    for mean,std in [(prop_scores[\"mean\"][size],prop_scores[\"std\"][size]) for size in sizes]:\n",
    "        means.append(mean*100)\n",
    "        lowers.append((mean-std)*100)\n",
    "        uppers.append((mean-std)*100)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "\n",
    "    actual = [750000*size/100 for size in sizes]\n",
    "    plt.title(\"Intermediate result generation learning curve\")\n",
    "    plt.ylabel(\"Exact match %\")\n",
    "    plt.xlabel(\"Number of training data\")\n",
    "\n",
    "    plt.plot(actual,means)\n",
    "    plt.fill_between(actual,lowers,uppers,alpha=0.2)\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "    labels = {\n",
    "        \"type_count\": \"Count\",\n",
    "        \"type_set\": \"Set\",\n",
    "        \"type_argmin\": \"Min\",\n",
    "        \"type_argmax\": \"Max\",\n",
    "        \"type_bool\":\"Boolean\",\n",
    "        \"type_ext\": \"Extractive\",\n",
    "        \"x_avg_negative\": \"NULL Answer\"\n",
    "    }\n",
    "\n",
    "    legend = [\"All\"]\n",
    "    for line in type_cols2:\n",
    "         prop_scores = breakdown.T[\"operator_sweep\"][display][\"t5-base\"][\"8e-5\"][\"null\"][sizes].T[line]\n",
    "         means = []\n",
    "         uppers = []\n",
    "         lowers = []\n",
    "\n",
    "         for mean,std in [(prop_scores[\"mean\"][size],prop_scores[\"std\"][size]) for size in sizes]:\n",
    "             means.append(100*mean)\n",
    "             lowers.append(100*(mean-std))\n",
    "             uppers.append(100*(mean-std))\n",
    "\n",
    "\n",
    "         plt.plot(actual,means)\n",
    "         plt.fill_between(actual,lowers,uppers,alpha=0.2)\n",
    "         legend.append(labels[line])\n",
    "\n",
    "\n",
    "\n",
    "    plt.legend(legend)\n",
    "    plt.savefig(\"/scratch/jth/neural_sp_data.pdf\", bbox_inches = 'tight')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    def get_num(item):\n",
    "        bits = item.split(\"[SEP]\")\n",
    "        if len(bits) > 1:\n",
    "            return bits[1].strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_ent(item):\n",
    "        bits = item.split(\"[SEP]\")\n",
    "        if len(bits) > 1:\n",
    "            return bits[0].strip().replace(\"[LOOKUP]\",\"\").strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    err_predict_null =0\n",
    "    err_wrong_num = 0\n",
    "    err_wrong_ent = 0\n",
    "\n",
    "    for exp in filter(lambda exp: \"filters=null,train_percentage=1.0\" in exp[\"file\"], experiments):\n",
    "        for item in exp[\"raw\"]:\n",
    "            if \"[SEP]\" in item[0]:\n",
    "                master = get_num(item[0])\n",
    "                predicted = get_num(item[1])\n",
    "\n",
    "                if predicted is None:\n",
    "                    err_predict_null += 1\n",
    "\n",
    "                elif predicted != master:\n",
    "                    err_wrong_num += 1\n",
    "\n",
    "                    print(predicted,master)\n",
    "\n",
    "            if \"[SEP]\" in item[0]:\n",
    "                master = get_ent(item[0])\n",
    "                predicted = get_ent(item[1])\n",
    "\n",
    "                if predicted is None:\n",
    "                    pass\n",
    "                elif predicted != master:\n",
    "                    err_wrong_num += 1\n",
    "                    print(predicted,master)\n",
    "\n",
    "\n",
    "    print(err_wrong_num, err_predict_null)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL\n",
      "[BOOL] Itzcoatl\n",
      "[SET] Itzcoatl\n",
      "[NULL_ANSWER]\n",
      "[ARG] king of Wisigoths [SEP] Gundemar\n",
      "[BOOL] FALSE\n",
      "[NULL_ANSWER]\n",
      "[BOOL] FALSE\n",
      "[NULL_ANSWER]\n",
      "[BOOL] FALSE\n",
      "[NULL_ANSWER]\n",
      "defaultdict(<class 'int'>, {'negative': 214, 'set': 1, 'argmin': 1, 'atomic_boolean': 2, 'atomic_extractive': 1})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"LABEL\")\n",
    "type_counts = defaultdict(int)\n",
    "for exp in experiments:\n",
    "    if exp[\"version\"] == \"v2.2\" and exp[\"lr\"] == \"8e-5\" and exp[\"train_percentage\"]==100:\n",
    "        for item in exp[\"raw\"]:\n",
    "            if item[0].split(\" \")[0] != item[1].split(\" \")[0]:\n",
    "                test_instance = item[3]\n",
    "                if test_instance[\"type\"]!=\"negative\":\n",
    "                    print(item[0])\n",
    "                    print(item[1])\n",
    "                type_counts[test_instance[\"type\"]] +=1\n",
    "\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "print(type_counts)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVES\n",
      "defaultdict(<class 'int'>, {'argmin': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "print(\"FALSE NEGATIVES\")\n",
    "type_counts = defaultdict(int)\n",
    "for exp in experiments:\n",
    "    if exp[\"version\"] == \"v2.2\" and exp[\"lr\"] == \"8e-5\" and exp[\"train_percentage\"]==100:\n",
    "        for item in exp[\"raw\"]:\n",
    "        # for item in random.sample(exp[\"raw\"],k=100):\n",
    "            if \"[NULL_ANSWER]\" in item[0] and item[2]<1:\n",
    "                test_instance = item[3]\n",
    "                type_counts[test_instance[\"type\"]] +=1\n",
    "                #print(\"*\"*80)\n",
    "                #print(\"Score\\t\\t\",item[2])\n",
    "                #print(\"Query\\t\\t\",item[3][\"query\"])\n",
    "                #print(\"Fact\\t\\t\",item[3][\"fact\"])\n",
    "                #print(\"Projection\\t\\t\",item[3][\"projection\"])\n",
    "                ##print(\"Projection (tokenized)\\t\\t\", item[1])\n",
    "                #print(\"Predicted (tokenized)\\t\\t\", item[0])\n",
    "\n",
    "print(type_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE POSITIVES\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has been to the fewest universities?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Jacques Attali did their undergraduate at Sciences Po']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Jacques Attali [SEP] Sciences Po\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Xuxa works as a television actor']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Xuxa [SEP] television actor\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 2246 inhabitants of Storvik']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Storvik [SEP] 2246\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Natalia Kowalska works as a racing automobile driver']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] racing automobile driver [SEP] Natalia Kowalska\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Tim Schafer's job is a screenwriter\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] screenwriter [SEP] Tim Schafer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has the fewest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Joe McGuire is a politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] politician [SEP] Joe McGuire\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has had the most people die there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Hanau is where Countess Johanna Magdalene of Hanau-Lichtenberg died']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Hanau [SEP] Countess Johanna Magdalene of Hanau-Lichtenberg\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Herman Kahn works as a mathematician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] mathematician [SEP] Herman Kahn\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Agutaya and Araceli are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Agutaya [SEP] Araceli\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Tiviers is neighbour with Saint-Georges.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Tiviers [SEP] Saint-Georges\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the largest number of citizens?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['United States of America recognizes Bruce Graham as its citizen.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] United States of America [SEP] Bruce Graham\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Fluquires is 220']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Fluquires [SEP] 220\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Firmat is 25757']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Firmat [SEP] 25757\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Jamie Green's job is a racing automobile driver\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] racing automobile driver [SEP] Jamie Green\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Hultehouse is neighbour with Garrebourg.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Garrebourg [SEP] Hultehouse\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Veit Bach's job is a musician\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] musician [SEP] Veit Bach\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the highest number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Bill Holcombe is a composer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bill Holcombe [SEP] composer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Notzingen is 3627']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Notzingen [SEP] 3627\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Gyr-Moson-Sopron County and Veszprm County are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Gyr-Moson-Sopron County [SEP] Veszprm County\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Pedro do Rosrio is 22732']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Pedro do Rosrio [SEP] 22732\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Ally Kerr's job is a songwriter\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ally Kerr [SEP] songwriter\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Jennifer Tung works as a actor']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] actor [SEP] Jennifer Tung\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular gender?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The gender of Paulo Assuno is male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] male [SEP] Paulo Assuno\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Fontenay-le-Marmion shares a border with May-sur-Orne.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Fontenay-le-Marmion [SEP] May-sur-Orne\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What university has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Chris Kanyon studied their degree at University at Buffalo']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] University at Buffalo [SEP] Chris Kanyon\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has had the highest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"August Varenius's job is a theologian\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] theologian [SEP] August Varenius\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Guguan is 0']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Guguan [SEP] 0\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which team has the most players?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Erik Heijblok is a part of FC Volendam']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] FC Volendam [SEP] Erik Heijblok\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the biggest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Forssa is 17833']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Forssa [SEP] 17833\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Camurac and Belcaire are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Camurac [SEP] Belcaire\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t How many people are writer?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Private School was written by Dan Greenburg']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [COUNT] Dan Greenburg\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Molandier is neighbour with Belpech.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Molandier [SEP] Belpech\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the largest number of citizens?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['France recognizes Heinrich Scheuch as its citizen.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] France [SEP] Heinrich Scheuch\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the highest number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Tommy Aldridge is a drummer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Tommy Aldridge [SEP] drummer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 386 inhabitants of Soye']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Soye [SEP] 386\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Hofamt Priel shares a border with Sankt Oswald, Lower Austria.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Hofamt Priel [SEP] Sankt Oswald, Lower Austria\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What school has the fewest students?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Monier Monier-Williams did their undergraduate at King's College School\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] King's College School [SEP] Monier Monier-Williams\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Paul Funk is a mathematician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] mathematician [SEP] Paul Funk\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Gillian Rolton works as a event rider']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] event rider [SEP] Gillian Rolton\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has the fewest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Anatoly Lunacharsky is a politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] politician [SEP] Anatoly Lunacharsky\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The number of people at 21st World Scout Jamboree was 38074']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] 21st World Scout Jamboree [SEP] 38074\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which gender has the most people?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Sigmund Exner is male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] male [SEP] Sigmund Exner\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Bernard Consten's job is a racing automobile driver\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] racing automobile driver [SEP] Bernard Consten\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t How many nationals does Germany have?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Erdmann Kopernikus has the citizenship of Germany']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [COUNT] Erdmann Kopernikus\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Quebec is where Andr Ouellet was born']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Quebec [SEP] Andr Ouellet\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Norbert Reithofer is a entrepreneur']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] entrepreneur [SEP] Norbert Reithofer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 1351 inhabitants of Almoster']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Almoster [SEP] 1351\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has the fewest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Mgrdi Margosyan's job is a writer\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] writer [SEP] Mgrdi Margosyan\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Wolpertshausen is 2041']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Wolpertshausen [SEP] 2041\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the fewest jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Giulio Paolini works as a photographer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Giulio Paolini [SEP] photographer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has played for the fewest teams?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Bauke Mollema is a member of Trek-Segafredo']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bauke Mollema [SEP] Trek-Segafredo\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has had the highest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Phil Zimmermann's job is a computer scientist\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] computer scientist [SEP] Phil Zimmermann\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Tartu County is a neighbour of Plva County.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Tartu County [SEP] Plva County\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Viggianello and Fozzano are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Viggianello [SEP] Fozzano\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has the fewest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Quintus Aiacius Modestus Crescentianus's job is a politician\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] politician [SEP] Quintus Aiacius Modestus Crescentianus\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the fewest jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Francesc d'Asss Gal is a painter\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Francesc d'Asss Gal [SEP] painter\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has had the highest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Cornelius van Bynkershoek's job is a legal counsel\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] legal counsel [SEP] Cornelius van Bynkershoek\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Sidi Mohamed Ould Boubacar works as a politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] politician [SEP] Sidi Mohamed Ould Boubacar\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place had the least people born there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Dorothea Christina of Aichelberg was born in Pln']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Pln [SEP] Dorothea Christina of Aichelberg\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has had the highest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Joe Benton is a politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] politician [SEP] Joe Benton\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Christa Prets was born in Diez']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Diez [SEP] Christa Prets\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Sachiko Kobayashi's job is a seiy\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Sachiko Kobayashi [SEP] seiy\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 726 inhabitants of Stlky']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Stlky [SEP] 726\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the fewest jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Mascha Kalko works as a writer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Mascha Kalko [SEP] writer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Oberhausen-Rheinhausen is 7699']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Oberhausen-Rheinhausen [SEP] 7699\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people born there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Prostjov is where Nathan Porges was born']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Prostjov [SEP] Nathan Porges\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Fontenay-le-Marmion and Fresney-le-Puceux share borders with each other.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Fontenay-le-Marmion [SEP] Fresney-le-Puceux\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 170 inhabitants of Little Sioux']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Little Sioux [SEP] 170\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Fontenelle is 157']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Fontenelle [SEP] 157\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Martigny-Courpierre is neighbour with Bruyres-et-Montbrault.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Martigny-Courpierre [SEP] Bruyres-et-Montbrault\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the team with the most players?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Jesper Olsen is a part of Denmark national football team']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Denmark national football team [SEP] Jesper Olsen\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Whow many people study?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Dirk Fock studied their undergraduate at Leiden University']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [COUNT] Dirk Fock\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which team has the fewest players?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Kelly Smith is a member of Arsenal F.C.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Arsenal F.C. [SEP] Kelly Smith\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the fewest jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Anton von Ruthner's job is a writer\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Anton von Ruthner [SEP] writer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Yssingeaux is where Jacques Barrot was born']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Yssingeaux [SEP] Jacques Barrot\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the highest number of nationals?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Nazi Germany recognizes Viktor Lutze as its citizen.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Nazi Germany [SEP] Viktor Lutze\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has discovered the most things?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Yakov Dzhugashvili studied at Military academy of strategic rocket forces']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Yakov Dzhugashvili [SEP] Military academy of strategic rocket forces\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Doucy-en-Bauges is 99']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Doucy-en-Bauges [SEP] 99\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the lowest number of nationals?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Janes Nielsen is a citizen of Faroe Islands']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Faroe Islands [SEP] Janes Nielsen\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people born there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Krefeld is the place of birth of Wilhelm von Abbema']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Krefeld [SEP] Wilhelm von Abbema\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which team has the lowest number of players?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The league that Radosaw Kauny plays in is Bundesliga']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bundesliga [SEP] Radosaw Kauny\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the lowest number of nationals?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Benjamin White has the nationality of United States of America']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] United States of America [SEP] Benjamin White\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Emil von Schoenaich-Carolath is a writer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] writer [SEP] Emil von Schoenaich-Carolath\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the highest number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Dokgo Young-jae's job is a actor\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Dokgo Young-jae [SEP] actor\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 132 inhabitants of Feyt']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Feyt [SEP] 132\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has had the highest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Caspar Scheuren's job is a painter\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] painter [SEP] Caspar Scheuren\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the team with the fewest players?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Associazione Calcio Milan's membership includes Marco Simone\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Associazione Calcio Milan [SEP] Marco Simone\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Roman Catholic Diocese of Bac Ninh is 8061000']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Roman Catholic Diocese of Bac Ninh [SEP] 8061000\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Whow many people study?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['One of the students at RESAD was Josep Maria Pou']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [COUNT] Josep Maria Pou\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Ruggiero Ricci is a musician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ruggiero Ricci [SEP] musician\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Mgrdi Margosyan's job is a writer\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] writer [SEP] Mgrdi Margosyan\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Le Vernet-Chamane is neighbour with Saint-Quentin-sur-Sauxillanges.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Quentin-sur-Sauxillanges [SEP] Le Vernet-Chamane\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which places have the most people die there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Bautzen is where August Adolf von Haugwitz died']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bautzen [SEP] August Adolf von Haugwitz\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['John R. Neill is a writer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] John R. Neill [SEP] writer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Villemomble is neighbour with Les Pavillons-sous-Bois.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Villemomble [SEP] Les Pavillons-sous-Bois\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the smallest team?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Rildo da Costa Menezes is a member of Cleveland Cobras']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Cleveland Cobras [SEP] Rildo da Costa Menezes\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Landl and Wildalpen share borders with each other.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Wildalpen [SEP] Landl\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Diocese of Prizren is neighbour with Roman Catholic Archdiocese of Belgrade.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Roman Catholic Archdiocese of Belgrade [SEP] Diocese of Prizren\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Aubigny-la-Ronce and Molinot share borders with each other.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Molinot [SEP] Aubigny-la-Ronce\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Spanish Fork is 36956']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Spanish Fork [SEP] 36956\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Vescovana and Granze are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Granze [SEP] Vescovana\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has the fewest children?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Duke Xian of Qi is a parent of Duke Wu of Qi']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Duke Xian of Qi [SEP] Duke Wu of Qi\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 4640 people living in Esporles']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Esporles [SEP] 4640\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 1216 inhabitants of Velk Losenice']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Velk Losenice [SEP] 1216\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Does Nicole live in United Kingdom?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Nicole was born in Clarks Summit in 1975.', 'Ramona was born in 1990. At the time, her parents lived in Malters.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Alfred Capus is a playwright']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] playwright [SEP] Alfred Capus\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which places have the most people die there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Hohenasperg is where Albert Rapp died']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Hohenasperg [SEP] Albert Rapp\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the most jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Philo of Byzantium is a writer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Philo of Byzantium [SEP] writer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Iglesias shares a border with Siliqua, Sardinia.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Siliqua, Sardinia [SEP] Iglesias\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Ribeiro Preto is 604682']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ribeiro Preto [SEP] 604682\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the fewest jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Hermann Usener is a religious studies scholar']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Hermann Usener [SEP] religious studies scholar\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people born there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Accra is the place of birth of Jerry Rawlings']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Accra [SEP] Jerry Rawlings\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Where is the place where the fewest people have died?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Nikolai Patolichev died in Moscow']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Moscow [SEP] Nikolai Patolichev\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has gone to university?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Carolyn Bessette-Kennedy studied their undergraduate at Boston University']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Carolyn Bessette-Kennedy\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Joseph Wharton works as a business magnate']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Joseph Wharton [SEP] business magnate\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which team has the least players?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Alessandro Abbondanza plays for A.C. Pisa 1909']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] A.C. Pisa 1909 [SEP] Alessandro Abbondanza\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Troissy and Igny-Comblizy are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Igny-Comblizy [SEP] Troissy\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 16730 inhabitants of Hockenheim']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Hockenheim [SEP] 16730\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Panketal and Ahrensfelde are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ahrensfelde [SEP] Panketal\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the most births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Vienna is the place of birth of August Hornbostel']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Vienna [SEP] August Hornbostel\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the highest number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Jules Perrot's job is a choreographer\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Jules Perrot [SEP] choreographer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular gender?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Philipp Scharwenka is male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] male [SEP] Philipp Scharwenka\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 563 people living in Crace']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Crace [SEP] 563\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 16204 people living in ternberk']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] ternberk [SEP] 16204\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Joseph Salvat's job is a linguist\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] linguist [SEP] Joseph Salvat\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Oradour and Czens are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Oradour [SEP] Czens\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the biggest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 25197 people living in Balaoan']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Balaoan [SEP] 25197\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Bad Kissingen is 20802']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bad Kissingen [SEP] 20802\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 263 people living in Wembach']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Wembach [SEP] 263\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the biggest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 560 inhabitants of Saint-Fraimbault']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Fraimbault [SEP] 560\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t How many neighbours does Garching bei Mnchen have?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 7469 people living in Garching bei Mnchen']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [COUNT] 7469\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 47961 people living in Akoubounou']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Akoubounou [SEP] 47961\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Campitello shares a border with Scolca.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Campitello [SEP] Scolca\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the fewest number of citizens?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Finland recognizes Masi Marjamki as its citizen.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Finland [SEP] Masi Marjamki\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Eastern Anatolia Region is a neighbour of Caucasus.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Caucasus [SEP] Eastern Anatolia Region\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Budrio and Castenaso are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Castenaso [SEP] Budrio\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Saint-Claude and Septmoncel are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Septmoncel [SEP] Saint-Claude\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Saint-Vincent-de-Paul is a neighbour of Ambars-et-Lagrave.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ambars-et-Lagrave [SEP] Saint-Vincent-de-Paul\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the biggest university?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Yun Dong-ju studied their degree at Rikkyo University']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Rikkyo University [SEP] Yun Dong-ju\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 1249 inhabitants of Unterleinleiter']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Unterleinleiter [SEP] 1249\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the fewest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Santo Domingo is the place of birth of Adolfo Alejandro Nouel']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Santo Domingo [SEP] Adolfo Alejandro Nouel\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Aubilly and Bligny are neighbours.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bligny [SEP] Aubilly\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who is a politician?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Franoise Giroud is a politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Franoise Giroud\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Nov Sdla is 221']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Nov Sdla [SEP] 221\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 18965 inhabitants of Sylvania']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Sylvania [SEP] 18965\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t List everyone who is male\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Karl Bertsch is a male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Karl Bertsch\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Michael II Asen works as a monarch']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] monarch [SEP] Michael II Asen\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Bavans is a neighbour of Voujeaucourt.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bavans [SEP] Voujeaucourt\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which university has had the most students?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Dan Quayle studied their degree at Indiana University Robert H. McKinney School of Law']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Indiana University Robert H. McKinney School of Law [SEP] Dan Quayle\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has the fewest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Ruggiero Ricci's job is a music pedagogue\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] music pedagogue [SEP] Ruggiero Ricci\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular university?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Lloyd Alexander studied their undergraduate at University of Paris']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] University of Paris [SEP] Lloyd Alexander\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Garza County is 6415']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Garza County [SEP] 6415\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who are the nationals of Germany?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Hermann Bcker has the nationality of Germany']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Angern an der March shares a border with Ebenthal, Lower Austria.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ebenthal, Lower Austria [SEP] Angern an der March\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Kenny Dorham works as a composer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Kenny Dorham [SEP] composer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Bannay is 71']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bannay [SEP] 71\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Koryany is a neighbour of Stlky.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Koryany [SEP] Stlky\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the least popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Jhann Jhannsson's job is a composer\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] composer [SEP] Jhann Jhannsson\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the fewest number of citizens?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Joseph A. Pepe has the citizenship of United States of America']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] United States of America [SEP] Joseph A. Pepe\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 419 inhabitants of Mrey-sous-Montrond']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Mrey-sous-Montrond [SEP] 419\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Condeissiat is a neighbour of Saint-Andr-sur-Vieux-Jonc.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Condeissiat [SEP] Saint-Andr-sur-Vieux-Jonc\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Orignolles is neighbour with Clrac.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Orignolles [SEP] Clrac\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which team has the highest number of players?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Czech Republic women's national volleyball team's membership includes Julie Kovov\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Czech Republic women's national volleyball team [SEP] Julie Kovov\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who is male?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['William Brewster is a male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] William Brewster\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the fewest number of citizens?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Chile recognizes Ena von Baer as its citizen.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Chile [SEP] Ena von Baer\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place is the birthplace of the most people?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Chris Cunningham was born in Reading']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Reading [SEP] Chris Cunningham\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Andrea Bianchi was born in Rome']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Rome [SEP] Andrea Bianchi\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the biggest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Roggliswil is 706']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Roggliswil [SEP] 706\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Adolf Schnrle is a engineer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] engineer [SEP] Adolf Schnrle\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 82053 people living in eDumbe Local Municipality']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] eDumbe Local Municipality [SEP] 82053\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Margaret of Austria, Queen of Bohemia is a sovereign']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] sovereign [SEP] Margaret of Austria, Queen of Bohemia\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 115530 inhabitants of Saint-Brieuc Agglomration Baie dArmor']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Brieuc Agglomration Baie dArmor [SEP] 115530\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place is the birthplace of the fewest people?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['L. F. L. Oppenheim was born in Windecken']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Windecken [SEP] L. F. L. Oppenheim\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which university has had the fewest students?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Shara Proctor's alma mater is University of Florida\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] University of Florida [SEP] Shara Proctor\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 6100000 inhabitants of Eastern Anatolia Region']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Eastern Anatolia Region [SEP] 6100000\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Morgex is neighbour with Pr-Saint-Didier.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Pr-Saint-Didier [SEP] Morgex\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has the fewest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Ken-Ichiro Kobayashi is a composer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] composer [SEP] Ken-Ichiro Kobayashi\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which country has the highest number of nationals?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Jacob Binck is a citizen of Germany']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Germany [SEP] Jacob Binck\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Worthing is the place of birth of Thomas Sackville, 1st Earl of Dorset']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Worthing [SEP] Thomas Sackville, 1st Earl of Dorset\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t How many people are male?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Chris von Rohr is male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [COUNT] Chris von Rohr\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Foncea shares a border with Bugedo.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bugedo [SEP] Foncea\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Louis I, Prince of Anhalt-Kthen's job is a writer\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] writer [SEP] Louis I, Prince of Anhalt-Kthen\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Olinka Hardiman's job is a actor\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] actor [SEP] Olinka Hardiman\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the highest number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Werner Greuter works as a curator']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Werner Greuter [SEP] curator\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most inhabited place?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 7891 people living in Millis']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Millis [SEP] 7891\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Burgille is neighbour with Courchapon.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Courchapon [SEP] Burgille\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Where have the most people studied?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Johann Anton Leisewitz was a student at University of Gttingen']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] University of Gttingen [SEP] Johann Anton Leisewitz\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which places has had the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Bilbao is the place of birth of Jon Kortajarena']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Bilbao [SEP] Jon Kortajarena\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 3524 people living in Notzingen']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Notzingen [SEP] 3524\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has been to the fewest universities?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Franz Meyen studied their degree at Humboldt University of Berlin']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Franz Meyen [SEP] Humboldt University of Berlin\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Is Pierre really into photography?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Pierre is employed by Datawave Systems Inc. as a cinematographer.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who are the nationals of Germany?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Germany recognizes Hans Walter Wolff as its citizen.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has studied the most?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Guillermo Gonzlez Camarena was a student at National Polytechnic Institute']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Guillermo Gonzlez Camarena [SEP] National Polytechnic Institute\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the least number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Walley Barnes was born in Brecon']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Brecon [SEP] Walley Barnes\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which team has the most players?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Jaap Stam is a member of Associazione Calcio Milan']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Associazione Calcio Milan [SEP] Jaap Stam\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has been to the fewest universities?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Louis d'Aurelle de Paladines studied their undergraduate at Prytane National Militaire\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Louis d'Aurelle de Paladines [SEP] Prytane National Militaire\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the highest number of births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Wagga Wagga is where Nathan Hines was born']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Wagga Wagga [SEP] Nathan Hines\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Carter County is a neighbour of Mitchell County.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Mitchell County [SEP] Carter County\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has played for the least number of different teams?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Alexandre Alphonse plays for FC La Chaux-de-Fonds']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Alexandre Alphonse [SEP] FC La Chaux-de-Fonds\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t For how long did Brendan lived in Jakarta?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Brendan was born in 1986. At the time, his parents lived in Hay River.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Casatisma is neighbour with Castelletto di Branduzzo.']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Castelletto di Branduzzo [SEP] Casatisma\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the biggest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 168 inhabitants of Fterr']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Fterr [SEP] 168\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the fewest people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 1483 inhabitants of Evadale']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Evadale [SEP] 1483\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t List everyone born in Dobrich\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Weilburg is where Hermann Usener was born']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Hermann Usener\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the most popular job?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Lucius Appuleius Saturninus is a Ancient Roman politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ancient Roman politician [SEP] Lucius Appuleius Saturninus\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the smallest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The population of Villademor de la Vega is 349']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Villademor de la Vega [SEP] 349\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has studied the most?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Benjamin Dean Wyatt's alma mater is Westminster School\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Benjamin Dean Wyatt [SEP] Westminster School\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the most jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Roman Malinowski is a politician']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Roman Malinowski [SEP] politician\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Where have the fewest people studied?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Rolf Maximilian Sievert studied at Royal Institute of Technology']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Royal Institute of Technology [SEP] Rolf Maximilian Sievert\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which people are male?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['The gender of Marduk-apla-iddina I is male']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [SET] Marduk-apla-iddina I\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Which place has the biggest population?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 128 inhabitants of Mietice']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Mietice [SEP] 128\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What job has had the highest number of people working there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Eberhard Junkersdorf is a film producer']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] film producer [SEP] Eberhard Junkersdorf\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the most jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Michel Bral works as a linguist']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Michel Bral [SEP] linguist\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Who has had the least number of jobs?\n",
      "Type\t\t negative\n",
      "Fact\t\t [\"Hermann Kutschera's job is a architect\"]\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Hermann Kutschera [SEP] architect\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What is the place with the most births?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Wschowa is the place of birth of Melchior Teschner']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Wschowa [SEP] Melchior Teschner\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t Where is the place where the fewest people have died?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['Big Maybelle died in Ohio']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Ohio [SEP] Big Maybelle\n",
      "********************************************************************************\n",
      "Score\t\t 0.0\n",
      "Query\t\t What place has the most people living there?\n",
      "Type\t\t negative\n",
      "Fact\t\t ['There are 229484 people living in Vitoria-Gasteiz']\n",
      "Projection\t\t None\n",
      "Projection (tokenized)\t\t [NULL_ANSWER]\n",
      "Predicted (tokenized)\t\t [ARG] Vitoria-Gasteiz [SEP] 229484\n",
      "defaultdict(<class 'int'>, {'negative': 214, 'atomic_boolean': 2, 'atomic_extractive': 1})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "print(\"FALSE POSITIVES\")\n",
    "type_counts = defaultdict(int)\n",
    "for exp in experiments:\n",
    "    if exp[\"version\"] == \"v2.2\" and exp[\"lr\"] == \"8e-5\" and exp[\"train_percentage\"]==100:\n",
    "        for item in exp[\"raw\"]:\n",
    "            if \"[NULL_ANSWER]\" in item[1] and item[2]<1:\n",
    "                test_instance = item[3]\n",
    "                type_counts[test_instance[\"type\"]] +=1\n",
    "                print(\"*\"*80)\n",
    "                print(\"Score\\t\\t\",item[2])\n",
    "                print(\"Query\\t\\t\",item[3][\"query\"])\n",
    "                print(\"Type\\t\\t\",item[3][\"type\"])\n",
    "                print(\"Fact\\t\\t\",item[3][\"fact\"])\n",
    "                print(\"Projection\\t\\t\",item[3][\"projection\"])\n",
    "                print(\"Projection (tokenized)\\t\\t\", item[1])\n",
    "                print(\"Predicted (tokenized)\\t\\t\", item[0])\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "print(type_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANS ERROR\n",
      "********************************************************************************\n",
      "Score\t\t 0.30000000000000004\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Noyelles-en-Chausse and Yvrench share borders with each other.']\n",
      "Projection\t\t Yvrench [SEP] Noyelles-en-Chausse\n",
      "Projection (tokenized)\t\t [ARG] Yvrench [SEP] Noyelles-en-Chausse\n",
      "Predicted (tokenized)\t\t [ARG] Noyelles-en-Chausse [SEP] Yvrench\n",
      "********************************************************************************\n",
      "Score\t\t 0.2682926829268293\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Marchville-en-Wovre and Maizeray are neighbours.']\n",
      "Projection\t\t Maizeray [SEP] Marchville-en-Wovre\n",
      "Projection (tokenized)\t\t [ARG] Maizeray [SEP] Marchville-en-Wovre\n",
      "Predicted (tokenized)\t\t [ARG] Marchville-en-Wovre [SEP] Maizeray\n",
      "********************************************************************************\n",
      "Score\t\t 0.6296296296296297\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['South Hamgyong Province is a neighbour of Ryanggang Province.']\n",
      "Projection\t\t Ryanggang Province [SEP] South Hamgyong Province\n",
      "Projection (tokenized)\t\t [ARG] Ryanggang Province [SEP] South Hamgyong Province\n",
      "Predicted (tokenized)\t\t [ARG] South Hamgyong Province [SEP] Ryanggang Province\n",
      "********************************************************************************\n",
      "Score\t\t 0.4782608695652174\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Gaby and Issime share borders with each other.']\n",
      "Projection\t\t Issime [SEP] Gaby\n",
      "Projection (tokenized)\t\t [ARG] Issime [SEP] Gaby\n",
      "Predicted (tokenized)\t\t [ARG] Gaby [SEP] Issime\n",
      "********************************************************************************\n",
      "Score\t\t 0.52\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Duneau and Beill are neighbours.']\n",
      "Projection\t\t Beill [SEP] Duneau\n",
      "Projection (tokenized)\t\t [ARG] Beill [SEP] Duneau\n",
      "Predicted (tokenized)\t\t [ARG] Duneau [SEP] Beill\n",
      "********************************************************************************\n",
      "Score\t\t 0.5897435897435898\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Gmina Poskinia is neighbour with Gmina Mynary.']\n",
      "Projection\t\t Gmina Poskinia [SEP] Gmina Mynary\n",
      "Projection (tokenized)\t\t [ARG] Gmina Poskinia [SEP] Gmina Mynary\n",
      "Predicted (tokenized)\t\t [ARG] Gmina Mynary [SEP] Gmina Poskinia\n",
      "********************************************************************************\n",
      "Score\t\t 0.21052631578947367\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Au am Leithaberge is a neighbour of Stotzing.']\n",
      "Projection\t\t Au am Leithaberge [SEP] Stotzing\n",
      "Projection (tokenized)\t\t [ARG] Au am Leithaberge [SEP] Stotzing\n",
      "Predicted (tokenized)\t\t [ARG] Stotzing [SEP] Au am Leithaberge\n",
      "********************************************************************************\n",
      "Score\t\t 0.22580645161290325\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Poc-les-Bois is neighbour with Vitr.']\n",
      "Projection\t\t Poc-les-Bois [SEP] Vitr\n",
      "Projection (tokenized)\t\t [ARG] Poc-les-Bois [SEP] Vitr\n",
      "Predicted (tokenized)\t\t [ARG] Vitr [SEP] Poc-les-Bois\n",
      "********************************************************************************\n",
      "Score\t\t 0.4117647058823529\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Dy and Flogny-la-Chapelle share borders with each other.']\n",
      "Projection\t\t Dy [SEP] Flogny-la-Chapelle\n",
      "Projection (tokenized)\t\t [ARG] Dy [SEP] Flogny-la-Chapelle\n",
      "Predicted (tokenized)\t\t [ARG] Flogny-la-Chapelle [SEP] Dy\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Aleksandr born in Germany?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1957, Aleksandr's parents lived in Ulyanovsk when he was born.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Pordic and Binic are neighbours.']\n",
      "Projection\t\t Binic [SEP] Pordic\n",
      "Projection (tokenized)\t\t [ARG] Binic [SEP] Pordic\n",
      "Predicted (tokenized)\t\t [ARG] Pordic [SEP] Binic\n",
      "********************************************************************************\n",
      "Score\t\t 0.7333333333333334\n",
      "Query\t\t Where is Tenochtitlan the ruler?\n",
      "Type\t\t set\n",
      "Fact\t\t ['Tenochtitlan is the official with the highest formal authority in Itzcoatl.']\n",
      "Projection\t\t Itzcoatl\n",
      "Projection (tokenized)\t\t [SET] Itzcoatl\n",
      "Predicted (tokenized)\t\t [BOOL] Itzcoatl\n",
      "********************************************************************************\n",
      "Score\t\t 0.3023255813953488\n",
      "Query\t\t Which country has the fewest leaders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Republic of Ezo is the official with the highest formal authority in Enomoto Takeaki.']\n",
      "Projection\t\t Enomoto Takeaki [SEP] Republic of Ezo\n",
      "Projection (tokenized)\t\t [ARG] Enomoto Takeaki [SEP] Republic of Ezo\n",
      "Predicted (tokenized)\t\t [ARG] Republic of Ezo [SEP] Enomoto Takeaki\n",
      "********************************************************************************\n",
      "Score\t\t 0.3142857142857143\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Saint-Antoine is a neighbour of Flamarens.']\n",
      "Projection\t\t Saint-Antoine [SEP] Flamarens\n",
      "Projection (tokenized)\t\t [ARG] Saint-Antoine [SEP] Flamarens\n",
      "Predicted (tokenized)\t\t [ARG] Flamarens [SEP] Saint-Antoine\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Trina born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Trina was born in Royal Leamington Spa in 1969.']\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.4054054054054054\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Gmina Brenna and Bielsko-Biaa share borders with each other.']\n",
      "Projection\t\t Bielsko-Biaa [SEP] Gmina Brenna\n",
      "Projection (tokenized)\t\t [ARG] Bielsko-Biaa [SEP] Gmina Brenna\n",
      "Predicted (tokenized)\t\t [ARG] Gmina Brenna [SEP] Bielsko-Biaa\n",
      "********************************************************************************\n",
      "Score\t\t 0.6756756756756757\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Gibson County is neighbour with Dyer County.']\n",
      "Projection\t\t Dyer County [SEP] Gibson County\n",
      "Projection (tokenized)\t\t [ARG] Dyer County [SEP] Gibson County\n",
      "Predicted (tokenized)\t\t [ARG] Gibson County [SEP] Dyer County\n",
      "********************************************************************************\n",
      "Score\t\t 0.4666666666666667\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Landl is neighbour with Altenmarkt bei Sankt Gallen.']\n",
      "Projection\t\t Altenmarkt bei Sankt Gallen [SEP] Landl\n",
      "Projection (tokenized)\t\t [ARG] Altenmarkt bei Sankt Gallen [SEP] Landl\n",
      "Predicted (tokenized)\t\t [ARG] Landl [SEP] Altenmarkt bei Sankt Gallen\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which country was Alicia born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Alicia was born in Rosario in 1953.']\n",
      "Projection\t\t Argentina\n",
      "Projection (tokenized)\t\t [BOOL] Argentina\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.34615384615384615\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Mato Grosso do Sul is neighbour with Santa Cruz Department.']\n",
      "Projection\t\t Santa Cruz Department [SEP] Mato Grosso do Sul\n",
      "Projection (tokenized)\t\t [ARG] Santa Cruz Department [SEP] Mato Grosso do Sul\n",
      "Predicted (tokenized)\t\t [ARG] Mato Grosso do Sul [SEP] Santa Cruz Department\n",
      "********************************************************************************\n",
      "Score\t\t 0.7297297297297297\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Putnam County shares a border with Clay County.']\n",
      "Projection\t\t Putnam County [SEP] Clay County\n",
      "Projection (tokenized)\t\t [ARG] Putnam County [SEP] Clay County\n",
      "Predicted (tokenized)\t\t [ARG] Clay County [SEP] Putnam County\n",
      "********************************************************************************\n",
      "Score\t\t 0.4193548387096774\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Chambeire and Longchamp share borders with each other.']\n",
      "Projection\t\t Longchamp [SEP] Chambeire\n",
      "Projection (tokenized)\t\t [ARG] Longchamp [SEP] Chambeire\n",
      "Predicted (tokenized)\t\t [ARG] Chambeire [SEP] Longchamp\n",
      "********************************************************************************\n",
      "Score\t\t 0.5714285714285714\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Charlevoix County and Emmet County are neighbours.']\n",
      "Projection\t\t Charlevoix County [SEP] Emmet County\n",
      "Projection (tokenized)\t\t [ARG] Charlevoix County [SEP] Emmet County\n",
      "Predicted (tokenized)\t\t [ARG] Emmet County [SEP] Charlevoix County\n",
      "********************************************************************************\n",
      "Score\t\t 0.34693877551020413\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Scandicci is neighbour with San Casciano in Val di Pesa.']\n",
      "Projection\t\t Scandicci [SEP] San Casciano in Val di Pesa\n",
      "Projection (tokenized)\t\t [ARG] Scandicci [SEP] San Casciano in Val di Pesa\n",
      "Predicted (tokenized)\t\t [ARG] San Casciano in Val di Pesa [SEP] Scandicci\n",
      "********************************************************************************\n",
      "Score\t\t 0.3142857142857143\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Landresse is neighbour with Germfontaine.']\n",
      "Projection\t\t Germfontaine [SEP] Landresse\n",
      "Projection (tokenized)\t\t [ARG] Germfontaine [SEP] Landresse\n",
      "Predicted (tokenized)\t\t [ARG] Landresse [SEP] Germfontaine\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Lisa born in United Kingdom?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Lisa was born in 1963. At the time, her parents lived in Silver Spring.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.43999999999999995\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Samoreau shares a border with Avon.']\n",
      "Projection\t\t Avon [SEP] Samoreau\n",
      "Projection (tokenized)\t\t [ARG] Avon [SEP] Samoreau\n",
      "Predicted (tokenized)\t\t [ARG] Samoreau [SEP] Avon\n",
      "********************************************************************************\n",
      "Score\t\t 0.6153846153846154\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Aubilly and Bligny are neighbours.']\n",
      "Projection\t\t Aubilly [SEP] Bligny\n",
      "Projection (tokenized)\t\t [ARG] Aubilly [SEP] Bligny\n",
      "Predicted (tokenized)\t\t [ARG] Bligny [SEP] Aubilly\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Ronny born in Asia?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1966, Ronny's mother gave birth to Ronny in Antwerp.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Stephan born in Italy?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1967, Stephan's mother gave birth to Stephan in Salzgitter.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.31034482758620685\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Aretxabaleta and Oati share borders with each other.']\n",
      "Projection\t\t Aretxabaleta [SEP] Oati\n",
      "Projection (tokenized)\t\t [ARG] Aretxabaleta [SEP] Oati\n",
      "Predicted (tokenized)\t\t [ARG] Oati [SEP] Aretxabaleta\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which country was Ken born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Ken was born in Windsor in 1964.']\n",
      "Projection\t\t Canada\n",
      "Projection (tokenized)\t\t [BOOL] Canada\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.40740740740740744\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Misserghin and Oran share borders with each other.']\n",
      "Projection\t\t Misserghin [SEP] Oran\n",
      "Projection (tokenized)\t\t [ARG] Misserghin [SEP] Oran\n",
      "Predicted (tokenized)\t\t [ARG] Oran [SEP] Misserghin\n",
      "********************************************************************************\n",
      "Score\t\t 0.375\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Die shares a border with Solaure-en-Diois.']\n",
      "Projection\t\t Die [SEP] Solaure-en-Diois\n",
      "Projection (tokenized)\t\t [ARG] Die [SEP] Solaure-en-Diois\n",
      "Predicted (tokenized)\t\t [ARG] Solaure-en-Diois [SEP] Die\n",
      "********************************************************************************\n",
      "Score\t\t 0.375\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Lignerolles and Prpotin share borders with each other.']\n",
      "Projection\t\t Lignerolles [SEP] Prpotin\n",
      "Projection (tokenized)\t\t [ARG] Lignerolles [SEP] Prpotin\n",
      "Predicted (tokenized)\t\t [ARG] Prpotin [SEP] Lignerolles\n",
      "********************************************************************************\n",
      "Score\t\t 0.31999999999999995\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Chiclana de la Frontera shares a border with Medina Sidonia.']\n",
      "Projection\t\t Medina Sidonia [SEP] Chiclana de la Frontera\n",
      "Projection (tokenized)\t\t [ARG] Medina Sidonia [SEP] Chiclana de la Frontera\n",
      "Predicted (tokenized)\t\t [ARG] Chiclana de la Frontera [SEP] Medina Sidonia\n",
      "********************************************************************************\n",
      "Score\t\t 0.43999999999999995\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Allauch and Mimet share borders with each other.']\n",
      "Projection\t\t Allauch [SEP] Mimet\n",
      "Projection (tokenized)\t\t [ARG] Allauch [SEP] Mimet\n",
      "Predicted (tokenized)\t\t [ARG] Mimet [SEP] Allauch\n",
      "********************************************************************************\n",
      "Score\t\t 0.8333333333333334\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Province of Venice and Province of Udine share borders with each other.']\n",
      "Projection\t\t Province of Venice [SEP] Province of Udine\n",
      "Projection (tokenized)\t\t [ARG] Province of Venice [SEP] Province of Udine\n",
      "Predicted (tokenized)\t\t [ARG] Province of Udine [SEP] Province of Venice\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Anthony born in North America?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1987, Anthony's mother gave birth to Anthony in Aubenas.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.33333333333333337\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Troissy and Igny-Comblizy are neighbours.']\n",
      "Projection\t\t Troissy [SEP] Igny-Comblizy\n",
      "Projection (tokenized)\t\t [ARG] Troissy [SEP] Igny-Comblizy\n",
      "Predicted (tokenized)\t\t [ARG] Igny-Comblizy [SEP] Troissy\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Trmloir and Pordic are neighbours.']\n",
      "Projection\t\t Trmloir [SEP] Pordic\n",
      "Projection (tokenized)\t\t [ARG] Trmloir [SEP] Pordic\n",
      "Predicted (tokenized)\t\t [ARG] Pordic [SEP] Trmloir\n",
      "********************************************************************************\n",
      "Score\t\t 0.37142857142857144\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Niedernai and Meistratzheim are neighbours.']\n",
      "Projection\t\t Meistratzheim [SEP] Niedernai\n",
      "Projection (tokenized)\t\t [ARG] Meistratzheim [SEP] Niedernai\n",
      "Predicted (tokenized)\t\t [ARG] Niedernai [SEP] Meistratzheim\n",
      "********************************************************************************\n",
      "Score\t\t 0.75\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Orist is a neighbour of Olost.']\n",
      "Projection\t\t Orist [SEP] Olost\n",
      "Projection (tokenized)\t\t [ARG] Orist [SEP] Olost\n",
      "Predicted (tokenized)\t\t [ARG] Olost [SEP] Orist\n",
      "********************************************************************************\n",
      "Score\t\t 0.2777777777777778\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Saint-Baslemont and Relanges are neighbours.']\n",
      "Projection\t\t Saint-Baslemont [SEP] Relanges\n",
      "Projection (tokenized)\t\t [ARG] Saint-Baslemont [SEP] Relanges\n",
      "Predicted (tokenized)\t\t [ARG] Relanges [SEP] Saint-Baslemont\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t [\"Sant'Oreste shares a border with Stimigliano.\"]\n",
      "Projection\t\t Stimigliano [SEP] Sant'Oreste\n",
      "Projection (tokenized)\t\t [ARG] Stimigliano [SEP] Sant'Oreste\n",
      "Predicted (tokenized)\t\t [ARG] Sant'Oreste [SEP] Stimigliano\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Eriq born in France?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1967, Eriq's mother gave birth to Eriq in Angers.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Steve born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1947, Steve's mother gave birth to Steve in Grimsby.\"]\n",
      "Projection\t\t Europe\n",
      "Projection (tokenized)\t\t [BOOL] Europe\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.36585365853658536\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Ernolsheim-Bruche is neighbour with Duttlenheim.']\n",
      "Projection\t\t Duttlenheim [SEP] Ernolsheim-Bruche\n",
      "Projection (tokenized)\t\t [ARG] Duttlenheim [SEP] Ernolsheim-Bruche\n",
      "Predicted (tokenized)\t\t [ARG] Ernolsheim-Bruche [SEP] Duttlenheim\n",
      "********************************************************************************\n",
      "Score\t\t 0.2941176470588235\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Herzogsdorf and Sankt Gotthard im Mhlkreis share borders with each other.']\n",
      "Projection\t\t Herzogsdorf [SEP] Sankt Gotthard im Mhlkreis\n",
      "Projection (tokenized)\t\t [ARG] Herzogsdorf [SEP] Sankt Gotthard im Mhlkreis\n",
      "Predicted (tokenized)\t\t [ARG] Sankt Gotthard im Mhlkreis [SEP] Herzogsdorf\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Andrew born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Andrew was born in 1968. At the time, his parents lived in Goulburn.']\n",
      "Projection\t\t Oceania\n",
      "Projection (tokenized)\t\t [BOOL] Oceania\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.34693877551020413\n",
      "Query\t\t Which book has the fewest number of authors?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Alessandro Baricco is the author of Castelli di rabbia']\n",
      "Projection\t\t Alessandro Baricco [SEP] Castelli di rabbia\n",
      "Projection (tokenized)\t\t [ARG] Alessandro Baricco [SEP] Castelli di rabbia\n",
      "Predicted (tokenized)\t\t [ARG] Castelli di rabbia [SEP] Alessandro Baricco\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t In which country was Willy born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1954, Willy's parents lived in Diest when he was born.\"]\n",
      "Projection\t\t Belgium\n",
      "Projection (tokenized)\t\t [BOOL] Belgium\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.4375\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Sommecaise and Les Ormes are neighbours.']\n",
      "Projection\t\t Sommecaise [SEP] Les Ormes\n",
      "Projection (tokenized)\t\t [ARG] Sommecaise [SEP] Les Ormes\n",
      "Predicted (tokenized)\t\t [ARG] Les Ormes [SEP] Sommecaise\n",
      "********************************************************************************\n",
      "Score\t\t 0.3157894736842105\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Cardano al Campo and Gallarate are neighbours.']\n",
      "Projection\t\t Gallarate [SEP] Cardano al Campo\n",
      "Projection (tokenized)\t\t [ARG] Gallarate [SEP] Cardano al Campo\n",
      "Predicted (tokenized)\t\t [ARG] Cardano al Campo [SEP] Gallarate\n",
      "********************************************************************************\n",
      "Score\t\t 0.641025641025641\n",
      "Query\t\t What league has the fewest participants?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Lennart Hartmann participates in Bundesliga']\n",
      "Projection\t\t Bundesliga [SEP] Lennart Hartmann\n",
      "Projection (tokenized)\t\t [ARG] Bundesliga [SEP] Lennart Hartmann\n",
      "Predicted (tokenized)\t\t [ARG] Bundesliga [SEP] Bundesliga\n",
      "********************************************************************************\n",
      "Score\t\t 0.5384615384615384\n",
      "Query\t\t In which continent was Ali born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1957, Ali's mother gave birth to Ali in Sabzevar.\"]\n",
      "Projection\t\t Asia\n",
      "Projection (tokenized)\t\t [BOOL] Asia\n",
      "Predicted (tokenized)\t\t [BOOL] Europe\n",
      "********************************************************************************\n",
      "Score\t\t 0.5555555555555556\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Haverlah is a neighbour of Sehlde.']\n",
      "Projection\t\t Sehlde [SEP] Haverlah\n",
      "Projection (tokenized)\t\t [ARG] Sehlde [SEP] Haverlah\n",
      "Predicted (tokenized)\t\t [ARG] Haverlah [SEP] Sehlde\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Is Vernica an actor at Companhia de Alimentos Fargo?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Vernica is a television actor at Companhia de Alimentos Fargo.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.48571428571428577\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Durrenentzen shares a border with Artzenheim.']\n",
      "Projection\t\t Durrenentzen [SEP] Artzenheim\n",
      "Projection (tokenized)\t\t [ARG] Durrenentzen [SEP] Artzenheim\n",
      "Predicted (tokenized)\t\t [ARG] Artzenheim [SEP] Durrenentzen\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Courvires is neighbour with Censeau.']\n",
      "Projection\t\t Censeau [SEP] Courvires\n",
      "Projection (tokenized)\t\t [ARG] Censeau [SEP] Courvires\n",
      "Predicted (tokenized)\t\t [ARG] Courvires [SEP] Censeau\n",
      "********************************************************************************\n",
      "Score\t\t 0.4666666666666667\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Bigorno is a neighbour of Campitello.']\n",
      "Projection\t\t Bigorno [SEP] Campitello\n",
      "Projection (tokenized)\t\t [ARG] Bigorno [SEP] Campitello\n",
      "Predicted (tokenized)\t\t [ARG] Campitello [SEP] Bigorno\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Verretto and Casatisma share borders with each other.']\n",
      "Projection\t\t Verretto [SEP] Casatisma\n",
      "Projection (tokenized)\t\t [ARG] Verretto [SEP] Casatisma\n",
      "Predicted (tokenized)\t\t [ARG] Casatisma [SEP] Verretto\n",
      "********************************************************************************\n",
      "Score\t\t 0.44680851063829785\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Saint-Vincent-de-Paul is a neighbour of Saint-Gervais.']\n",
      "Projection\t\t Saint-Vincent-de-Paul [SEP] Saint-Gervais\n",
      "Projection (tokenized)\t\t [ARG] Saint-Vincent-de-Paul [SEP] Saint-Gervais\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Gervais [SEP] Saint-Vincent-de-Paul\n",
      "********************************************************************************\n",
      "Score\t\t 0.7142857142857143\n",
      "Query\t\t In which country was Olaf born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Olaf was born in 1963. At the time, his parents lived in Trondheim.']\n",
      "Projection\t\t Norway\n",
      "Projection (tokenized)\t\t [BOOL] Norway\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.6428571428571428\n",
      "Query\t\t In which country was Mayu born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Mayu was born in 1982. At the time, her parents lived in Fussa.']\n",
      "Projection\t\t Japan\n",
      "Projection (tokenized)\t\t [BOOL] Japan\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.29729729729729726\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t [\"Roncello and Trezzo sull'Adda share borders with each other.\"]\n",
      "Projection\t\t Trezzo sull'Adda [SEP] Roncello\n",
      "Projection (tokenized)\t\t [ARG] Trezzo sull'Adda [SEP] Roncello\n",
      "Predicted (tokenized)\t\t [ARG] Roncello [SEP] Trezzo sull'Adda\n",
      "********************************************************************************\n",
      "Score\t\t 0.276595744680851\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Benalup-Casas Viejas and Medina Sidonia share borders with each other.']\n",
      "Projection\t\t Medina Sidonia [SEP] Benalup-Casas Viejas\n",
      "Projection (tokenized)\t\t [ARG] Medina Sidonia [SEP] Benalup-Casas Viejas\n",
      "Predicted (tokenized)\t\t [ARG] Benalup-Casas Viejas [SEP] Medina Sidonia\n",
      "********************************************************************************\n",
      "Score\t\t 0.5714285714285714\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Nrysund is neighbour with Hylandet.']\n",
      "Projection\t\t Nrysund [SEP] Hylandet\n",
      "Projection (tokenized)\t\t [ARG] Nrysund [SEP] Hylandet\n",
      "Predicted (tokenized)\t\t [ARG] Hylandet [SEP] Nrysund\n",
      "********************************************************************************\n",
      "Score\t\t 0.24444444444444446\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Castelmauro shares a border with San Felice del Molise.']\n",
      "Projection\t\t San Felice del Molise [SEP] Castelmauro\n",
      "Projection (tokenized)\t\t [ARG] San Felice del Molise [SEP] Castelmauro\n",
      "Predicted (tokenized)\t\t [ARG] Castelmauro [SEP] San Felice del Molise\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was James born in North America?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['James was born in 1962. At the time, his parents lived in Lima.']\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Lambruisse and Clumanc share borders with each other.']\n",
      "Projection\t\t Clumanc [SEP] Lambruisse\n",
      "Projection (tokenized)\t\t [ARG] Clumanc [SEP] Lambruisse\n",
      "Predicted (tokenized)\t\t [ARG] Lambruisse [SEP] Clumanc\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Does Rob live in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Rob used to live in Budapest. Rob then moved to Washington D.C. with Lucy.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.25\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t [\"Guilligomarc'h and Bern share borders with each other.\"]\n",
      "Projection\t\t Bern [SEP] Guilligomarc'h\n",
      "Projection (tokenized)\t\t [ARG] Bern [SEP] Guilligomarc'h\n",
      "Predicted (tokenized)\t\t [ARG] Guilligomarc'h [SEP] Bern\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was John born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['John was born in Leeds in 1970.']\n",
      "Projection\t\t Europe\n",
      "Projection (tokenized)\t\t [BOOL] Europe\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.4181818181818182\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Toral de los Guzmanes and Villademor de la Vega share borders with each other.']\n",
      "Projection\t\t Villademor de la Vega [SEP] Toral de los Guzmanes\n",
      "Projection (tokenized)\t\t [ARG] Villademor de la Vega [SEP] Toral de los Guzmanes\n",
      "Predicted (tokenized)\t\t [ARG] Toral de los Guzmanes [SEP] Villademor de la Vega\n",
      "********************************************************************************\n",
      "Score\t\t 0.3793103448275862\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Blatn is neighbour with Bezddovice.']\n",
      "Projection\t\t Bezddovice [SEP] Blatn\n",
      "Projection (tokenized)\t\t [ARG] Bezddovice [SEP] Blatn\n",
      "Predicted (tokenized)\t\t [ARG] Blatn [SEP] Bezddovice\n",
      "********************************************************************************\n",
      "Score\t\t 0.3023255813953488\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Muneville-le-Bingard and Ancteville share borders with each other.']\n",
      "Projection\t\t Muneville-le-Bingard [SEP] Ancteville\n",
      "Projection (tokenized)\t\t [ARG] Muneville-le-Bingard [SEP] Ancteville\n",
      "Predicted (tokenized)\t\t [ARG] Ancteville [SEP] Muneville-le-Bingard\n",
      "********************************************************************************\n",
      "Score\t\t 0.3571428571428571\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Bir El Djir is neighbour with Oran.']\n",
      "Projection\t\t Bir El Djir [SEP] Oran\n",
      "Projection (tokenized)\t\t [ARG] Bir El Djir [SEP] Oran\n",
      "Predicted (tokenized)\t\t [ARG] Oran [SEP] Bir El Djir\n",
      "********************************************************************************\n",
      "Score\t\t 0.18918918918918914\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['jezd u ern Hory and Milonice share borders with each other.']\n",
      "Projection\t\t jezd u ern Hory [SEP] Milonice\n",
      "Projection (tokenized)\t\t [ARG] jezd u ern Hory [SEP] Milonice\n",
      "Predicted (tokenized)\t\t [ARG] Milonice [SEP] jezd u ern Hory\n",
      "********************************************************************************\n",
      "Score\t\t 0.6216216216216216\n",
      "Query\t\t What league has the most participants?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['1. FC Nrnberg is a player in Bundesliga']\n",
      "Projection\t\t Bundesliga [SEP] Bundesliga\n",
      "Projection (tokenized)\t\t [ARG] Bundesliga [SEP] Bundesliga\n",
      "Predicted (tokenized)\t\t [ARG] Bundesliga [SEP] 1. FC Nrnberg\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Taavi born in Estonia?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1974, Taavi's mother gave birth to Taavi in Eidapere.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.2222222222222222\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['jezd u ern Hory and Skalika share borders with each other.']\n",
      "Projection\t\t jezd u ern Hory [SEP] Skalika\n",
      "Projection (tokenized)\t\t [ARG] jezd u ern Hory [SEP] Skalika\n",
      "Predicted (tokenized)\t\t [ARG] Skalika [SEP] jezd u ern Hory\n",
      "********************************************************************************\n",
      "Score\t\t 0.29729729729729726\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['La Chapelle-Janson and Luitr share borders with each other.']\n",
      "Projection\t\t La Chapelle-Janson [SEP] Luitr\n",
      "Projection (tokenized)\t\t [ARG] La Chapelle-Janson [SEP] Luitr\n",
      "Predicted (tokenized)\t\t [ARG] Luitr [SEP] La Chapelle-Janson\n",
      "********************************************************************************\n",
      "Score\t\t 0.5714285714285714\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Landresse shares a border with Sancey.']\n",
      "Projection\t\t Sancey [SEP] Landresse\n",
      "Projection (tokenized)\t\t [ARG] Sancey [SEP] Landresse\n",
      "Predicted (tokenized)\t\t [ARG] Landresse [SEP] Sancey\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Does Janet's spouse live in Berlin?\n",
      "Type\t\t join_boolean\n",
      "Fact\t\t [\"Ted is Janet's spouse\", 'Ted was living in Berlin, but he now lives in Washington D.C..']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.5172413793103448\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['cuill and Champign share borders with each other.']\n",
      "Projection\t\t Champign [SEP] cuill\n",
      "Projection (tokenized)\t\t [ARG] Champign [SEP] cuill\n",
      "Predicted (tokenized)\t\t [ARG] cuill [SEP] Champign\n",
      "********************************************************************************\n",
      "Score\t\t 0.33333333333333337\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Contessa Entellina shares a border with Santa Margherita di Belice.']\n",
      "Projection\t\t Contessa Entellina [SEP] Santa Margherita di Belice\n",
      "Projection (tokenized)\t\t [ARG] Contessa Entellina [SEP] Santa Margherita di Belice\n",
      "Predicted (tokenized)\t\t [ARG] Santa Margherita di Belice [SEP] Contessa Entellina\n",
      "********************************************************************************\n",
      "Score\t\t 0.2941176470588235\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Saint-Fraimbault is a neighbour of Souc.']\n",
      "Projection\t\t Saint-Fraimbault [SEP] Souc\n",
      "Projection (tokenized)\t\t [ARG] Saint-Fraimbault [SEP] Souc\n",
      "Predicted (tokenized)\t\t [ARG] Souc [SEP] Saint-Fraimbault\n",
      "********************************************************************************\n",
      "Score\t\t 0.5384615384615384\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Mayoyao is a neighbour of Barlig.']\n",
      "Projection\t\t Barlig [SEP] Mayoyao\n",
      "Projection (tokenized)\t\t [ARG] Barlig [SEP] Mayoyao\n",
      "Predicted (tokenized)\t\t [ARG] Mayoyao [SEP] Barlig\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Is Dee a journalist at Diversinet Inc.?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Dee is an opinion journalist at Diversinet Inc..']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6428571428571428\n",
      "Query\t\t In which country was Aimi born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1995, Aimi's mother gave birth to Aimi in Ube.\"]\n",
      "Projection\t\t Japan\n",
      "Projection (tokenized)\t\t [BOOL] Japan\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.5\n",
      "Query\t\t In which continent was Darby born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Darby was born in 1971. At the time, her parents lived in Kodiak.']\n",
      "Projection\t\t North America\n",
      "Projection (tokenized)\t\t [BOOL] North America\n",
      "Predicted (tokenized)\t\t [BOOL] Asia\n",
      "********************************************************************************\n",
      "Score\t\t 0.4838709677419355\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Cahagnes and Sept-Vents share borders with each other.']\n",
      "Projection\t\t Cahagnes [SEP] Sept-Vents\n",
      "Projection (tokenized)\t\t [ARG] Cahagnes [SEP] Sept-Vents\n",
      "Predicted (tokenized)\t\t [ARG] Sept-Vents [SEP] Cahagnes\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t In which country was Nathan born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1981, Nathan's parents lived in Bradford when he was born.\"]\n",
      "Projection\t\t United Kingdom\n",
      "Projection (tokenized)\t\t [BOOL] United Kingdom\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Donnas and Valchiusa are neighbours.']\n",
      "Projection\t\t Valchiusa [SEP] Donnas\n",
      "Projection (tokenized)\t\t [ARG] Valchiusa [SEP] Donnas\n",
      "Predicted (tokenized)\t\t [ARG] Donnas [SEP] Valchiusa\n",
      "********************************************************************************\n",
      "Score\t\t 0.2727272727272727\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t [\"Meslan is neighbour with Guilligomarc'h.\"]\n",
      "Projection\t\t Meslan [SEP] Guilligomarc'h\n",
      "Projection (tokenized)\t\t [ARG] Meslan [SEP] Guilligomarc'h\n",
      "Predicted (tokenized)\t\t [ARG] Guilligomarc'h [SEP] Meslan\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which country was Martha born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1984, Martha's mother gave birth to Martha in Charlottetown.\"]\n",
      "Projection\t\t Canada\n",
      "Projection (tokenized)\t\t [BOOL] Canada\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Suizy-le-Franc is a neighbour of Igny-Comblizy.']\n",
      "Projection\t\t Suizy-le-Franc [SEP] Igny-Comblizy\n",
      "Projection (tokenized)\t\t [ARG] Suizy-le-Franc [SEP] Igny-Comblizy\n",
      "Predicted (tokenized)\t\t [ARG] Igny-Comblizy [SEP] Suizy-le-Franc\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Is Gail living in Berlin?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Gail was living in Berlin, but she now lives in Washington D.C..']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Emmanuel born in France?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1971, Emmanuel's mother gave birth to Emmanuel in Sedan.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.31999999999999995\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Chiclana de la Frontera shares a border with Medina Sidonia.']\n",
      "Projection\t\t Medina Sidonia [SEP] Chiclana de la Frontera\n",
      "Projection (tokenized)\t\t [ARG] Medina Sidonia [SEP] Chiclana de la Frontera\n",
      "Predicted (tokenized)\t\t [ARG] Chiclana de la Frontera [SEP] Medina Sidonia\n",
      "********************************************************************************\n",
      "Score\t\t 0.2753623188405797\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Diocese of Prizren is neighbour with Roman Catholic Archdiocese of Belgrade.']\n",
      "Projection\t\t Diocese of Prizren [SEP] Roman Catholic Archdiocese of Belgrade\n",
      "Projection (tokenized)\t\t [ARG] Diocese of Prizren [SEP] Roman Catholic Archdiocese of Belgrade\n",
      "Predicted (tokenized)\t\t [ARG] Roman Catholic Archdiocese of Belgrade [SEP] Diocese of Prizren\n",
      "********************************************************************************\n",
      "Score\t\t 0.26315789473684215\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Duisburg and Rhein-Kreis Neuss are neighbours.']\n",
      "Projection\t\t Rhein-Kreis Neuss [SEP] Duisburg\n",
      "Projection (tokenized)\t\t [ARG] Rhein-Kreis Neuss [SEP] Duisburg\n",
      "Predicted (tokenized)\t\t [ARG] Duisburg [SEP] Rhein-Kreis Neuss\n",
      "********************************************************************************\n",
      "Score\t\t 0.43999999999999995\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Fresno de Caracena is a neighbour of Carrascosa de Abajo.']\n",
      "Projection\t\t Carrascosa de Abajo [SEP] Fresno de Caracena\n",
      "Projection (tokenized)\t\t [ARG] Carrascosa de Abajo [SEP] Fresno de Caracena\n",
      "Predicted (tokenized)\t\t [ARG] Fresno de Caracena [SEP] Carrascosa de Abajo\n",
      "********************************************************************************\n",
      "Score\t\t 0.625\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Hauts-Bassins Region is neighbour with Cascades Region.']\n",
      "Projection\t\t Cascades Region [SEP] Hauts-Bassins Region\n",
      "Projection (tokenized)\t\t [ARG] Cascades Region [SEP] Hauts-Bassins Region\n",
      "Predicted (tokenized)\t\t [ARG] Hauts-Bassins Region [SEP] Cascades Region\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Gmina Wilkowice shares a border with Bielsko-Biaa.']\n",
      "Projection\t\t Bielsko-Biaa [SEP] Gmina Wilkowice\n",
      "Projection (tokenized)\t\t [ARG] Bielsko-Biaa [SEP] Gmina Wilkowice\n",
      "Predicted (tokenized)\t\t [ARG] Gmina Wilkowice [SEP] Bielsko-Biaa\n",
      "********************************************************************************\n",
      "Score\t\t 0.4545454545454546\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Occhiatana is neighbour with Monticello.']\n",
      "Projection\t\t Occhiatana [SEP] Monticello\n",
      "Projection (tokenized)\t\t [ARG] Occhiatana [SEP] Monticello\n",
      "Predicted (tokenized)\t\t [ARG] Monticello [SEP] Occhiatana\n",
      "********************************************************************************\n",
      "Score\t\t 0.3142857142857143\n",
      "Query\t\t Who is author with the fewest number of books?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Ai Yazawa is the author of Paradise Kiss']\n",
      "Projection\t\t Paradise Kiss [SEP] Ai Yazawa\n",
      "Projection (tokenized)\t\t [ARG] Paradise Kiss [SEP] Ai Yazawa\n",
      "Predicted (tokenized)\t\t [ARG] Ai Yazawa [SEP] Paradise Kiss\n",
      "********************************************************************************\n",
      "Score\t\t 0.4193548387096774\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Pohoelice and Napajedla share borders with each other.']\n",
      "Projection\t\t Pohoelice [SEP] Napajedla\n",
      "Projection (tokenized)\t\t [ARG] Pohoelice [SEP] Napajedla\n",
      "Predicted (tokenized)\t\t [ARG] Napajedla [SEP] Pohoelice\n",
      "********************************************************************************\n",
      "Score\t\t 0.375\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Palmyra and Spanish Fork are neighbours.']\n",
      "Projection\t\t Palmyra [SEP] Spanish Fork\n",
      "Projection (tokenized)\t\t [ARG] Palmyra [SEP] Spanish Fork\n",
      "Predicted (tokenized)\t\t [ARG] Spanish Fork [SEP] Palmyra\n",
      "********************************************************************************\n",
      "Score\t\t 0.40740740740740744\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Odolo and Preseglie are neighbours.']\n",
      "Projection\t\t Preseglie [SEP] Odolo\n",
      "Projection (tokenized)\t\t [ARG] Preseglie [SEP] Odolo\n",
      "Predicted (tokenized)\t\t [ARG] Odolo [SEP] Preseglie\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Sachiko born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1953, Sachiko's parents lived in Ch-ku when she was born.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Does Alicia's spouse live in Europe?\n",
      "Type\t\t join_boolean\n",
      "Fact\t\t [\"Michael is Alicia's spouse\", 'Michael was living in Washington D.C., but he now lives in Dublin.']\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.2571428571428571\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Ghyvelde is a neighbour of Leffrinckoucke.']\n",
      "Projection\t\t Leffrinckoucke [SEP] Ghyvelde\n",
      "Projection (tokenized)\t\t [ARG] Leffrinckoucke [SEP] Ghyvelde\n",
      "Predicted (tokenized)\t\t [ARG] Ghyvelde [SEP] Leffrinckoucke\n",
      "********************************************************************************\n",
      "Score\t\t 0.36585365853658536\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Torrubia del Campo is a neighbour of Pozorrubio.']\n",
      "Projection\t\t Pozorrubio [SEP] Torrubia del Campo\n",
      "Projection (tokenized)\t\t [ARG] Pozorrubio [SEP] Torrubia del Campo\n",
      "Predicted (tokenized)\t\t [ARG] Torrubia del Campo [SEP] Pozorrubio\n",
      "********************************************************************************\n",
      "Score\t\t 0.375\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Deggendorf is a neighbour of Plattling.']\n",
      "Projection\t\t Plattling [SEP] Deggendorf\n",
      "Projection (tokenized)\t\t [ARG] Plattling [SEP] Deggendorf\n",
      "Predicted (tokenized)\t\t [ARG] Deggendorf [SEP] Plattling\n",
      "********************************************************************************\n",
      "Score\t\t 0.4193548387096774\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Penzing and Purkersdorf are neighbours.']\n",
      "Projection\t\t Penzing [SEP] Purkersdorf\n",
      "Projection (tokenized)\t\t [ARG] Penzing [SEP] Purkersdorf\n",
      "Predicted (tokenized)\t\t [ARG] Purkersdorf [SEP] Penzing\n",
      "********************************************************************************\n",
      "Score\t\t 0.18367346938775508\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Le Bny-Bocage shares a border with Saint-Charles-de-Percy.']\n",
      "Projection\t\t Le Bny-Bocage [SEP] Saint-Charles-de-Percy\n",
      "Projection (tokenized)\t\t [ARG] Le Bny-Bocage [SEP] Saint-Charles-de-Percy\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Charles-de-Percy [SEP] Le Bny-Bocage\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Kenny born in Norway?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1974, Kenny's parents lived in ngelholm when he was born.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Ellen born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Ellen was born in Cottbus in 1980.']\n",
      "Projection\t\t Europe\n",
      "Projection (tokenized)\t\t [BOOL] Europe\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which country was Jemaine born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Jemaine was born in Masterton in 1974.']\n",
      "Projection\t\t New Zealand\n",
      "Projection (tokenized)\t\t [BOOL] New Zealand\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.2941176470588235\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Versonnex and Saint-Eusbe are neighbours.']\n",
      "Projection\t\t Saint-Eusbe [SEP] Versonnex\n",
      "Projection (tokenized)\t\t [ARG] Saint-Eusbe [SEP] Versonnex\n",
      "Predicted (tokenized)\t\t [ARG] Versonnex [SEP] Saint-Eusbe\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Kaci born in North America?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1988, Kaci's parents lived in Zeeland when she was born.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.33333333333333337\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Gondenans-Montby is neighbour with Soye.']\n",
      "Projection\t\t Soye [SEP] Gondenans-Montby\n",
      "Projection (tokenized)\t\t [ARG] Soye [SEP] Gondenans-Montby\n",
      "Predicted (tokenized)\t\t [ARG] Gondenans-Montby [SEP] Soye\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Ricardo born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Ricardo was born in 1964. At the time, his parents lived in Rio de Janeiro.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Ouvans shares a border with Landresse.']\n",
      "Projection\t\t Landresse [SEP] Ouvans\n",
      "Projection (tokenized)\t\t [ARG] Landresse [SEP] Ouvans\n",
      "Predicted (tokenized)\t\t [ARG] Ouvans [SEP] Landresse\n",
      "********************************************************************************\n",
      "Score\t\t 0.5652173913043479\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Sirdal shares a border with Lund.']\n",
      "Projection\t\t Sirdal [SEP] Lund\n",
      "Projection (tokenized)\t\t [ARG] Sirdal [SEP] Lund\n",
      "Predicted (tokenized)\t\t [ARG] Lund [SEP] Sirdal\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Thziers is a neighbour of Domazan.']\n",
      "Projection\t\t Thziers [SEP] Domazan\n",
      "Projection (tokenized)\t\t [ARG] Thziers [SEP] Domazan\n",
      "Predicted (tokenized)\t\t [ARG] Domazan [SEP] Thziers\n",
      "********************************************************************************\n",
      "Score\t\t 0.4545454545454546\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Collan is a neighbour of Dy.']\n",
      "Projection\t\t Dy [SEP] Collan\n",
      "Projection (tokenized)\t\t [ARG] Dy [SEP] Collan\n",
      "Predicted (tokenized)\t\t [ARG] Collan [SEP] Dy\n",
      "********************************************************************************\n",
      "Score\t\t 0.3142857142857143\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Saint-Pandelon shares a border with Seyresse.']\n",
      "Projection\t\t Seyresse [SEP] Saint-Pandelon\n",
      "Projection (tokenized)\t\t [ARG] Seyresse [SEP] Saint-Pandelon\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Pandelon [SEP] Seyresse\n",
      "********************************************************************************\n",
      "Score\t\t 0.52\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Aracena shares a border with Zufre.']\n",
      "Projection\t\t Aracena [SEP] Zufre\n",
      "Projection (tokenized)\t\t [ARG] Aracena [SEP] Zufre\n",
      "Predicted (tokenized)\t\t [ARG] Zufre [SEP] Aracena\n",
      "********************************************************************************\n",
      "Score\t\t 0.47619047619047616\n",
      "Query\t\t In which country was Alice born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Alice was born in 1968. At the time, her parents lived in Frodsham.']\n",
      "Projection\t\t United Kingdom\n",
      "Projection (tokenized)\t\t [BOOL] United Kingdom\n",
      "Predicted (tokenized)\t\t [BOOL] England\n",
      "********************************************************************************\n",
      "Score\t\t 0.28\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Condeissiat is a neighbour of Saint-Andr-sur-Vieux-Jonc.']\n",
      "Projection\t\t Saint-Andr-sur-Vieux-Jonc [SEP] Condeissiat\n",
      "Projection (tokenized)\t\t [ARG] Saint-Andr-sur-Vieux-Jonc [SEP] Condeissiat\n",
      "Predicted (tokenized)\t\t [ARG] Condeissiat [SEP] Saint-Andr-sur-Vieux-Jonc\n",
      "********************************************************************************\n",
      "Score\t\t 0.2647058823529411\n",
      "Query\t\t How many people went to 12822484?\n",
      "Type\t\t count\n",
      "Fact\t\t ['12822484 went to 200809 Fuball-Bundesliga']\n",
      "Projection\t\t 12822484\n",
      "Projection (tokenized)\t\t [COUNT] 12822484\n",
      "Predicted (tokenized)\t\t [COUNT] 200809 Fuball-Bundesliga\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Jimmy born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1948, Jimmy's parents lived in Southport when he was born.\"]\n",
      "Projection\t\t Europe\n",
      "Projection (tokenized)\t\t [BOOL] Europe\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.5\n",
      "Query\t\t How many people visit Getty Villa every year?\n",
      "Type\t\t count\n",
      "Fact\t\t ['405710 people visit Getty Villa annually']\n",
      "Projection\t\t \n",
      "Projection (tokenized)\t\t [COUNT]\n",
      "Predicted (tokenized)\t\t [COUNT] 405710\n",
      "********************************************************************************\n",
      "Score\t\t 0.6296296296296297\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Virton is neighbour with Tintigny.']\n",
      "Projection\t\t Virton [SEP] Tintigny\n",
      "Projection (tokenized)\t\t [ARG] Virton [SEP] Tintigny\n",
      "Predicted (tokenized)\t\t [ARG] Tintigny [SEP] Virton\n",
      "********************************************************************************\n",
      "Score\t\t 0.43999999999999995\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Fresno de Caracena is a neighbour of Carrascosa de Abajo.']\n",
      "Projection\t\t Carrascosa de Abajo [SEP] Fresno de Caracena\n",
      "Projection (tokenized)\t\t [ARG] Carrascosa de Abajo [SEP] Fresno de Caracena\n",
      "Predicted (tokenized)\t\t [ARG] Fresno de Caracena [SEP] Carrascosa de Abajo\n",
      "********************************************************************************\n",
      "Score\t\t 0.3529411764705882\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Klosterneuburg and Penzing are neighbours.']\n",
      "Projection\t\t Penzing [SEP] Klosterneuburg\n",
      "Projection (tokenized)\t\t [ARG] Penzing [SEP] Klosterneuburg\n",
      "Predicted (tokenized)\t\t [ARG] Klosterneuburg [SEP] Penzing\n",
      "********************************************************************************\n",
      "Score\t\t 0.23076923076923073\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Naujan-et-Postiac is neighbour with Bellefond.']\n",
      "Projection\t\t Naujan-et-Postiac [SEP] Bellefond\n",
      "Projection (tokenized)\t\t [ARG] Naujan-et-Postiac [SEP] Bellefond\n",
      "Predicted (tokenized)\t\t [ARG] Bellefond [SEP] Naujan-et-Postiac\n",
      "********************************************************************************\n",
      "Score\t\t 0.34883720930232553\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t [\"Sant'Elena Sannita and Casalciprano are neighbours.\"]\n",
      "Projection\t\t Sant'Elena Sannita [SEP] Casalciprano\n",
      "Projection (tokenized)\t\t [ARG] Sant'Elena Sannita [SEP] Casalciprano\n",
      "Predicted (tokenized)\t\t [ARG] Casalciprano [SEP] Sant'Elena Sannita\n",
      "********************************************************************************\n",
      "Score\t\t 0.36\n",
      "Query\t\t How many books did Mater et Magistra write?\n",
      "Type\t\t count\n",
      "Fact\t\t ['John XXIII wrote Mater et Magistra']\n",
      "Projection\t\t Mater et Magistra\n",
      "Projection (tokenized)\t\t [COUNT] Mater et Magistra\n",
      "Predicted (tokenized)\t\t [COUNT] John XXIII\n",
      "********************************************************************************\n",
      "Score\t\t 0.4814814814814815\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Pagnona is neighbour with Delebio.']\n",
      "Projection\t\t Delebio [SEP] Pagnona\n",
      "Projection (tokenized)\t\t [ARG] Delebio [SEP] Pagnona\n",
      "Predicted (tokenized)\t\t [ARG] Pagnona [SEP] Delebio\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Pdraic born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1977, Pdraic's parents lived in Adamstown when he was born.\"]\n",
      "Projection\t\t Europe\n",
      "Projection (tokenized)\t\t [BOOL] Europe\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.19999999999999996\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Macogny is a neighbour of Chzy-en-Orxois.']\n",
      "Projection\t\t Macogny [SEP] Chzy-en-Orxois\n",
      "Projection (tokenized)\t\t [ARG] Macogny [SEP] Chzy-en-Orxois\n",
      "Predicted (tokenized)\t\t [ARG] Chzy-en-Orxois [SEP] Macogny\n",
      "********************************************************************************\n",
      "Score\t\t 0.28888888888888886\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Brie-Comte-Robert and Chevry-Cossigny are neighbours.']\n",
      "Projection\t\t Brie-Comte-Robert [SEP] Chevry-Cossigny\n",
      "Projection (tokenized)\t\t [ARG] Brie-Comte-Robert [SEP] Chevry-Cossigny\n",
      "Predicted (tokenized)\t\t [ARG] Chevry-Cossigny [SEP] Brie-Comte-Robert\n",
      "********************************************************************************\n",
      "Score\t\t 0.30000000000000004\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Painblanc is neighbour with Chaudenay-la-Ville.']\n",
      "Projection\t\t Painblanc [SEP] Chaudenay-la-Ville\n",
      "Projection (tokenized)\t\t [ARG] Painblanc [SEP] Chaudenay-la-Ville\n",
      "Predicted (tokenized)\t\t [ARG] Chaudenay-la-Ville [SEP] Painblanc\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Aivar born in Estonia?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1980, Aivar's parents lived in Pltsamaa when he was born.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.2857142857142857\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Province of Cuneo shares a border with Hautes-Alpes.']\n",
      "Projection\t\t Hautes-Alpes [SEP] Province of Cuneo\n",
      "Projection (tokenized)\t\t [ARG] Hautes-Alpes [SEP] Province of Cuneo\n",
      "Predicted (tokenized)\t\t [ARG] Province of Cuneo [SEP] Hautes-Alpes\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Brandivy and Plumergat share borders with each other.']\n",
      "Projection\t\t Plumergat [SEP] Brandivy\n",
      "Projection (tokenized)\t\t [ARG] Plumergat [SEP] Brandivy\n",
      "Predicted (tokenized)\t\t [ARG] Brandivy [SEP] Plumergat\n",
      "********************************************************************************\n",
      "Score\t\t 0.6799999999999999\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Plrin is a neighbour of Pordic.']\n",
      "Projection\t\t Plrin [SEP] Pordic\n",
      "Projection (tokenized)\t\t [ARG] Plrin [SEP] Pordic\n",
      "Predicted (tokenized)\t\t [ARG] Pordic [SEP] Plrin\n",
      "********************************************************************************\n",
      "Score\t\t 0.6326530612244898\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Santa Cruz Department is a neighbour of Beni Department.']\n",
      "Projection\t\t Beni Department [SEP] Santa Cruz Department\n",
      "Projection (tokenized)\t\t [ARG] Beni Department [SEP] Santa Cruz Department\n",
      "Predicted (tokenized)\t\t [ARG] Santa Cruz Department [SEP] Beni Department\n",
      "********************************************************************************\n",
      "Score\t\t 0.4375\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Stanghella and Vescovana are neighbours.']\n",
      "Projection\t\t Stanghella [SEP] Vescovana\n",
      "Projection (tokenized)\t\t [ARG] Stanghella [SEP] Vescovana\n",
      "Predicted (tokenized)\t\t [ARG] Vescovana [SEP] Stanghella\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Jin born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Jin was born in Hefei in 1981.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.5652173913043479\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Jury is a neighbour of Peltre.']\n",
      "Projection\t\t Peltre [SEP] Jury\n",
      "Projection (tokenized)\t\t [ARG] Peltre [SEP] Jury\n",
      "Predicted (tokenized)\t\t [ARG] Jury [SEP] Peltre\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Querr is a neighbour of Champign.']\n",
      "Projection\t\t Champign [SEP] Querr\n",
      "Projection (tokenized)\t\t [ARG] Champign [SEP] Querr\n",
      "Predicted (tokenized)\t\t [ARG] Querr [SEP] Champign\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Al born in United States?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1966, Al's mother gave birth to Al in Dearborn.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.3650793650793651\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Figueira de Castelo Rodrigo and Ahigal de los Aceiteros are neighbours.']\n",
      "Projection\t\t Figueira de Castelo Rodrigo [SEP] Ahigal de los Aceiteros\n",
      "Projection (tokenized)\t\t [ARG] Figueira de Castelo Rodrigo [SEP] Ahigal de los Aceiteros\n",
      "Predicted (tokenized)\t\t [ARG] Ahigal de los Aceiteros [SEP] Figueira de Castelo Rodrigo\n",
      "********************************************************************************\n",
      "Score\t\t 0.368421052631579\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Coole and Maisons-en-Champagne are neighbours.']\n",
      "Projection\t\t Maisons-en-Champagne [SEP] Coole\n",
      "Projection (tokenized)\t\t [ARG] Maisons-en-Champagne [SEP] Coole\n",
      "Predicted (tokenized)\t\t [ARG] Coole [SEP] Maisons-en-Champagne\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Erardo born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Erardo was born in 1953. At the time, his parents lived in Comodoro Rivadavia.']\n",
      "Projection\t\t South America\n",
      "Projection (tokenized)\t\t [BOOL] South America\n",
      "Predicted (tokenized)\t\t [BOOL] Europe\n",
      "********************************************************************************\n",
      "Score\t\t 0.3529411764705882\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Prata Sannita and Ciorlano share borders with each other.']\n",
      "Projection\t\t Prata Sannita [SEP] Ciorlano\n",
      "Projection (tokenized)\t\t [ARG] Prata Sannita [SEP] Ciorlano\n",
      "Predicted (tokenized)\t\t [ARG] Ciorlano [SEP] Prata Sannita\n",
      "********************************************************************************\n",
      "Score\t\t 0.6756756756756757\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Wood County is a neighbour of Ottawa County.']\n",
      "Projection\t\t Ottawa County [SEP] Wood County\n",
      "Projection (tokenized)\t\t [ARG] Ottawa County [SEP] Wood County\n",
      "Predicted (tokenized)\t\t [ARG] Wood County [SEP] Ottawa County\n",
      "********************************************************************************\n",
      "Score\t\t 0.3090909090909091\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Saint-Ferrol-des-Ctes is a neighbour of Marsac-en-Livradois.']\n",
      "Projection\t\t Saint-Ferrol-des-Ctes [SEP] Marsac-en-Livradois\n",
      "Projection (tokenized)\t\t [ARG] Saint-Ferrol-des-Ctes [SEP] Marsac-en-Livradois\n",
      "Predicted (tokenized)\t\t [ARG] Marsac-en-Livradois [SEP] Saint-Ferrol-des-Ctes\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t In which country was Carmen's spouse born?\n",
      "Type\t\t join_extractive\n",
      "Fact\t\t [\"Tricky is Carmen's spouse\", \"In 1968, Tricky's mother gave birth to Tricky in Bristol.\"]\n",
      "Projection\t\t United Kingdom\n",
      "Projection (tokenized)\t\t [BOOL] United Kingdom\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.48571428571428577\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Borger-Odoorn is neighbour with Coevorden.']\n",
      "Projection\t\t Borger-Odoorn [SEP] Coevorden\n",
      "Projection (tokenized)\t\t [ARG] Borger-Odoorn [SEP] Coevorden\n",
      "Predicted (tokenized)\t\t [ARG] Coevorden [SEP] Borger-Odoorn\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Saclas is a neighbour of Mrville.']\n",
      "Projection\t\t Mrville [SEP] Saclas\n",
      "Projection (tokenized)\t\t [ARG] Mrville [SEP] Saclas\n",
      "Predicted (tokenized)\t\t [ARG] Saclas [SEP] Mrville\n",
      "********************************************************************************\n",
      "Score\t\t 0.5384615384615384\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['pargnes and Cozes are neighbours.']\n",
      "Projection\t\t Cozes [SEP] pargnes\n",
      "Projection (tokenized)\t\t [ARG] Cozes [SEP] pargnes\n",
      "Predicted (tokenized)\t\t [ARG] pargnes [SEP] Cozes\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t In which country was Jose born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Jose was born in Bootle in 1992.']\n",
      "Projection\t\t United Kingdom\n",
      "Projection (tokenized)\t\t [BOOL] United Kingdom\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.2777777777777778\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Bydgoszcz is neighbour with Gmina Osielsko.']\n",
      "Projection\t\t Bydgoszcz [SEP] Gmina Osielsko\n",
      "Projection (tokenized)\t\t [ARG] Bydgoszcz [SEP] Gmina Osielsko\n",
      "Predicted (tokenized)\t\t [ARG] Gmina Osielsko [SEP] Bydgoszcz\n",
      "********************************************************************************\n",
      "Score\t\t 0.5833333333333333\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Radmer and Landl are neighbours.']\n",
      "Projection\t\t Landl [SEP] Radmer\n",
      "Projection (tokenized)\t\t [ARG] Landl [SEP] Radmer\n",
      "Predicted (tokenized)\t\t [ARG] Radmer [SEP] Landl\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Todd born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1976, Todd's parents lived in Adelaide when he was born.\"]\n",
      "Projection\t\t Oceania\n",
      "Projection (tokenized)\t\t [BOOL] Oceania\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.52\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Austin is neighbour with Cicero.']\n",
      "Projection\t\t Cicero [SEP] Austin\n",
      "Projection (tokenized)\t\t [ARG] Cicero [SEP] Austin\n",
      "Predicted (tokenized)\t\t [ARG] Austin [SEP] Cicero\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Tie born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1969, Tie's mother gave birth to Tie in Windsor.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6296296296296297\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['tarnov shares a border with ternberk.']\n",
      "Projection\t\t tarnov [SEP] ternberk\n",
      "Projection (tokenized)\t\t [ARG] tarnov [SEP] ternberk\n",
      "Predicted (tokenized)\t\t [ARG] ternberk [SEP] tarnov\n",
      "********************************************************************************\n",
      "Score\t\t 0.4193548387096774\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Caplong and Landerrouat are neighbours.']\n",
      "Projection\t\t Caplong [SEP] Landerrouat\n",
      "Projection (tokenized)\t\t [ARG] Caplong [SEP] Landerrouat\n",
      "Predicted (tokenized)\t\t [ARG] Landerrouat [SEP] Caplong\n",
      "********************************************************************************\n",
      "Score\t\t 0.5714285714285714\n",
      "Query\t\t In which country was David born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['David was born in 1943. At the time, his parents lived in Kitchener.']\n",
      "Projection\t\t Canada\n",
      "Projection (tokenized)\t\t [BOOL] Canada\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Guillaume born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Guillaume was born in 1987. At the time, his parents lived in Sainte-Catherine.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which country was Kerrin born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Kerrin was born in 1966. At the time, her parents lived in Trail.']\n",
      "Projection\t\t Canada\n",
      "Projection (tokenized)\t\t [BOOL] Canada\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.6521739130434783\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Liberec District is neighbour with esk Lpa District.']\n",
      "Projection\t\t esk Lpa District [SEP] Liberec District\n",
      "Projection (tokenized)\t\t [ARG] esk Lpa District [SEP] Liberec District\n",
      "Predicted (tokenized)\t\t [ARG] Liberec District [SEP] esk Lpa District\n",
      "********************************************************************************\n",
      "Score\t\t 0.2857142857142857\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Missy shares a border with Le Locheur.']\n",
      "Projection\t\t Missy [SEP] Le Locheur\n",
      "Projection (tokenized)\t\t [ARG] Missy [SEP] Le Locheur\n",
      "Predicted (tokenized)\t\t [ARG] Le Locheur [SEP] Missy\n",
      "********************************************************************************\n",
      "Score\t\t 0.6428571428571428\n",
      "Query\t\t In which continent was Warren born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1965, Warren's mother gave birth to Warren in Ballarat.\"]\n",
      "Projection\t\t Oceania\n",
      "Projection (tokenized)\t\t [BOOL] Oceania\n",
      "Predicted (tokenized)\t\t [BOOL] Asia\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Vonetta born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Vonetta was born in Birmingham in 1973.']\n",
      "Projection\t\t North America\n",
      "Projection (tokenized)\t\t [BOOL] North America\n",
      "Predicted (tokenized)\t\t [BOOL] Europe\n",
      "********************************************************************************\n",
      "Score\t\t 0.5\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Chaptuzat shares a border with Vensat.']\n",
      "Projection\t\t Vensat [SEP] Chaptuzat\n",
      "Projection (tokenized)\t\t [ARG] Vensat [SEP] Chaptuzat\n",
      "Predicted (tokenized)\t\t [ARG] Chaptuzat [SEP] Vensat\n",
      "********************************************************************************\n",
      "Score\t\t 0.4666666666666667\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Landl is neighbour with Altenmarkt bei Sankt Gallen.']\n",
      "Projection\t\t Altenmarkt bei Sankt Gallen [SEP] Landl\n",
      "Projection (tokenized)\t\t [ARG] Altenmarkt bei Sankt Gallen [SEP] Landl\n",
      "Predicted (tokenized)\t\t [ARG] Landl [SEP] Altenmarkt bei Sankt Gallen\n",
      "********************************************************************************\n",
      "Score\t\t 0.4814814814814815\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Mietice is neighbour with Pravonn.']\n",
      "Projection\t\t Mietice [SEP] Pravonn\n",
      "Projection (tokenized)\t\t [ARG] Mietice [SEP] Pravonn\n",
      "Predicted (tokenized)\t\t [ARG] Pravonn [SEP] Mietice\n",
      "********************************************************************************\n",
      "Score\t\t 0.4482758620689655\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Flassan is neighbour with Mormoiron.']\n",
      "Projection\t\t Flassan [SEP] Mormoiron\n",
      "Projection (tokenized)\t\t [ARG] Flassan [SEP] Mormoiron\n",
      "Predicted (tokenized)\t\t [ARG] Mormoiron [SEP] Flassan\n",
      "********************************************************************************\n",
      "Score\t\t 0.30000000000000004\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t [\"Sant'Oreste shares a border with Rignano Flaminio.\"]\n",
      "Projection\t\t Rignano Flaminio [SEP] Sant'Oreste\n",
      "Projection (tokenized)\t\t [ARG] Rignano Flaminio [SEP] Sant'Oreste\n",
      "Predicted (tokenized)\t\t [ARG] Sant'Oreste [SEP] Rignano Flaminio\n",
      "********************************************************************************\n",
      "Score\t\t 0.43999999999999995\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Antzuola is a neighbour of Oati.']\n",
      "Projection\t\t Oati [SEP] Antzuola\n",
      "Projection (tokenized)\t\t [ARG] Oati [SEP] Antzuola\n",
      "Predicted (tokenized)\t\t [ARG] Antzuola [SEP] Oati\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Does Charlie live in Berlin?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Charlie was living in Berlin, but he now lives in Washington D.C..']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.7619047619047619\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Berea District and Maseru District are neighbours.']\n",
      "Projection\t\t Berea District [SEP] Maseru District\n",
      "Projection (tokenized)\t\t [ARG] Berea District [SEP] Maseru District\n",
      "Predicted (tokenized)\t\t [ARG] Maseru District [SEP] Berea District\n",
      "********************************************************************************\n",
      "Score\t\t 0.18367346938775508\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Le Bny-Bocage shares a border with Saint-Charles-de-Percy.']\n",
      "Projection\t\t Le Bny-Bocage [SEP] Saint-Charles-de-Percy\n",
      "Projection (tokenized)\t\t [ARG] Le Bny-Bocage [SEP] Saint-Charles-de-Percy\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Charles-de-Percy [SEP] Le Bny-Bocage\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Eliel born in Asia?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1983, Eliel's mother gave birth to Eliel in Marianao.\"]\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.5\n",
      "Query\t\t In which country was Hilde born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Hilde was born in Linz in 1961.']\n",
      "Projection\t\t Austria\n",
      "Projection (tokenized)\t\t [BOOL] Austria\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.3220338983050848\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Burgo de Osma-Ciudad de Osma is neighbour with Fresno de Caracena.']\n",
      "Projection\t\t Burgo de Osma-Ciudad de Osma [SEP] Fresno de Caracena\n",
      "Projection (tokenized)\t\t [ARG] Burgo de Osma-Ciudad de Osma [SEP] Fresno de Caracena\n",
      "Predicted (tokenized)\t\t [ARG] Fresno de Caracena [SEP] Burgo de Osma-Ciudad de Osma\n",
      "********************************************************************************\n",
      "Score\t\t 0.5\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Auxant is neighbour with Painblanc.']\n",
      "Projection\t\t Auxant [SEP] Painblanc\n",
      "Projection (tokenized)\t\t [ARG] Auxant [SEP] Painblanc\n",
      "Predicted (tokenized)\t\t [ARG] Painblanc [SEP] Auxant\n",
      "********************************************************************************\n",
      "Score\t\t 0.30000000000000004\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Lagonegro and Casaletto Spartano share borders with each other.']\n",
      "Projection\t\t Lagonegro [SEP] Casaletto Spartano\n",
      "Projection (tokenized)\t\t [ARG] Lagonegro [SEP] Casaletto Spartano\n",
      "Predicted (tokenized)\t\t [ARG] Casaletto Spartano [SEP] Lagonegro\n",
      "********************************************************************************\n",
      "Score\t\t 0.4444444444444444\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Villademor de la Vega and Valencia de Don Juan share borders with each other.']\n",
      "Projection\t\t Valencia de Don Juan [SEP] Villademor de la Vega\n",
      "Projection (tokenized)\t\t [ARG] Valencia de Don Juan [SEP] Villademor de la Vega\n",
      "Predicted (tokenized)\t\t [ARG] Villademor de la Vega [SEP] Valencia de Don Juan\n",
      "********************************************************************************\n",
      "Score\t\t 0.3055555555555556\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['arrondissement of Saint-Laurent-du-Maroni shares a border with Marowijne District.']\n",
      "Projection\t\t Marowijne District [SEP] arrondissement of Saint-Laurent-du-Maroni\n",
      "Projection (tokenized)\t\t [ARG] Marowijne District [SEP] arrondissement of Saint-Laurent-du-Maroni\n",
      "Predicted (tokenized)\t\t [ARG] arrondissement of Saint-Laurent-du-Maroni [SEP] Marowijne District\n",
      "********************************************************************************\n",
      "Score\t\t 0.23404255319148937\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Saint-Yrieix-le-Djalat is a neighbour of Grandsaigne.']\n",
      "Projection\t\t Saint-Yrieix-le-Djalat [SEP] Grandsaigne\n",
      "Projection (tokenized)\t\t [ARG] Saint-Yrieix-le-Djalat [SEP] Grandsaigne\n",
      "Predicted (tokenized)\t\t [ARG] Grandsaigne [SEP] Saint-Yrieix-le-Djalat\n",
      "********************************************************************************\n",
      "Score\t\t 0.2777777777777778\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t [\"Cavaglio d'Agogna is a neighbour of Ghemme.\"]\n",
      "Projection\t\t Ghemme [SEP] Cavaglio d'Agogna\n",
      "Projection (tokenized)\t\t [ARG] Ghemme [SEP] Cavaglio d'Agogna\n",
      "Predicted (tokenized)\t\t [ARG] Cavaglio d'Agogna [SEP] Ghemme\n",
      "********************************************************************************\n",
      "Score\t\t 0.44999999999999996\n",
      "Query\t\t In which continent was Francisco born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Francisco was born in 1981. At the time, his parents lived in San Fernando.']\n",
      "Projection\t\t Europe\n",
      "Projection (tokenized)\t\t [BOOL] Europe\n",
      "Predicted (tokenized)\t\t [BOOL] North America\n",
      "********************************************************************************\n",
      "Score\t\t 0.52\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Melide is a neighbour of Lugano.']\n",
      "Projection\t\t Melide [SEP] Lugano\n",
      "Projection (tokenized)\t\t [ARG] Melide [SEP] Lugano\n",
      "Predicted (tokenized)\t\t [ARG] Lugano [SEP] Melide\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t In which country was Elrio born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1983, Elrio's mother gave birth to Elrio in Port Elizabeth.\"]\n",
      "Projection\t\t South Africa\n",
      "Projection (tokenized)\t\t [BOOL] South Africa\n",
      "Predicted (tokenized)\t\t [BOOL] United Kingdom\n",
      "********************************************************************************\n",
      "Score\t\t 0.26315789473684215\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Mrville is neighbour with Autruy-sur-Juine.']\n",
      "Projection\t\t Mrville [SEP] Autruy-sur-Juine\n",
      "Projection (tokenized)\t\t [ARG] Mrville [SEP] Autruy-sur-Juine\n",
      "Predicted (tokenized)\t\t [ARG] Autruy-sur-Juine [SEP] Mrville\n",
      "********************************************************************************\n",
      "Score\t\t 0.37142857142857144\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Villa Estense and Vescovana share borders with each other.']\n",
      "Projection\t\t Vescovana [SEP] Villa Estense\n",
      "Projection (tokenized)\t\t [ARG] Vescovana [SEP] Villa Estense\n",
      "Predicted (tokenized)\t\t [ARG] Villa Estense [SEP] Vescovana\n",
      "********************************************************************************\n",
      "Score\t\t 0.7435897435897436\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Hualien County and Yilan County share borders with each other.']\n",
      "Projection\t\t Hualien County [SEP] Yilan County\n",
      "Projection (tokenized)\t\t [ARG] Hualien County [SEP] Yilan County\n",
      "Predicted (tokenized)\t\t [ARG] Yilan County [SEP] Hualien County\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was David born in South Africa?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['David was born in Longjumeau in 1986.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Is Nick a resident in Berlin?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Nick used to live in Berlin. Nick then moved to Washington D.C. with Heather.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.3846153846153846\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Chanoz-Chtenay and Condeissiat are neighbours.']\n",
      "Projection\t\t Chanoz-Chtenay [SEP] Condeissiat\n",
      "Projection (tokenized)\t\t [ARG] Chanoz-Chtenay [SEP] Condeissiat\n",
      "Predicted (tokenized)\t\t [ARG] Condeissiat [SEP] Chanoz-Chtenay\n",
      "********************************************************************************\n",
      "Score\t\t 0.26086956521739135\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Muneville-le-Bingard is a neighbour of La Ronde-Haye.']\n",
      "Projection\t\t Muneville-le-Bingard [SEP] La Ronde-Haye\n",
      "Projection (tokenized)\t\t [ARG] Muneville-le-Bingard [SEP] La Ronde-Haye\n",
      "Predicted (tokenized)\t\t [ARG] La Ronde-Haye [SEP] Muneville-le-Bingard\n",
      "********************************************************************************\n",
      "Score\t\t 0.27083333333333337\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Castelnuovo Bocca dAdda is neighbour with Maccastorna.']\n",
      "Projection\t\t Castelnuovo Bocca dAdda [SEP] Maccastorna\n",
      "Projection (tokenized)\t\t [ARG] Castelnuovo Bocca dAdda [SEP] Maccastorna\n",
      "Predicted (tokenized)\t\t [ARG] Maccastorna [SEP] Castelnuovo Bocca dAdda\n",
      "********************************************************************************\n",
      "Score\t\t 0.33333333333333337\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Garching bei Mnchen and Oberschleiheim are neighbours.']\n",
      "Projection\t\t Garching bei Mnchen [SEP] Oberschleiheim\n",
      "Projection (tokenized)\t\t [ARG] Garching bei Mnchen [SEP] Oberschleiheim\n",
      "Predicted (tokenized)\t\t [ARG] Oberschleiheim [SEP] Garching bei Mnchen\n",
      "********************************************************************************\n",
      "Score\t\t 0.4193548387096774\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Brot-Vernet is a neighbour of Vendat.']\n",
      "Projection\t\t Vendat [SEP] Brot-Vernet\n",
      "Projection (tokenized)\t\t [ARG] Vendat [SEP] Brot-Vernet\n",
      "Predicted (tokenized)\t\t [ARG] Brot-Vernet [SEP] Vendat\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Georgina born in North America?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Georgina was born in 1965. At the time, her parents lived in Nanaimo.']\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.46153846153846156\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Reitwein is neighbour with Lebus.']\n",
      "Projection\t\t Lebus [SEP] Reitwein\n",
      "Projection (tokenized)\t\t [ARG] Lebus [SEP] Reitwein\n",
      "Predicted (tokenized)\t\t [ARG] Reitwein [SEP] Lebus\n",
      "********************************************************************************\n",
      "Score\t\t 0.2063492063492064\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Petrovac, Bosnia and Herzegovina shares a border with Drvar Municipality.']\n",
      "Projection\t\t Petrovac, Bosnia and Herzegovina [SEP] Drvar Municipality\n",
      "Projection (tokenized)\t\t [ARG] Petrovac, Bosnia and Herzegovina [SEP] Drvar Municipality\n",
      "Predicted (tokenized)\t\t [ARG] Drvar Municipality [SEP] Petrovac, Bosnia and Herzegovina\n",
      "********************************************************************************\n",
      "Score\t\t 0.3142857142857143\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Scandicci and Montespertoli are neighbours.']\n",
      "Projection\t\t Montespertoli [SEP] Scandicci\n",
      "Projection (tokenized)\t\t [ARG] Montespertoli [SEP] Scandicci\n",
      "Predicted (tokenized)\t\t [ARG] Scandicci [SEP] Montespertoli\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Lori born in South America?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Lori was born in Vancouver in 1963.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.4482758620689655\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Trvrien is neighbour with Plesder.']\n",
      "Projection\t\t Plesder [SEP] Trvrien\n",
      "Projection (tokenized)\t\t [ARG] Plesder [SEP] Trvrien\n",
      "Predicted (tokenized)\t\t [ARG] Trvrien [SEP] Plesder\n",
      "********************************************************************************\n",
      "Score\t\t 0.29032258064516125\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['West Bandung shares a border with Cimahi.']\n",
      "Projection\t\t Cimahi [SEP] West Bandung\n",
      "Projection (tokenized)\t\t [ARG] Cimahi [SEP] West Bandung\n",
      "Predicted (tokenized)\t\t [ARG] West Bandung [SEP] Cimahi\n",
      "********************************************************************************\n",
      "Score\t\t 0.30434782608695654\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Saint-Didier-la-Fort is neighbour with Brot-Vernet.']\n",
      "Projection\t\t Saint-Didier-la-Fort [SEP] Brot-Vernet\n",
      "Projection (tokenized)\t\t [ARG] Saint-Didier-la-Fort [SEP] Brot-Vernet\n",
      "Predicted (tokenized)\t\t [ARG] Brot-Vernet [SEP] Saint-Didier-la-Fort\n",
      "********************************************************************************\n",
      "Score\t\t 0.36170212765957444\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Chry-Chartreuve shares a border with Seringes-et-Nesles.']\n",
      "Projection\t\t Chry-Chartreuve [SEP] Seringes-et-Nesles\n",
      "Projection (tokenized)\t\t [ARG] Chry-Chartreuve [SEP] Seringes-et-Nesles\n",
      "Predicted (tokenized)\t\t [ARG] Seringes-et-Nesles [SEP] Chry-Chartreuve\n",
      "********************************************************************************\n",
      "Score\t\t 0.31999999999999995\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Marano Lagunare shares a border with Palazzolo dello Stella.']\n",
      "Projection\t\t Palazzolo dello Stella [SEP] Marano Lagunare\n",
      "Projection (tokenized)\t\t [ARG] Palazzolo dello Stella [SEP] Marano Lagunare\n",
      "Predicted (tokenized)\t\t [ARG] Marano Lagunare [SEP] Palazzolo dello Stella\n",
      "********************************************************************************\n",
      "Score\t\t 0.31707317073170727\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t [\"Saint-Rambert-d'Albon and Peyraud share borders with each other.\"]\n",
      "Projection\t\t Peyraud [SEP] Saint-Rambert-d'Albon\n",
      "Projection (tokenized)\t\t [ARG] Peyraud [SEP] Saint-Rambert-d'Albon\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Rambert-d'Albon [SEP] Peyraud\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Donnas and Arnad are neighbours.']\n",
      "Projection\t\t Arnad [SEP] Donnas\n",
      "Projection (tokenized)\t\t [ARG] Arnad [SEP] Donnas\n",
      "Predicted (tokenized)\t\t [ARG] Donnas [SEP] Arnad\n",
      "********************************************************************************\n",
      "Score\t\t 0.7727272727272727\n",
      "Query\t\t How many items were made?\n",
      "Type\t\t count\n",
      "Fact\t\t ['There were 849702000 Fuji made']\n",
      "Projection\t\t 849702000\n",
      "Projection (tokenized)\t\t [COUNT] 849702000\n",
      "Predicted (tokenized)\t\t [COUNT] 849702000 Fuji\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Does Emma's mother live in Berlin?\n",
      "Type\t\t join_boolean\n",
      "Fact\t\t [\"Julie is Emma's mother\", 'Julie lived in Berlin for 2 years, currently she lives in London.']\n",
      "Projection\t\t FALSE\n",
      "Projection (tokenized)\t\t [BOOL] FALSE\n",
      "Predicted (tokenized)\t\t [BOOL] TRUE\n",
      "********************************************************************************\n",
      "Score\t\t 0.7391304347826086\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Lhden and Lahn share borders with each other.']\n",
      "Projection\t\t Lhden [SEP] Lahn\n",
      "Projection (tokenized)\t\t [ARG] Lhden [SEP] Lahn\n",
      "Predicted (tokenized)\t\t [ARG] Lahn [SEP] Lhden\n",
      "********************************************************************************\n",
      "Score\t\t 0.7\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Mr shares a border with Dy.']\n",
      "Projection\t\t Dy [SEP] Mr\n",
      "Projection (tokenized)\t\t [ARG] Dy [SEP] Mr\n",
      "Predicted (tokenized)\t\t [ARG] Mr [SEP] Dy\n",
      "********************************************************************************\n",
      "Score\t\t 0.7142857142857143\n",
      "Query\t\t In which country was Dorinel born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1968, Dorinel's parents lived in Grdinari when he was born.\"]\n",
      "Projection\t\t Romania\n",
      "Projection (tokenized)\t\t [BOOL] Romania\n",
      "Predicted (tokenized)\t\t [BOOL] Croatia\n",
      "********************************************************************************\n",
      "Score\t\t 0.2727272727272727\n",
      "Query\t\t Which book has the fewest number of authors?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Catherine Lucile Moore wrote Shambleau']\n",
      "Projection\t\t Catherine Lucile Moore [SEP] Shambleau\n",
      "Projection (tokenized)\t\t [ARG] Catherine Lucile Moore [SEP] Shambleau\n",
      "Predicted (tokenized)\t\t [ARG] Shambleau [SEP] Catherine Lucile Moore\n",
      "********************************************************************************\n",
      "Score\t\t 0.5714285714285714\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Corbas shares a border with Chaponnay.']\n",
      "Projection\t\t Corbas [SEP] Chaponnay\n",
      "Projection (tokenized)\t\t [ARG] Corbas [SEP] Chaponnay\n",
      "Predicted (tokenized)\t\t [ARG] Chaponnay [SEP] Corbas\n",
      "********************************************************************************\n",
      "Score\t\t 0.47619047619047616\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['jezd u ern Hory is neighbour with Hlubok Dvory.']\n",
      "Projection\t\t jezd u ern Hory [SEP] Hlubok Dvory\n",
      "Projection (tokenized)\t\t [ARG] jezd u ern Hory [SEP] Hlubok Dvory\n",
      "Predicted (tokenized)\t\t [ARG] Hlubok Dvory [SEP] jezd u ern Hory\n",
      "********************************************************************************\n",
      "Score\t\t 0.42307692307692313\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Lacarry-Arhan-Charritte-de-Haut shares a border with Etchebar.']\n",
      "Projection\t\t Lacarry-Arhan-Charritte-de-Haut [SEP] Etchebar\n",
      "Projection (tokenized)\t\t [ARG] Lacarry-Arhan-Charritte-de-Haut [SEP] Etchebar\n",
      "Predicted (tokenized)\t\t [ARG] Etchebar [SEP] Lacarry-Arhan-Charritte-de-Haut\n",
      "********************************************************************************\n",
      "Score\t\t 0.19999999999999996\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Rhein-Kreis Neuss shares a border with Dsseldorf.']\n",
      "Projection\t\t Rhein-Kreis Neuss [SEP] Dsseldorf\n",
      "Projection (tokenized)\t\t [ARG] Rhein-Kreis Neuss [SEP] Dsseldorf\n",
      "Predicted (tokenized)\t\t [ARG] Dsseldorf [SEP] Rhein-Kreis Neuss\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t In which country was Emma born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t ['Emma was born in Beechworth in 1974.']\n",
      "Projection\t\t Australia\n",
      "Projection (tokenized)\t\t [BOOL] Australia\n",
      "Predicted (tokenized)\t\t [BOOL] United Kingdom\n",
      "********************************************************************************\n",
      "Score\t\t 0.736842105263158\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Lucas County and Ottawa County are neighbours.']\n",
      "Projection\t\t Ottawa County [SEP] Lucas County\n",
      "Projection (tokenized)\t\t [ARG] Ottawa County [SEP] Lucas County\n",
      "Predicted (tokenized)\t\t [ARG] Lucas County [SEP] Ottawa County\n",
      "********************************************************************************\n",
      "Score\t\t 0.5294117647058824\n",
      "Query\t\t Which place has the highest number of neighbours?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Plougoumelen is neighbour with Plumergat.']\n",
      "Projection\t\t Plougoumelen [SEP] Plumergat\n",
      "Projection (tokenized)\t\t [ARG] Plougoumelen [SEP] Plumergat\n",
      "Predicted (tokenized)\t\t [ARG] Plumergat [SEP] Plougoumelen\n",
      "********************************************************************************\n",
      "Score\t\t 0.4285714285714286\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Brchaumont is neighbour with Wolfersdorf.']\n",
      "Projection\t\t Brchaumont [SEP] Wolfersdorf\n",
      "Projection (tokenized)\t\t [ARG] Brchaumont [SEP] Wolfersdorf\n",
      "Predicted (tokenized)\t\t [ARG] Wolfersdorf [SEP] Brchaumont\n",
      "********************************************************************************\n",
      "Score\t\t 0.6944444444444444\n",
      "Query\t\t What league has the most participants?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['The league that Radosaw Kauny plays in is Bundesliga']\n",
      "Projection\t\t Bundesliga [SEP] Bundesliga\n",
      "Projection (tokenized)\t\t [ARG] Bundesliga [SEP] Bundesliga\n",
      "Predicted (tokenized)\t\t [ARG] Bundesliga [SEP] Radosaw Kauny\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Michael born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Michael was born in 1990. At the time, his parents lived in Padua.']\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.4181818181818182\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Canton of Esch-sur-Alzette and Canton of Remich share borders with each other.']\n",
      "Projection\t\t Canton of Esch-sur-Alzette [SEP] Canton of Remich\n",
      "Projection (tokenized)\t\t [ARG] Canton of Esch-sur-Alzette [SEP] Canton of Remich\n",
      "Predicted (tokenized)\t\t [ARG] Canton of Remich [SEP] Canton of Esch-sur-Alzette\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Russ born in Europe?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t ['Russ was born in 1945. At the time, his parents lived in Waltham Cross.']\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.5714285714285714\n",
      "Query\t\t In which country was Maurice born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1947, Maurice's parents lived in Aalst when he was born.\"]\n",
      "Projection\t\t Belgium\n",
      "Projection (tokenized)\t\t [BOOL] Belgium\n",
      "Predicted (tokenized)\t\t [BOOL] Germany\n",
      "********************************************************************************\n",
      "Score\t\t 0.6666666666666667\n",
      "Query\t\t Was Lea born in Switzerland?\n",
      "Type\t\t atomic_boolean\n",
      "Fact\t\t [\"In 1980, Lea's parents lived in Winterthur when she was born.\"]\n",
      "Projection\t\t TRUE\n",
      "Projection (tokenized)\t\t [BOOL] TRUE\n",
      "Predicted (tokenized)\t\t [BOOL] FALSE\n",
      "********************************************************************************\n",
      "Score\t\t 0.4545454545454546\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Koganei City shares a border with Nishitky.']\n",
      "Projection\t\t Nishitky [SEP] Koganei City\n",
      "Projection (tokenized)\t\t [ARG] Nishitky [SEP] Koganei City\n",
      "Predicted (tokenized)\t\t [ARG] Koganei City [SEP] Nishitky\n",
      "********************************************************************************\n",
      "Score\t\t 0.3023255813953488\n",
      "Query\t\t What is the place with the maximum number of borders?\n",
      "Type\t\t argmax\n",
      "Fact\t\t ['Caspian Sea is neighbour with Mazandaran Province.']\n",
      "Projection\t\t Caspian Sea [SEP] Mazandaran Province\n",
      "Projection (tokenized)\t\t [ARG] Caspian Sea [SEP] Mazandaran Province\n",
      "Predicted (tokenized)\t\t [ARG] Mazandaran Province [SEP] Caspian Sea\n",
      "********************************************************************************\n",
      "Score\t\t 0.4\n",
      "Query\t\t In which country was Nelson born?\n",
      "Type\t\t atomic_extractive\n",
      "Fact\t\t [\"In 1988, Nelson's parents lived in Reims when he was born.\"]\n",
      "Projection\t\t France\n",
      "Projection (tokenized)\t\t [BOOL] France\n",
      "Predicted (tokenized)\t\t [BOOL] United States\n",
      "********************************************************************************\n",
      "Score\t\t 0.5384615384615384\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t ['Mladjov is neighbour with Samina.']\n",
      "Projection\t\t Mladjov [SEP] Samina\n",
      "Projection (tokenized)\t\t [ARG] Mladjov [SEP] Samina\n",
      "Predicted (tokenized)\t\t [ARG] Samina [SEP] Mladjov\n",
      "********************************************************************************\n",
      "Score\t\t 0.8048780487804879\n",
      "Query\t\t What is the place with the minimum number of borders?\n",
      "Type\t\t argmin\n",
      "Fact\t\t [\"Pieve d'Alpago and Chies d'Alpago share borders with each other.\"]\n",
      "Projection\t\t Pieve d'Alpago [SEP] Chies d'Alpago\n",
      "Projection (tokenized)\t\t [ARG] Pieve d'Alpago [SEP] Chies d'Alpago\n",
      "Predicted (tokenized)\t\t [ARG] Chies d'Alpago [SEP] Pieve d'Alpago\n",
      "********************************************************************************\n",
      "Score\t\t 0.4347826086956522\n",
      "Query\t\t Which place has the lowest number of neighbours?\n",
      "Type\t\t argmin\n",
      "Fact\t\t [\"Saint-Gervais is neighbour with Saint-Laurent-d'Arce.\"]\n",
      "Projection\t\t Saint-Gervais [SEP] Saint-Laurent-d'Arce\n",
      "Projection (tokenized)\t\t [ARG] Saint-Gervais [SEP] Saint-Laurent-d'Arce\n",
      "Predicted (tokenized)\t\t [ARG] Saint-Laurent-d'Arce [SEP] Saint-Gervais\n",
      "defaultdict(<class 'int'>, {'argmax': 85, 'argmin': 93, 'atomic_boolean': 32, 'set': 1, 'atomic_extractive': 32, 'join_boolean': 3, 'count': 4, 'join_extractive': 1})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"TRANS ERROR\")\n",
    "type_counts = defaultdict(int)\n",
    "for exp in experiments:\n",
    "    if exp[\"version\"] == \"v2.2\" and exp[\"lr\"] == \"8e-5\" and exp[\"train_percentage\"]==100:\n",
    "        for item in exp[\"raw\"]:\n",
    "            if \"[NULL_ANSWER]\" not in item[0]  and \"[NULL_ANSWER]\" not in item[1] and item[2]<1:\n",
    "                test_instance = item[3]\n",
    "                type_counts[test_instance[\"type\"]] +=1\n",
    "                print(\"*\"*80)\n",
    "                print(\"Score\\t\\t\",item[2])\n",
    "                print(\"Query\\t\\t\",item[3][\"query\"])\n",
    "                print(\"Type\\t\\t\",item[3][\"type\"])\n",
    "                print(\"Fact\\t\\t\",item[3][\"fact\"])\n",
    "                print(\"Projection\\t\\t\",item[3][\"projection\"])\n",
    "                print(\"Projection (tokenized)\\t\\t\", item[1])\n",
    "                print(\"Predicted (tokenized)\\t\\t\", item[0])\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "print(type_counts)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "neuraldb",
   "language": "python",
   "display_name": "neuraldb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}