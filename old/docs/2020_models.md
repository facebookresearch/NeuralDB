# 2020 Models for VLDB paper

This assumes that you are using the 2020 data format which contains questions and facts paired with projections insteasd of the direct answers.
 The projections are computed by model with full supervision and then _aggregated_ by a downstream module to compute the final answer. 
 
 The first half of this readme considers the oracle/perfectIR case (assuming that the correct sentences are input to the model) using retrieved evidence from a pipeline is considered in the second half of this document.

## Projection data file
This should have been generated in the previous step. The data files can, however, be downloaded from this [Google Drive]() folder.

## Training

The models are a T5 sequence to sequence model that input a fact, and query and output a projection.
The models are trained with full supervision of the intermediate form.

To run the HuggingFace fine-tuning program, see: `scripts/train.t5.operator.sh`. 

```
python src/neuraldb/commands/t5train2_operator.py \
  --model_name_or_path=t5-base \
  --learning_rate=1e-5 \
  --train_batch_size=64 \
  --eval_batch_size=64 \
  --num_train_epoch=3 \
  --output_dir=output/ndb_operator/ \
  --n_gpu=${NUM_GPU:-1} \
  --do_train \
  --train_path=${version}/generated_clean_train.jsonl \
  --val_path=${version}/generated_clean_val.jsonl \
  --test_name=metrics_test.jsonl \
  --val_check_interval=1.0 \
  --seed=${seed}
```

Relations can be filtered out of the training dataset (to assess transfer learning ability) with the following arguments 
```
--filter P54 P31 
```

etc

### Predictions

Model predictions need to be aggregated to generate the final answer. The model is optimized to minimize the error on the projection and we assess this downstream on the trained model finally on the end to end task. 

The predictions can be generated by evaluating the model with huggingface.

```
python -m neuraldb.commands.t5train2_operator \
--output_dir [path_to_finetuned model] \
--model_name_or_path t5-base \
--do_predict \
--eval_batch_size 128 \
--n_gpu 1 \
--test_name metrics_test.jsonl \
--train_path=[path_to_train.jsonl] \
--val_path=[path_to_dev.jsonl] \
--test_path=[path_to_test.jsonl]
```
  
### Aggregating the answer

The projections need to be compiled to a single answer. This entails reading the `metrics_test.jsonl` file containing the predictions, and aggregating the reuslts into a single file (assuming one large database).

See the `notebooks/final_operator_breakdown3` notebook for an example of how this is done. The code for building the answers for 2020 is in the notebooks. It's not really re-usable. However, for 2021 the same code (or a slight improvement of it) is avaialable in 
`https://github.com/fairinternal/ndb-kg-lm/blob/master/src/score_operator_e2e.py`


 