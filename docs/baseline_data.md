## Downloading baseline model (D1) data

The baseline data are generated by synthesizing new facts for entities and properties. Some entities are taken from 
Wikipedia and generated by randomly assigning properties and relations to these entities.

The baseline datasets are generated by Marzieh Saedi 

The dropbox links behind the scripits to download the data keep expiring/changing. Archived data is stored in [Google drive](https://drive.google.com/drive/folders/1q8v5zs3IiMIZTosUxXabfx9DE0lX6iAT?usp=sharing)
 
Changelog is in this [readme file](data/gen/README.md) 

```bash
bash data/gen/download_gen_data_v02.sh
bash data/gen/download_gen_data_v04.sh
bash data/gen/download_gen_data_v05.sh
```

### File format / purpose

The baseline files contain databases of 50-10000 facts and questions/answers over these. They evaluate simple question 
answering behaviour for joins and basic aggregation such as min/max. The filenames end in `_last_NNNN` where NNNN 
represents the number of facts in each of the databases.

The file format is a JSON list of databases. Each database contains an ordered list of facts, and a set of queries and answers.
There are subtle differences between v0.2,4 and 5. Because of this, all there are 3 variations of this dataset reader.

See the following files:

```
src/neuraldb/dataset/e2e_reader/v_0_2_database_reader.py
src/neuraldb/dataset/e2e_reader/v_0_4_database_reader.py
src/neuraldb/dataset/e2e_reader/v_0_5_database_reader.py
```

The dataset reader can be interchanged by each of the model files.
